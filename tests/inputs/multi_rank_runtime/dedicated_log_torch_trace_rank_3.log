V0804 12:34:12.717000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "3da8c36d2a0ed7f7a0e688b44d952da4"}
	{
	"name": "dynamo",
	"ts": 1754336052717635.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:12.718000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "441d934774cf2009f47efa3ac2fc6ccd"}
	{
	"name": "entire_frame_compile",
	"ts": 1754336052718671.8,
	"args": {
	"fn_name": "_compile.compile_inner",
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:12.719000 1142858 torch/_logging/structured.py:28] {"str": ["/home/skarjala/pytorch/torch/_dynamo/convert_frame.py", 0]}
V0804 12:34:12.720000 1142858 torch/_logging/structured.py:28] {"str": ["/home/skarjala/pytorch/test2.py", 1]}
V0804 12:34:12.720000 1142858 torch/_logging/structured.py:28] {"str": ["/home/skarjala/pytorch/torch/_dynamo/eval_frame.py", 2]}
V0804 12:34:12.720000 1142858 torch/_logging/structured.py:28] {"str": ["/home/skarjala/pytorch/torch/_dynamo/external_utils.py", 3]}
V0804 12:34:12.720000 1142858 torch/_dynamo/convert_frame.py:231] {"dynamo_start": {"stack": [{"line": 191, "name": "<module>", "filename": 1, "loc": "main()"}, {"line": 164, "name": "main", "filename": 1, "loc": "_ = compiled_graph_two(x)"}, {"line": 804, "name": "compile_wrapper", "filename": 2, "loc": "return fn(*args, **kwargs)"}, {"line": 66, "name": "inner", "filename": 3}]}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.721000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "e349b3408a6429cb8d898075ef2cac68"}
	{
	"name": "compile_attempt_0",
	"ts": 1754336052721261.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:12.726000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "3f0d68559606e7bbc18e3b196d4ff7f2"}
	{
	"name": "bytecode_tracing",
	"ts": 1754336052726123.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:12.737000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 0, "describer_id": 0, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.737000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1024, 1], "storage": 0, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0276250c80>)", "describer_id": 0}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.738000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 0, "id": 0, "source": "L['fn'].__self__._modules['lin2']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.750000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 1, "describer_id": 0, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.751000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "stride": [1024, 1], "storage": 1, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Tensor object at 0x7f02578e68a0>)", "describer_id": 0}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.751000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 0, "id": 1, "source": "L['args'][0]"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.771000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 2, "describer_id": 0, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.771000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 7, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1024, 1], "storage": 2, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0275d78370>)", "describer_id": 0}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.772000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 0, "id": 7, "source": "L['fn'].__self__._modules['lin1']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:12.778000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "44cac01ebf4df11745191fe5c0a49187"}
	{
	"name": "bytecode_tracing",
	"ts": 1754336052778331.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:12.782000 1142858 torch/_dynamo/output_graph.py:1686] {"dynamo_output_graph": {"sizes": {"l_fn_self_modules_lin2_parameters_weight_": [1024, 1024], "l_args_0_": [1024, 1024], "l_fn_self_modules_lin1_parameters_weight_": [1024, 1024], "a": [1024, 1024], "a_1": [1024, 1024], "all_reduce_default": [1024, 1024], "a_2": [1024, 1024], "a_3": [1024, 1024], "a_4": [1024, 1024]}}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "294ecad1b9f72d8e800c88db76b03c83"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:105 in graph_two, code: a = self.lin2(x)
	        a: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin2_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:106 in graph_two, code: a = F.silu(a)
	        a_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.silu(a);  a = None
	        
	         # File: /home/skarjala/pytorch/test2.py:109 in graph_two, code: torch.ops._c10d_functional.all_reduce.default(a, "avg", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(a_1, 'avg', '0');  a_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:108 in graph_two, code: a = torch.ops._c10d_functional.wait_tensor.default(
	        a_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:113 in graph_two, code: a = self.lin1(a)
	        a_3: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(a_2, l_fn_self_modules_lin1_parameters_weight_, None);  a_2 = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:114 in graph_two, code: a = F.relu(a)
	        a_4: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(a_3);  a_3 = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (a_4,)
	        
V0804 12:34:12.783000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "5fb25b72bcc75e531fbd608633158e8f"}
	{
	"name": "backend_compile",
	"ts": 1754336052783549.0,
	"args": {
	"fn_name": "OutputGraph.call_user_compiler",
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:12.784000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "1bca001edc6c878ecc6e6bca4911fff1"}
	{
	"name": "inductor_codecache_torch_key",
	"ts": 1754336052784177.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:13.002000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "43861f9501d76fb7f758f326732a1715"}
	{
	"name": "inductor_codecache_torch_key",
	"ts": 1754336053002018.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:13.005000 1142858 torch/_inductor/compile_fx.py:2185] {"artifact": {"name": "before_pre_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "a17d620758f7c42df2981e18058f82b0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:105 in graph_two, code: a = self.lin2(x)
	        a: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin2_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:106 in graph_two, code: a = F.silu(a)
	        a_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.silu(a);  a = None
	        
	         # File: /home/skarjala/pytorch/test2.py:109 in graph_two, code: torch.ops._c10d_functional.all_reduce.default(a, "avg", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(a_1, 'avg', '0');  a_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:108 in graph_two, code: a = torch.ops._c10d_functional.wait_tensor.default(
	        a_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:113 in graph_two, code: a = self.lin1(a)
	        a_3: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(a_2, l_fn_self_modules_lin1_parameters_weight_, None);  a_2 = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:114 in graph_two, code: a = F.relu(a)
	        a_4: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(a_3);  a_3 = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (a_4,)
	        
	
	 # graph id: 139645242014800
V0804 12:34:13.005000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "013e018988283022f71816049e6559a6"}
	{
	"name": "_recursive_pre_grad_passes",
	"ts": 1754336053005705.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:13.011000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "6e70d1b00397cf71265688ea994303fa"}
	{
	"name": "_recursive_pre_grad_passes",
	"ts": 1754336053011404.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:13.012000 1142858 torch/_inductor/compile_fx.py:2216] {"artifact": {"name": "after_pre_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "a17d620758f7c42df2981e18058f82b0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:105 in graph_two, code: a = self.lin2(x)
	        a: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin2_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:106 in graph_two, code: a = F.silu(a)
	        a_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.silu(a);  a = None
	        
	         # File: /home/skarjala/pytorch/test2.py:109 in graph_two, code: torch.ops._c10d_functional.all_reduce.default(a, "avg", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(a_1, 'avg', '0');  a_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:108 in graph_two, code: a = torch.ops._c10d_functional.wait_tensor.default(
	        a_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:113 in graph_two, code: a = self.lin1(a)
	        a_3: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(a_2, l_fn_self_modules_lin1_parameters_weight_, None);  a_2 = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:114 in graph_two, code: a = F.relu(a)
	        a_4: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(a_3);  a_3 = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (a_4,)
	        
	
	 # graph id: 139645242014800
V0804 12:34:14.180000 1142858 torch/_dynamo/utils.py:1970] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "1aa72e0c3016ac5d656926a294b604cf"}
	{
	"name": "autograd_cache_miss",
	"ts": 1754336054179866.0,
	"args": {
	"cache_status_detailed": "full_miss",
	"key": "avszzuec4skaixhlo4k23plqxin6wttp5kgdfzdscokpn5q3bble",
	"cache_state": "miss",
	"components": [
	"[bza62mayqe7bei6il2tvvhjndm2n2qxqd6hots3pjak4kqrx7gr] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight')], True, False)",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False",
	"[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>",
	"[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])",
	"[hytvaouwdcfh55gy4gq3gm54v6jhj2gm5stwgfrdvnahbrym6gr] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    a = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    a_1 = torch.nn.functional.silu(a);  a = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(a_1, 'avg', '0');  a_1 = None\n    a_2 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    a_3 = torch._C._nn.linear(a_2, p_2, None);  a_2 = p_2 = None\n    a_4 = torch.nn.functional.relu(a_3);  a_3 = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (a_4,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"compile_id": "0/0"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0804 12:34:14.181000 1142858 torch/_functorch/_aot_autograd/autograd_cache.py:1231] {"artifact": {"name": "aotautograd_cache_miss", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "2ecf7547c374ca248cb789b9864d67d5"}
	{"cache_status_detailed": "full_miss", "key": "avszzuec4skaixhlo4k23plqxin6wttp5kgdfzdscokpn5q3bble", "cache_state": "miss", "components": ["[bza62mayqe7bei6il2tvvhjndm2n2qxqd6hots3pjak4kqrx7gr] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight')], True, False)", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False", "[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>", "[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])", "[hytvaouwdcfh55gy4gq3gm54v6jhj2gm5stwgfrdvnahbrym6gr] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    a = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    a_1 = torch.nn.functional.silu(a);  a = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(a_1, 'avg', '0');  a_1 = None\n    a_2 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    a_3 = torch._C._nn.linear(a_2, p_2, None);  a_2 = p_2 = None\n    a_4 = torch.nn.functional.relu(a_3);  a_3 = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (a_4,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ", "[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)", "[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>", "[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}", "[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}", "[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False", "[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10", "[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True", "[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']", "[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None", "[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op", "[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait", "[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"], "compile_id": "0/0"}
V0804 12:34:14.181000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "f261b5987dea201da3a90bd9f53b731d"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1754336054181707.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.187000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "3b109fceac1156324f395b1c6ebbe5ef"}
	{
	"name": "aot_collect_metadata",
	"ts": 1754336054187592.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.199000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "aaa3c2f1b3be9e91734fd70b75c00811"}
	{
	"name": "aot_collect_metadata",
	"ts": 1754336054199664.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.241000 1142858 torch/_functorch/_aot_autograd/graph_capture.py:301] {"artifact": {"name": "aot_forward_graph_fw_metadata", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "8a4ad9f0f02e5b8a499cde7a3f9582ed"}
	ViewAndMutationMeta(input_info=[InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=False,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True)],
	                    output_info=[OutputAliasInfo(output_type=<OutputType.non_alias: 1>,
	                                                raw_type=<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,
	                                                base_idx=None,
	                                                dynamic_dims=set(),
	                                                requires_grad=False,
	                                                functional_tensor=None)],
	                    num_intermediate_bases=0,
	                    keep_input_mutations=True,
	                    traced_tangents=[],
	                    traced_tangents_descs=[],
	                    subclass_inp_meta=[PlainTensorMeta(unwrapped_idx=0,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=1,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=2,
	                                                      memory_format=None)],
	                    subclass_fw_graph_out_meta=[PlainTensorMeta(unwrapped_idx=0,
	                                                               memory_format=None)],
	                    subclass_tangent_meta=[],
	                    is_train=False,
	                    traced_tangent_metas=None,
	                    num_symints_saved_for_bw=None,
	                    grad_enabled_mutation=None,
	                    deterministic=False,
	                    static_input_indices=[0, 2],
	                    tokens={},
	                    indices_of_inputs_that_requires_grad_with_mutations_in_bw=[],
	                    bw_donated_idxs=None,
	                    num_backward_tokens=0,
	                    num_graphsafe_rng_states=0,
	                    graphsafe_rng_state_index=None)
V0804 12:34:14.242000 1142858 torch/_functorch/_aot_autograd/graph_capture.py:319] {"aot_inference_graph": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "cdc7f7263d3a66a419e50b654107ddd9"}
	class <lambda>(torch.nn.Module):
	    def forward(
	        self,
	        arg0_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=0)
	        arg1_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=1)
	        arg2_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=2)
	    ):
	         # File: /home/skarjala/pytorch/test2.py:105 in graph_two, code: a = self.lin2(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:106 in graph_two, code: a = F.silu(a)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        sigmoid: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sigmoid.default(convert_element_type_2)
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, sigmoid);  convert_element_type_2 = sigmoid = None
	        convert_element_type_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul, torch.float16);  mul = None
	        
	         # File: /home/skarjala/pytorch/test2.py:109 in graph_two, code: torch.ops._c10d_functional.all_reduce.default(a, "avg", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(convert_element_type_3, 'avg', '0');  convert_element_type_3 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:108 in graph_two, code: a = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:113 in graph_two, code: a = self.lin1(a)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg2_1, [1, 0]);  arg2_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:114 in graph_two, code: a = F.relu(a)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        return (
	            relu,  # PlainAOTOutput(idx=0)
	        )
	        
V0804 12:34:14.244000 1142858 torch/_functorch/_aot_autograd/graph_compile.py:285] {"artifact": {"name": "torch._functorch.config", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "7b8fae87b220765c393a4321db77304b"}
	{
	"TYPE_CHECKING": false,
	"functionalize_rng_ops": false,
	"fake_tensor_allow_meta": true,
	"debug_assert": false,
	"debug_partitioner": true,
	"decompose_custom_triton_ops": true,
	"static_weight_shapes": true,
	"treat_parameters_as_free_to_save": true,
	"cse": true,
	"enable_autograd_cache": true,
	"autograd_cache_allow_custom_autograd_functions": false,
	"bundled_autograd_cache": false,
	"autograd_cache_normalize_inputs": true,
	"enable_remote_autograd_cache": null,
	"view_replay_for_aliased_outputs": true,
	"max_dist_from_bw": 1000,
	"ban_recompute_used_far_apart": true,
	"ban_recompute_long_fusible_chains": true,
	"ban_recompute_materialized_backward": true,
	"ban_recompute_not_in_allowlist": true,
	"ban_recompute_reductions": true,
	"recompute_views": false,
	"activation_memory_budget": 1.0,
	"activation_memory_budget_runtime_estimator": "flops",
	"activation_memory_budget_solver": "dp",
	"visualize_memory_budget_pareto": false,
	"memory_budget_pareto_dir": null,
	"aggressive_recomputation": false,
	"fake_tensor_allow_unsafe_data_ptr_access": true,
	"unlift_effect_tokens": true,
	"custom_op_default_layout_constraint": "needs_exact_strides",
	"fake_tensor_crossref": false,
	"fake_tensor_propagate_real_tensors": false,
	"backward_pass_autocast": "same_as_forward",
	"donated_buffer": true,
	"torch_compile_graph_format": "svg",
	"generate_fake_kernels_from_real_mismatches": false,
	"graphsafe_rng_functionalization": true,
	"strict_autograd_cache": false,
	"unsafe_allow_optimization_of_collectives": false,
	"disable_guess_zero_tangent_for_mutated_input_subclass": false,
	"guess_tangent_strides_as_outputs": false,
	"_sync_decision_cross_ranks": false,
	"saved_tensors_hooks_filtering_mode": "donated"
	}
V0804 12:34:14.244000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "9698442c68edea92fa1868ae4040a84d"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1754336054244857.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.245000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "42ead1b2ab69aaf7ff3dd56c3c0eb138"}
	{
	"name": "_recursive_joint_graph_passes",
	"ts": 1754336054245480.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.447000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "8ea0dd191fda0dd5b88f0ff4ef84b2fe"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336054447877.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.448000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "15d6b797184ee3ee581e7715d7da2fb3"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336054448825.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.449000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "b927de8c3eb86fd06437965485d47067"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336054449595.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.450000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "bcefb0cb1e07a80e52b0f1981c088217"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336054450109.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.451000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "a27ceecd6aa00124868475a79a925208"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336054451431.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.452000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "dcc850b8df9d335424afd2fdc4c9b23e"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336054451990.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.452000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "74c9984a4d6775104295a05ec1eda55e"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336054452701.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.453000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "a758a41d8969a7bda00a232c22d9a867"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336054453199.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.454000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "21eff0fd36379be03f2c786320258203"}
	{
	"name": "_recursive_joint_graph_passes",
	"ts": 1754336054454155.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.454000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "a08a9eeac0876ca410bcb538d776069f"}
	{
	"name": "inductor_compile",
	"ts": 1754336054454685.2,
	"args": {
	"fn_name": "compile_fx_inner",
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.456000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "d06e9f001ce8da711dc4c6fffc83b008"}
	{
	"name": "fx_codegen_and_compile",
	"ts": 1754336054456064.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.470000 1142858 torch/_inductor/compile_fx.py:1218] {"artifact": {"name": "fx_graph_runnable", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "32b2890c2753a386b4c6e175ec2e259c"}
	
	import os
	os.environ['TORCH_TRACE'] = '1'
	os.environ['TORCHELASTIC_RESTART_COUNT'] = '0'
	os.environ['TORCHELASTIC_MAX_RESTARTS'] = '0'
	os.environ['TORCHELASTIC_RUN_ID'] = 'none'
	os.environ['TORCHELASTIC_USE_AGENT_STORE'] = 'True'
	os.environ['TORCH_NCCL_ASYNC_ERROR_HANDLING'] = '1'
	os.environ['TORCHELASTIC_ERROR_FILE'] = '/tmp/torchelastic_krot7efo/none_58jhr50i/attempt_0/1/error.json'
	os.environ['TORCH_COMPILE_DEBUG'] = '1'
	os.environ['TORCH_LOGS_FORMAT'] = '[%(filename)s:%(lineno)d %(levelname)s] %(message)s'
	os.environ['TORCH_LOGS_OUT'] = '/dev/stdout'
	os.environ['TORCHINDUCTOR_CACHE_DIR'] = '/tmp/torchinductor_cache'
	
	import torch
	from torch import tensor, device
	import torch.fx as fx
	from torch._dynamo.testing import rand_strided
	from math import inf
	import torch._inductor.inductor_prims
	import torch.distributed as dist
	from torch.testing._internal.distributed.fake_pg import FakeStore
	
	import torch._dynamo.config
	import torch._inductor.config
	import torch._functorch.config
	import torch.fx.experimental._config
	
	
	torch._functorch.config.functionalize_rng_ops = False
	torch._functorch.config.debug_partitioner = True
	torch._functorch.config.fake_tensor_allow_unsafe_data_ptr_access = True
	torch._functorch.config.unlift_effect_tokens = True
	
	
	
	isolate_fails_code_str = None
	
	
	
	
	# torch version: 2.9.0a0+git2249284
	# torch cuda version: 12.4
	# torch git version: 22492848b66f13637b01a4d8f98a16e3004940a9
	
	
	# CUDA Info: 
	# nvcc: NVIDIA (R) Cuda compiler driver 
	# Copyright (c) 2005-2024 NVIDIA Corporation 
	# Built on Thu_Mar_28_02:18:24_PDT_2024 
	# Cuda compilation tools, release 12.4, V12.4.131 
	# Build cuda_12.4.r12.4/compiler.34097967_0 
	
	# GPU Hardware Info: 
	# NVIDIA PG509-210 : 2 
	
	
	from torch.nn import *
	class Repro(torch.nn.Module):
	    def __init__(self) -> None:
	        super().__init__()
	
	    
	    
	    def forward(self, arg0_1, arg1_1, arg2_1):
	        permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        sigmoid = torch.ops.aten.sigmoid.default(convert_element_type_2)
	        mul = torch.ops.aten.mul.Tensor(convert_element_type_2, sigmoid);  convert_element_type_2 = sigmoid = None
	        convert_element_type_3 = torch.ops.prims.convert_element_type.default(mul, torch.float16);  mul = None
	        all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_3, 'avg', '0');  convert_element_type_3 = None
	        wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        permute_1 = torch.ops.aten.permute.default(arg2_1, [1, 0]);  arg2_1 = None
	        mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        return (relu,)
	        
	def load_args(reader):
	    buf0 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf0, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg0_1
	    buf1 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf1, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg1_1
	    buf2 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf2, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg2_1
	load_args._version = 0
	mod = Repro()
	if __name__ == '__main__':
	    from torch._dynamo.repro.after_aot import run_repro
	    # Initialize FakeProcessGroup for distributed operations
	    store = FakeStore()
	    dist.init_process_group(
	        backend="fake",
	        rank=0,
	        world_size=2,
	        store=store
	    )
	    with torch.no_grad():
	        run_repro(mod, load_args, accuracy=False, command='run', save_dir=None, tracing_mode='real', check_str=None)
	        # To run it separately, do 
	        # mod, args = run_repro(mod, load_args, accuracy=False, command='get_args', save_dir=None, tracing_mode='real', check_str=None)
	        # mod(*args)
	    dist.destroy_process_group()
	
V0804 12:34:14.473000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "0ae8fb2ae507dcf5fdecd95b4aa80615"}
	{
	"name": "additional_fake_tensor_prop",
	"ts": 1754336054473661.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.480000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "4169920d79d7e29594687fe3af143683"}
	{
	"name": "additional_fake_tensor_prop",
	"ts": 1754336054480459.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.481000 1142858 torch/_inductor/compile_fx.py:1267] {"artifact": {"name": "before_post_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "677b28a7dc71f6dc57fd670398f2b62d"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f16[1024, 1024][1024, 1]cuda:1", arg1_1: "f16[1024, 1024][1024, 1]cuda:1", arg2_1: "f16[1024, 1024][1024, 1]cuda:1"):
	         # File: /home/skarjala/pytorch/test2.py:105 in graph_two, code: a = self.lin2(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:106 in graph_two, code: a = F.silu(a)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        sigmoid: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sigmoid.default(convert_element_type_2)
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, sigmoid);  convert_element_type_2 = sigmoid = None
	        convert_element_type_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul, torch.float16);  mul = None
	        
	         # File: /home/skarjala/pytorch/test2.py:109 in graph_two, code: torch.ops._c10d_functional.all_reduce.default(a, "avg", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(convert_element_type_3, 'avg', '0');  convert_element_type_3 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:108 in graph_two, code: a = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:113 in graph_two, code: a = self.lin1(a)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg2_1, [1, 0]);  arg2_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:114 in graph_two, code: a = F.relu(a)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        return (relu,)
	        
V0804 12:34:14.482000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "012a191b0c5d86356069f93fdec372c8"}
	{
	"name": "_recursive_post_grad_passes",
	"ts": 1754336054482092.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.510000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "e32d122f20db5503e7c65715fa140606"}
	{
	"name": "_recursive_post_grad_passes",
	"ts": 1754336054510479.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.512000 1142858 torch/_inductor/compile_fx.py:1305] {"artifact": {"name": "after_post_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "d0f0de1dbf95debc3d00408beb9ba4cb"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f16[1024, 1024][1024, 1]cuda:1", arg1_1: "f16[1024, 1024][1024, 1]cuda:1", arg2_1: "f16[1024, 1024][1024, 1]cuda:1"):
	         # File: /home/skarjala/pytorch/test2.py:105 in graph_two, code: a = self.lin2(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:106 in graph_two, code: a = F.silu(a)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        sigmoid: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sigmoid.default(convert_element_type_2)
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, sigmoid);  convert_element_type_2 = sigmoid = None
	        convert_element_type_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul, torch.float16);  mul = None
	        
	         # File: /home/skarjala/pytorch/test2.py:109 in graph_two, code: torch.ops._c10d_functional.all_reduce.default(a, "avg", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce_.default(convert_element_type_3, 'avg', '0');  convert_element_type_3 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:108 in graph_two, code: a = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:113 in graph_two, code: a = self.lin1(a)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg2_1, [1, 0]);  arg2_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:114 in graph_two, code: a = F.relu(a)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        return (relu,)
	        
V0804 12:34:14.513000 1142858 torch/_inductor/compile_fx.py:1317] {"artifact": {"name": "inductor_post_to_pre_grad_nodes", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "47d48532aec6c8d1665e74c65e166dda"}
	{"permute": [{"name": "a", "target": "<built-in function linear>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm": [{"name": "a", "target": "<built-in function linear>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_2": [{"name": "a_1", "target": "<function silu at 0x7f01fe16e660>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sigmoid": [{"name": "a_1", "target": "<function silu at 0x7f01fe16e660>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul": [{"name": "a_1", "target": "<function silu at 0x7f01fe16e660>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_3": [{"name": "a_1", "target": "<function silu at 0x7f01fe16e660>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "all_reduce": [{"name": "all_reduce_default", "target": "_c10d_functional.all_reduce.default", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor": [{"name": "a_2", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_1": [{"name": "a_3", "target": "<built-in function linear>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_1": [{"name": "a_3", "target": "<built-in function linear>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "relu": [{"name": "a_4", "target": "<function relu at 0x7f01fe16da80>", "graph_id": 139645242014800, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}
V0804 12:34:14.514000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "0a06c1ffae6a9cfff9252f0f3dd8e6c2"}
	{
	"name": "GraphLowering.run",
	"ts": 1754336054514587.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.571000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "4349c3fdf035eec036e3ce21f85a6076"}
	{
	"name": "GraphLowering.run",
	"ts": 1754336054570956.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.571000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "64a80b32c21f0bb668adaf395bc8b7b5"}
	{
	"name": "GraphLowering.compile_to_fn",
	"ts": 1754336054571532.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.572000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "984c581731857656c1e35471a8e6b490"}
	{
	"name": "code_gen",
	"ts": 1754336054571942.0,
	"args": {
	"fn_name": "GraphLowering.compile_to_module",
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.572000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "944b26d1a5d8b43b65ca201f30f0eebf"}
	{
	"name": "GraphLowering.codegen",
	"ts": 1754336054572332.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.574000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "56281ff3e4e4ef5ff3a7ab7ec855e59e"}
	{
	"name": "Scheduler.__init__",
	"ts": 1754336054574621.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.593000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "103decddb9aeb175151a1bcda00de8b4"}
	{
	"name": "Scheduler.fused_nodes",
	"ts": 1754336054593914.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.594000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "b36761b5e3855ede7899d5eec64975b0"}
	{
	"name": "Scheduler.fused_nodes",
	"ts": 1754336054594600.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.603000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "3b485407bbabce42bbeeb59eec5b541a"}
	{
	"name": "Scheduler.__init__",
	"ts": 1754336054603105.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.603000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "60448959c9345204c12beb3bb78d73b9"}
	{
	"name": "Scheduler.codegen",
	"ts": 1754336054603659.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.649000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "8878d000dc3373549059ce3186b31f80"}
	{
	"name": "Scheduler.codegen",
	"ts": 1754336054648999.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.649000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "6067c8614f8da368420526c75b4e6b17"}
	{
	"name": "PythonWrapperCodegen.generate",
	"ts": 1754336054649619.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.653000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "98cf6d1d1f42e86c4cce9c305da66510"}
	{
	"name": "PythonWrapperCodegen.generate",
	"ts": 1754336054653828.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.654000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "6541586ad552a375a8271a75d2879e0a"}
	{
	"name": "GraphLowering.codegen",
	"ts": 1754336054654269.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.655000 1142858 torch/_inductor/graph.py:2390] {"inductor_output_code": {"filename": "/tmp/torchinductor_cache/7z/c7zzniv6psl3mwbob4fdxji746ntddl47wclmlexuyefu4wi2cl2.py"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "b9839d2c7f29008c041e8a5dbde2c151"}
	# AOT ID: ['0_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from cmath import nanj
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	import triton
	import triton.language as tl
	from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
	from torch._C import _cuda_getCurrentRawStream as get_raw_stream
	from torch._C import _cuda_getCurrentRawStream as get_raw_stream
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	assert_alignment = torch._C._dynamo.guards.assert_alignment
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
	
	
	# kernel path: /tmp/torchinductor_cache/my/cmyfmoj3csqqipysxnla4uf4juhbhuhrkewgm7rned5rkncwwdkx.py
	# Topologically Sorted Source Nodes: [a_1, all_reduce_default], Original ATen: [aten.silu, _c10d_functional.all_reduce]
	# Source node to ATen node mapping:
	#   a_1 => convert_element_type_2, convert_element_type_3, mul, sigmoid
	#   all_reduce_default => all_reduce
	# Graph fragment:
	#   %mm : Tensor "f16[1024, 1024][1024, 1]cuda:1" = PlaceHolder[target=mm]
	#   %convert_element_type_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=2] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%mm, torch.float32), kwargs = {})
	#   %sigmoid : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.sigmoid.default](args = (%convert_element_type_2,), kwargs = {})
	#   %mul : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, %sigmoid), kwargs = {})
	#   %convert_element_type_3 : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%mul, torch.float16), kwargs = {})
	#   %all_reduce : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops._c10d_functional.all_reduce_.default](args = (%convert_element_type_3, avg, 0), kwargs = {})
	#   return %wait_tensor
	triton_poi_fused_all_reduce_silu_0 = async_compile.triton('triton_poi_fused_all_reduce_silu_0', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.pointwise(
	    size_hints={'x': 1048576}, 
	    filename=__file__,
	    triton_meta={'signature': {'in_out_ptr0': '*fp16', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_all_reduce_silu_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 6291456}},
	    min_elem_per_thread=0
	)
	@triton.jit
	def triton_poi_fused_all_reduce_silu_0(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
	    xnumel = 1048576
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = xoffset + tl.arange(0, XBLOCK)[:]
	    xmask = tl.full([XBLOCK], True, tl.int1)
	    x0 = xindex
	    tmp0 = tl.load(in_out_ptr0 + (x0), None).to(tl.float32)
	    tmp1 = tmp0.to(tl.float32)
	    tmp2 = tl.sigmoid(tmp1)
	    tmp3 = tmp1 * tmp2
	    tmp4 = tmp3.to(tl.float32)
	    tl.store(in_out_ptr0 + (x0), tmp4, None)
	''', device_str='cuda')
	
	
	# kernel path: /tmp/torchinductor_cache/jl/cjllim6z7dwkbfrmhgp5ci3nzuyvlc6fjagkg67aztohofna3cx4.py
	# Topologically Sorted Source Nodes: [a_4], Original ATen: [aten.relu]
	# Source node to ATen node mapping:
	#   a_4 => relu
	# Graph fragment:
	#   %mm_1 : Tensor "f16[1024, 1024][1024, 1]cuda:1" = PlaceHolder[target=mm_1]
	#   %relu : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%mm_1,), kwargs = {})
	#   return %relu
	triton_poi_fused_relu_1 = async_compile.triton('triton_poi_fused_relu_1', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.pointwise(
	    size_hints={'x': 1048576}, 
	    filename=__file__,
	    triton_meta={'signature': {'in_out_ptr0': '*fp16', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_relu_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 6291456}},
	    min_elem_per_thread=0
	)
	@triton.jit
	def triton_poi_fused_relu_1(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
	    xnumel = 1048576
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = xoffset + tl.arange(0, XBLOCK)[:]
	    xmask = tl.full([XBLOCK], True, tl.int1)
	    x0 = xindex
	    tmp0 = tl.load(in_out_ptr0 + (x0), None).to(tl.float32)
	    tmp1 = tl.full([1], 0, tl.int32)
	    tmp2 = triton_helpers.maximum(tmp1, tmp0)
	    tl.store(in_out_ptr0 + (x0), tmp2, None)
	''', device_str='cuda')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
	    with torch.cuda._DeviceGuard(1):
	        torch.cuda.set_device(1)
	        buf0 = empty_strided_cuda((1024, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [a], Original ATen: [aten.mm]
	        extern_kernels.mm(arg1_1, reinterpret_tensor(arg0_1, (1024, 1024), (1, 1024), 0), out=buf0)
	        del arg0_1
	        del arg1_1
	        buf1 = buf0; del buf0  # reuse
	        # Topologically Sorted Source Nodes: [a_1, all_reduce_default], Original ATen: [aten.silu, _c10d_functional.all_reduce]
	        stream1 = get_raw_stream(1)
	        triton_poi_fused_all_reduce_silu_0.run(buf1, 1048576, stream=stream1)
	        # Topologically Sorted Source Nodes: [a_1, all_reduce_default], Original ATen: [aten.silu, _c10d_functional.all_reduce]
	        torch.ops._c10d_functional.all_reduce_.default(buf1, 'avg', '0')
	        # Topologically Sorted Source Nodes: [a_2], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf1)
	        buf6 = empty_strided_cuda((1024, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [a_3], Original ATen: [aten.mm]
	        extern_kernels.mm(buf1, reinterpret_tensor(arg2_1, (1024, 1024), (1, 1024), 0), out=buf6)
	        del arg2_1
	        del buf1
	        buf7 = buf6; del buf6  # reuse
	        # Topologically Sorted Source Nodes: [a_4], Original ATen: [aten.relu]
	        stream1 = get_raw_stream(1)
	        triton_poi_fused_relu_1.run(buf7, 1048576, stream=stream1)
	    return (buf7, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg1_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg2_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0804 12:34:14.655000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "86967250bead25a3b8ef13aff74fb3a4"}
	{
	"name": "PyCodeCache.load_by_key_path",
	"ts": 1754336054655683.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.664000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "b8845b7858331cf5b6c72f94637938b0"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336054664391.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.948000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "19cb37f115544ce24aedf89f94b2b7b1"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336054948267.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.949000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "89f3ea3c82d01c30b983c4edff7b14f2"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336054949094.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.950000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "9cc2c19e8086fe29b1819085a22c31b4"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336054950376.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:14.950000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "dd174567958422bfb1d98d285ef814e9"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336054950919.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.195000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "ce99f8c13714bfa51fcb926023dc5725"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336055195819.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.196000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "33a397d600149abf3cddd6bbd363f9d1"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336055196657.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.197000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "e49eac63760492c98ad6478caf083ae4"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336055197846.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.198000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "4aed688d617e3e50cd8738c230ce4875"}
	{
	"name": "async_compile.wait",
	"ts": 1754336055198288.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.198000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "fdcc5e110781c2930ad0666b3db6594c"}
	{
	"name": "async_compile.wait",
	"ts": 1754336055198789.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.199000 1142858 torch/_inductor/async_compile.py:116] {"artifact": {"name": "triton_kernel_info", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "8c57995f07341ccfd25baf5da8dc019d"}
	{"triton_poi_fused_all_reduce_silu_0": {"autotune_cache_state": "miss", "num_configs": 2, "compile_time_us": 285427}, "triton_poi_fused_relu_1": {"autotune_cache_state": "miss", "num_configs": 2, "compile_time_us": 246411}}
V0804 12:34:15.199000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "433c8ada6b7408626fecfec50734e7a6"}
	{
	"name": "PyCodeCache.load_by_key_path",
	"ts": 1754336055199557.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.201000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "59d692aea4c0c4ce8187506bd58abe7b"}
	{
	"name": "code_gen",
	"ts": 1754336055201351.0,
	"args": {
	"fn_name": "GraphLowering.compile_to_module",
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.201000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "4a6db07116dbc433d81c1ea1a831b07e"}
	{
	"name": "GraphLowering.compile_to_fn",
	"ts": 1754336055201811.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.202000 1142858 torch/_inductor/debug.py:700] {"artifact": {"name": "inductor_collective_schedule", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "ef4d0a8db1d97743de090487b312ba8a"}
	[
	"torch.ops._c10d_functional.all_reduce_.default",
	"torch.ops._c10d_functional.wait_tensor.default"
	]
V0804 12:34:15.305000 1142858 torch/_inductor/debug.py:734] {"artifact": {"name": "inductor_runtime_and_tensor_meta", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "114d64567a1ab3e037f77ad8fb9055c2"}
	{
	"ops": [
	{
	"name": "extern_kernels.mm",
	"type": "compute",
	"estimated_runtime_ns": 7918718.15083388,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "op1",
	"type": "compute",
	"estimated_runtime_ns": 2492.275132275132,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.all_reduce_.default",
	"type": "collective",
	"estimated_runtime_ns": 34581.10319102395,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "extern_kernels.mm",
	"type": "compute",
	"estimated_runtime_ns": 7918718.15094938,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "op5",
	"type": "compute",
	"estimated_runtime_ns": 2492.275022751326,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	}
	]
	}
V0804 12:34:15.306000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "3b4cf5bb93177ff79c267703a5ce809b"}
	{
	"name": "TritonBundler.collect",
	"ts": 1754336055306144.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.307000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "5f0219d6eb7ba3d63253e331befb2cf8"}
	{
	"name": "TritonBundler.collect",
	"ts": 1754336055307736.0,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.311000 1142858 torch/_dynamo/utils.py:1970] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "5e33e55c9a7102a3605e90313506383d"}
	{
	"name": "fx_graph_cache_miss",
	"ts": 1754336054456579.5,
	"args": {
	"cache_status_detailed": "full_miss",
	"key": "fpyhvdhcfoiuuduzpn66gf4p7ec4hz36lxxb4suectspwni6qvvi",
	"components": [
	"[ba2mvxcjeobgwjj5px6dmzq4qh2ivithbmes6q34jl7xnubu45a] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    sigmoid = torch.ops.aten.sigmoid.default(convert_element_type_2)\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, sigmoid);  convert_element_type_2 = sigmoid = None\n    convert_element_type_3 = torch.ops.prims.convert_element_type.default(mul, torch.float16);  mul = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_3, 'avg', '0');  convert_element_type_3 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg2_1, [1, 0]);  arg2_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    return (relu,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[rncdo5wrumut4kpxippskulf7u4z3kvsxqyqmyxtrf4xjnzk666] fx_kwargs[static_input_idxs]: [0, 2]",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_event_time": 1754336054465465608,
	"cache_state": "miss",
	"triton_bundler_meta": "TritonBundlerMetadata(cached_kernel_names=['triton_poi_fused_all_reduce_silu_0', 'triton_poi_fused_all_reduce_silu_0', 'triton_poi_fused_relu_1', 'triton_poi_fused_relu_1'], statically_launched_kernel_names=['triton_poi_fused_all_reduce_silu_0', 'triton_poi_fused_relu_1'])",
	"time_taken_ns": 849496330,
	"compile_id": "0/0"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0804 12:34:15.311000 1142858 torch/_inductor/compile_fx.py:1046] {"artifact": {"name": "fx_graph_cache_miss", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "6b96771f5e4cfc3d9cf16706706699e8"}
	{"cache_status_detailed": "full_miss", "key": "fpyhvdhcfoiuuduzpn66gf4p7ec4hz36lxxb4suectspwni6qvvi", "components": ["[ba2mvxcjeobgwjj5px6dmzq4qh2ivithbmes6q34jl7xnubu45a] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    sigmoid = torch.ops.aten.sigmoid.default(convert_element_type_2)\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, sigmoid);  convert_element_type_2 = sigmoid = None\n    convert_element_type_3 = torch.ops.prims.convert_element_type.default(mul, torch.float16);  mul = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_3, 'avg', '0');  convert_element_type_3 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg2_1, [1, 0]);  arg2_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    return (relu,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ", "[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[rncdo5wrumut4kpxippskulf7u4z3kvsxqyqmyxtrf4xjnzk666] fx_kwargs[static_input_idxs]: [0, 2]", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)", "[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>", "[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}", "[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}", "[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False", "[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10", "[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True", "[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']", "[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None", "[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op", "[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait", "[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"], "cache_event_time": 1754336054465465608, "cache_state": "miss", "triton_bundler_meta": "TritonBundlerMetadata(cached_kernel_names=['triton_poi_fused_all_reduce_silu_0', 'triton_poi_fused_all_reduce_silu_0', 'triton_poi_fused_relu_1', 'triton_poi_fused_relu_1'], statically_launched_kernel_names=['triton_poi_fused_all_reduce_silu_0', 'triton_poi_fused_relu_1'])", "time_taken_ns": 849496330, "compile_id": "0/0"}
V0804 12:34:15.312000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "3a6b1080cecccacde4f230fb79d8ff95"}
	{
	"name": "fx_codegen_and_compile",
	"ts": 1754336055312490.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.313000 1142858 torch/_inductor/compile_fx.py:1063] {"artifact": {"name": "inductor_provenance_tracking_node_mappings", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "5db7da9a4bc09a5c55fc1bcd2948e2ec"}
	{"preToPost": {"a": ["permute", "mm"], "a_1": ["convert_element_type_2", "sigmoid", "mul", "convert_element_type_3"], "all_reduce_default": ["all_reduce"], "a_2": ["wait_tensor"], "a_3": ["permute_1", "mm_1"], "a_4": ["relu"]}, "postToPre": {"permute": ["a"], "mm": ["a"], "convert_element_type_2": ["a_1"], "sigmoid": ["a_1"], "mul": ["a_1"], "convert_element_type_3": ["a_1"], "all_reduce": ["all_reduce_default"], "wait_tensor": ["a_2"], "permute_1": ["a_3"], "mm_1": ["a_3"], "relu": ["a_4"]}, "cppCodeToPost": {"triton_poi_fused_all_reduce_silu_0": ["all_reduce", "convert_element_type_3", "mul", "convert_element_type_2", "sigmoid"], "triton_poi_fused_relu_1": ["relu"], "extern_kernels.mm": ["mm", "mm_1"]}, "postToCppCode": {"all_reduce": ["triton_poi_fused_all_reduce_silu_0"], "convert_element_type_3": ["triton_poi_fused_all_reduce_silu_0"], "mul": ["triton_poi_fused_all_reduce_silu_0"], "convert_element_type_2": ["triton_poi_fused_all_reduce_silu_0"], "sigmoid": ["triton_poi_fused_all_reduce_silu_0"], "relu": ["triton_poi_fused_relu_1"], "mm": ["extern_kernels.mm"], "mm_1": ["extern_kernels.mm"]}}
V0804 12:34:15.314000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "2ed8616acd37b3b71e1cf4daea42275d"}
	{
	"name": "inductor_compile",
	"ts": 1754336055314142.5,
	"args": {
	"fn_name": "compile_fx_inner",
	"compile_id": "0/0",
	"is_backward": false,
	"cache_state": "miss",
	"cache_event_time": 1754336054456579527,
	"key": "fpyhvdhcfoiuuduzpn66gf4p7ec4hz36lxxb4suectspwni6qvvi",
	"components": [
	"[ba2mvxcjeobgwjj5px6dmzq4qh2ivithbmes6q34jl7xnubu45a] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    sigmoid = torch.ops.aten.sigmoid.default(convert_element_type_2)\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, sigmoid);  convert_element_type_2 = sigmoid = None\n    convert_element_type_3 = torch.ops.prims.convert_element_type.default(mul, torch.float16);  mul = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_3, 'avg', '0');  convert_element_type_3 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg2_1, [1, 0]);  arg2_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    return (relu,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[rncdo5wrumut4kpxippskulf7u4z3kvsxqyqmyxtrf4xjnzk666] fx_kwargs[static_input_idxs]: [0, 2]",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_bypass_reason": null,
	"remote_cache_enabled": false,
	"local_cache_enabled": true
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.315000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "6b19b9ce43568d41c3ae05cee898f025"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1754336055315317.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.320000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "a35aa550999a6ca843edfa04541f22be"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1754336055320605.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.322000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "d307169ee725363566b533e960edfc82"}
	{
	"name": "backend_compile",
	"ts": 1754336055321559.0,
	"args": {
	"fn_name": "OutputGraph.call_user_compiler",
	"compile_id": "0/0",
	"cache_state": "miss",
	"cache_event_time": 1754336054179866083,
	"key": "avszzuec4skaixhlo4k23plqxin6wttp5kgdfzdscokpn5q3bble",
	"components": [
	"[bza62mayqe7bei6il2tvvhjndm2n2qxqd6hots3pjak4kqrx7gr] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight')], True, False)",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False",
	"[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>",
	"[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])",
	"[hytvaouwdcfh55gy4gq3gm54v6jhj2gm5stwgfrdvnahbrym6gr] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    a = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    a_1 = torch.nn.functional.silu(a);  a = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(a_1, 'avg', '0');  a_1 = None\n    a_2 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    a_3 = torch._C._nn.linear(a_2, p_2, None);  a_2 = p_2 = None\n    a_4 = torch.nn.functional.relu(a_3);  a_3 = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (a_4,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_bypass_reason": null,
	"remote_cache_enabled": false,
	"local_cache_enabled": true,
	"requires_subclass_dispatch": false,
	"dispatch_mode": "inference"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.324000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "373853093c201ebfcadf43006e53e7e5"}
	{
	"name": "compile_attempt_0",
	"ts": 1754336055324822.8,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.325000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "4f21a215d6a4deaa02a3ea8a9fe0838d"}
	{
	"name": "build_guards",
	"ts": 1754336055325269.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.371000 1142858 torch/_dynamo/guards.py:3264] {"dynamo_cpp_guards_str": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "7e0d7cc08418849d607a58f2a7fb798e"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo/output_graph.py:643 in init_ambient_guards
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:631 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['fn'], accessed_by=FrameLocalsGuardAccessor(key='fn', framelocals_idx=2), type=<class 'method'>, tag_safe=(False, False)
	| | +- ID_MATCH: ___check_obj_id(L['fn'], 139645370122560)                   
	| | +- GuardManager: source=L['fn'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__), type=<class 'tuple'>, tag_safe=(False, False)
	| | | +- GuardManager: source=L['fn'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0), type=<class 'cell'>, tag_safe=(False, False)
	| | | | +- GuardManager: source=L['fn'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents), type=<class 'method'>, tag_safe=(False, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__closure__[0].cell_contents, 9738560)  # with ctx_factory():  # utils/_contextlib.py:119 in decorate_context
	| | | +- GuardManager: source=L['fn'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1), type=<class 'cell'>, tag_safe=(False, False)
	| | | | +- GuardManager: source=L['fn'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- GuardManager: source=L['fn'].__closure__[1].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__), type=<class 'code'>, tag_safe=(True, False)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['fn'].__closure__[1].cell_contents.__code__, 10805760)  # return func(*args, **kwargs)  # utils/_contextlib.py:120 in decorate_context
	| | +- GuardManager: source=L['fn'].__self__, accessed_by=GetAttrGuardAccessor(__self__), type=<class '__main__.MultiGraphRepro'>, tag_safe=(True, True)
	| | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__, 86065824)                
	| | | +- GuardManager: source=L['fn'].__self__.__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | +- GuardManager: source=L['fn'].__self__._modules, accessed_by=DictGetItemGuardAccessor('_modules'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules, 9676128)          # a = self.lin2(x)  # test2.py:105 in graph_two
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1'], accessed_by=DictGetItemGuardAccessor('lin1'), type=<class 'torch.nn.modules.linear.Linear'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin1'], 87594704)  # a = self.lin1(a)  # test2.py:113 in graph_two
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['lin1'].__dict__)  # a = self.lin1(a)  # test2.py:113 in graph_two
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin1']._parameters, 9676128)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'NoneType'>, tag_safe=(True, False)
	| | | | | | | | | +- NONE_MATCH: L['fn'].__self__._modules['lin1']._parameters['bias'] is None  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['lin1']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2'], accessed_by=DictGetItemGuardAccessor('lin2'), type=<class 'torch.nn.modules.linear.Linear'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin2'], 87594704)  # a = self.lin2(x)  # test2.py:105 in graph_two
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['lin2'].__dict__)  # a = self.lin2(x)  # test2.py:105 in graph_two
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin2']._parameters, 9676128)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'NoneType'>, tag_safe=(True, False)
	| | | | | | | | | +- NONE_MATCH: L['fn'].__self__._modules['lin2']._parameters['bias'] is None  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['lin2']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | +- GuardManager: source=L['fn'].__self__._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._parameters, 9676128)       # a = self.lin2(x)  # test2.py:105 in graph_two
	| +- GuardManager: source=L['args'], accessed_by=FrameLocalsGuardAccessor(key='args', framelocals_idx=0), type=<class 'tuple'>, tag_safe=(True, False)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 9650464)                        
	| | +- LENGTH_CHECK: len(L['args']) == 1                                         
	| | +- GuardManager: source=L['args'][0], accessed_by=TupleGetItemGuardAccessor(0), type=<class 'torch.Tensor'>, tag_safe=(True, False)
	| | | +- TENSOR_MATCH: check_tensor(L['args'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=False, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- NO_HASATTR: hasattr(L['args'][0], '_dynamo_dynamic_indices') == False     # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| +- GuardManager: source=L['kwargs'], accessed_by=FrameLocalsGuardAccessor(key='kwargs', framelocals_idx=1), type=<class 'dict'>, tag_safe=(True, False)
	| | +- TYPE_MATCH: ___check_type_id(L['kwargs'], 9676128)                      
	| | +- DICT_LENGTH: not L['kwargs']                                             
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)
	| | +- GuardManager: source=G['__import___main__'], accessed_by=DictGetItemGuardAccessor('__import___main__'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import___main__'], 139648550378592)      # a = F.silu(a)  # test2.py:106 in graph_two
	| | | +- GuardManager: source=G['__import___main__'].torch, accessed_by=GetAttrGuardAccessor(torch), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch, 139648548799248)  # a = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:108 in graph_two
	| | | | +- GuardManager: source=G['__import___main__'].torch.ops, accessed_by=GetAttrGuardAccessor(ops), type=<class 'torch._ops._Ops'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops, 139646535729696)  # a = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:108 in graph_two
	| | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional, accessed_by=GetAttrGuardAccessor(_c10d_functional), type=<class 'torch._ops._OpNamespace'>, tag_safe=(False, False)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional, 139645390308672)  # a = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:108 in graph_two
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.all_reduce, accessed_by=GetAttrGuardAccessor(all_reduce), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.all_reduce, 139645365491216)  # torch.ops._c10d_functional.all_reduce.default(a, "avg", "0")  # test2.py:109 in graph_two
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.wait_tensor, accessed_by=GetAttrGuardAccessor(wait_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.wait_tensor, 139645391765136)  # a = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:108 in graph_two
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_linear'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 139646537542256)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F, 139646537542176)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.relu, accessed_by=GetAttrGuardAccessor(relu), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.relu, 139646534605440)  # a = F.relu(a)  # test2.py:114 in graph_two
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.silu, accessed_by=GetAttrGuardAccessor(silu), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.silu, 139646534608480)  # a = F.silu(a)  # test2.py:106 in graph_two
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.linear, accessed_by=GetAttrGuardAccessor(linear), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.linear, 139647331695760)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_module'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 139646542524272)  # a = self.lin2(x)  # test2.py:105 in graph_two
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 9668128)  # a = self.lin2(x)  # test2.py:105 in graph_two
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 9668128)  # a = self.lin2(x)  # test2.py:105 in graph_two
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 9668128)  # a = self.lin2(x)  # test2.py:105 in graph_two
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 9668128)  # a = self.lin2(x)  # test2.py:105 in graph_two
	+- LAMBDA_GUARD: G['__import_torch_dot_nn_dot_modules_dot_linear'].F is G['__import___main__'].F  # a = F.silu(a)  # test2.py:106 in graph_two
	
	Guard latency = 107.32 us
V0804 12:34:15.372000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "acd5810ee553c8007de24f49439636e5"}
	{
	"name": "build_guards",
	"ts": 1754336055372151.2,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.372000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "252e5dd21e9f655d09730a3938b28bd5"}
	{
	"name": "gc",
	"ts": 1754336055372814.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.373000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "384325dff1fda891d2f2bea0b37bb772"}
	{
	"name": "gc",
	"ts": 1754336055373750.5,
	"args": {
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.374000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "60e33dcf54ff283ce09ff8648328517b"}
	{
	"name": "entire_frame_compile",
	"ts": 1754336055374307.5,
	"args": {
	"fn_name": "_compile.compile_inner",
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.377000 1142858 torch/_dynamo/utils.py:1626] {"compilation_metrics": {"compile_id": "0/0", "frame_key": "1", "co_name": "inner", "co_filename": "/home/skarjala/pytorch/torch/_dynamo/external_utils.py", "co_firstlineno": 66, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 53, "shape_env_guard_count": 0, "graph_op_count": 8, "graph_node_count": 12, "graph_input_count": 3, "start_time": 1754336052.718661, "entire_frame_compile_time_s": 2.655635, "backend_compile_time_s": 2.538009, "inductor_compile_time_s": 0.859457, "code_gen_time_s": 0.629409, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": ["_c10d_functional::all_reduce", "_c10d_functional::wait_tensor"], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "remote_cache_time_saved_s": null, "structured_logging_overhead_s": 0.048496, "config_suppress_errors": false, "config_inline_inbuilt_nn_modules": true, "specialize_float": false, "dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}", "is_forward": true, "num_triton_bundles": null, "remote_fx_graph_cache_get_time_ms": null, "remote_fx_graph_cache_put_time_ms": null, "start_time_us": 1754336052718661, "duration_us": 2655635, "dynamo_cumulative_compile_time_us": 2655635, "aot_autograd_cumulative_compile_time_us": 2538009, "inductor_cumulative_compile_time_us": 859457, "inductor_code_gen_cumulative_compile_time_us": 629409, "triton_compile_time_us": 533413, "runtime_cudagraphify_time_us": null, "runtime_triton_autotune_time_us": null, "dynamo_compile_time_before_restart_us": 0, "distributed_ephemeral_timeout_us": null, "structured_logging_overhead_us": 48496, "remote_fx_graph_cache_get_time_us": null, "remote_fx_graph_cache_put_time_us": null, "backward_cumulative_compile_time_us": null, "end_time_us": 1754336055374689, "pre_grad_pass_time_us": 5698, "post_grad_pass_time_us": 28387, "joint_graph_pass_time_us": 208674, "log_format_version": 3, "inductor_config": "{\"TYPE_CHECKING\": false, \"_cache_config_ignore_prefix\": [\"trace\", \"cuda.cutlass_dir\", \"worker_start_method\", \"compile_threads\", \"post_grad_custom_post_pass\", \"post_grad_custom_pre_pass\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\", \"always_complex_memory_overlap_TESTING_ONLY\", \"fx_graph_cache\", \"fx_graph_remote_cache\", \"autotune_local_cache\", \"autotune_remote_cache\"], \"_collective.auto_select\": false, \"_collective.one_shot_all_reduce_threshold_bytes\": 131072, \"_fuse_ddp_bucket_size\": 25, \"_fuse_ddp_communication\": false, \"_fuse_ddp_communication_passes\": [\"fuse_ddp_with_concat_op\", \"schedule_comm_wait\"], \"_micro_pipeline_tp\": false, \"_post_fusion_custom_pass\": null, \"_pre_fusion_custom_pass\": null, \"_profile_var\": \"\", \"_raise_error_for_testing\": false, \"_save_config_ignore\": [\"trace.upload_tar\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"pre_grad_custom_pass\", \"aot_inductor.repro_level\", \"aot_inductor.dump_aoti_minifier\", \"post_grad_custom_pre_pass\", \"post_grad_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\"], \"add_pre_grad_passes\": null, \"aggressive_fusion\": false, \"alignment_asserts\": true, \"allow_buffer_reuse\": true, \"always_complex_memory_overlap_TESTING_ONLY\": false, \"always_keep_tensor_constants\": false, \"annotate_training\": false, \"aot_inductor.allow_stack_allocation\": false, \"aot_inductor.compile_standalone\": false, \"aot_inductor.compile_wrapper_opt_level\": \"O1\", \"aot_inductor.custom_op_libs\": null, \"aot_inductor.custom_ops_to_c_shims\": {}, \"aot_inductor.debug_compile\": false, \"aot_inductor.debug_intermediate_value_printer\": \"0\", \"aot_inductor.dump_aoti_minifier\": false, \"aot_inductor.embed_kernel_binary\": false, \"aot_inductor.emit_multi_arch_kernel\": false, \"aot_inductor.enable_lto\": false, \"aot_inductor.filtered_kernel_names\": null, \"aot_inductor.force_mmap_weights\": false, \"aot_inductor.metadata\": {}, \"aot_inductor.model_name_for_generated_files\": null, \"aot_inductor.output_path\": \"\", \"aot_inductor.package\": false, \"aot_inductor.package_constants_in_so\": true, \"aot_inductor.package_constants_on_disk\": false, \"aot_inductor.package_cpp_only\": null, \"aot_inductor.precompile_headers\": true, \"aot_inductor.presets\": {}, \"aot_inductor.raise_error_on_ignored_optimization\": true, \"aot_inductor.repro_level\": 2, \"aot_inductor.serialized_in_spec\": \"\", \"aot_inductor.serialized_out_spec\": \"\", \"aot_inductor.use_consts_asm_build\": true, \"aot_inductor.use_minimal_arrayref_interface\": false, \"aot_inductor.use_runtime_constant_folding\": false, \"aot_inductor.weight_use_caching_allocator\": false, \"assert_indirect_indexing\": true, \"assume_aligned_inputs\": false, \"assume_unaligned_fallback_output\": false, \"autoheuristic_collect\": \"\", \"autoheuristic_log_path\": \"DEFAULT\", \"autoheuristic_use\": \"mixed_mm\", \"autotune_fallback_to_aten\": false, \"autotune_in_subproc\": false, \"autotune_local_cache\": true, \"autotune_lookup_table\": {}, \"autotune_multi_device\": false, \"autotune_num_choices_displayed\": 10, \"autotune_remote_cache\": null, \"b2b_gemm_pass\": false, \"batch_fusion\": true, \"benchmark_combo_kernel\": false, \"benchmark_epilogue_fusion\": true, \"benchmark_fusion\": false, \"benchmark_harness\": true, \"benchmark_kernel\": false, \"bfloat16_atomic_adds_enabled\": true, \"bucket_all_gathers_fx\": \"none\", \"bucket_all_gathers_fx_bucket_size_determinator\": null, \"bucket_reduce_scatters_fx\": \"none\", \"bucket_reduce_scatters_fx_bucket_size_determinator\": null, \"bundle_triton_into_fx_graph_cache\": true, \"bundled_autotune_remote_cache\": null, \"bw_outputs_user_visible\": true, \"can_inplace_pad_graph_input\": false, \"check_stack_no_cycles_TESTING_ONLY\": false, \"combo_kernel_allow_mixed_sizes\": 1, \"combo_kernel_foreach_dynamic_shapes\": true, \"combo_kernels\": false, \"combo_kernels_autotune\": 1, \"comment_origin\": false, \"compile_threads\": 32, \"comprehensive_padding\": true, \"compute_all_bounds\": false, \"constant_and_index_propagation\": true, \"conv_1x1_as_mm\": false, \"coordinate_descent_check_all_directions\": false, \"coordinate_descent_search_radius\": 1, \"coordinate_descent_tuning\": false, \"cpp.cxx\": [null, \"g++\"], \"cpp.descriptive_names\": \"original_aten\", \"cpp.dynamic_threads\": false, \"cpp.enable_concat_linear\": false, \"cpp.enable_floating_point_contract_flag\": \"off\", \"cpp.enable_grouped_gemm_template\": false, \"cpp.enable_kernel_profile\": false, \"cpp.enable_loop_tail_vec\": true, \"cpp.enable_tiling_heuristics\": true, \"cpp.enable_unsafe_math_opt_flag\": false, \"cpp.fallback_scatter_reduce_sum\": true, \"cpp.force_inline_kernel\": false, \"cpp.gemm_cache_blocking\": null, \"cpp.gemm_max_k_slices\": 1, \"cpp.gemm_thread_factors\": null, \"cpp.inject_log1p_bug_TESTING_ONLY\": null, \"cpp.inject_relu_bug_TESTING_ONLY\": null, \"cpp.max_horizontal_fusion_size\": 16, \"cpp.min_chunk_size\": 512, \"cpp.no_redundant_loops\": true, \"cpp.simdlen\": null, \"cpp.threads\": -1, \"cpp.use_decompose_tanh\": false, \"cpp.use_small_dequant_buffer\": false, \"cpp.vec_isa_ok\": null, \"cpp.weight_prepack\": true, \"cpp_cache_precompile_headers\": true, \"cpp_wrapper\": false, \"cpp_wrapper_build_separate\": false, \"cpu_backend\": \"cpp\", \"cuda.arch\": null, \"cuda.binary_remote_cache_force_write\": false, \"cuda.compile_opt_level\": \"-O1\", \"cuda.cuda_cxx\": null, \"cuda.cutlass_backend_min_gemm_size\": 1, \"cuda.cutlass_dir\": \"/home/skarjala/pytorch/third_party/cutlass\", \"cuda.cutlass_enabled_ops\": \"all\", \"cuda.cutlass_epilogue_fusion_enabled\": false, \"cuda.cutlass_hash_with_compile_cmd\": false, \"cuda.cutlass_instantiation_level\": \"0\", \"cuda.cutlass_max_profiling_configs\": null, \"cuda.cutlass_max_profiling_swizzle_options\": [1, 2, 4, 8], \"cuda.cutlass_op_allowlist_regex\": null, \"cuda.cutlass_op_denylist_regex\": null, \"cuda.cutlass_prescreening\": true, \"cuda.cutlass_presets\": null, \"cuda.cutlass_tma_only\": false, \"cuda.enable_caching_codegen\": true, \"cuda.enable_cuda_lto\": false, \"cuda.enable_debug_info\": false, \"cuda.enable_ptxas_info\": false, \"cuda.generate_test_runner\": false, \"cuda.upload_to_binary_remote_cache\": false, \"cuda.use_binary_remote_cache\": true, \"cuda.use_fast_math\": false, \"cuda.version\": null, \"cuda_backend\": \"triton\", \"dce\": false, \"debug\": false, \"debug_fusion\": false, \"debug_index_asserts\": false, \"debug_ir_traceback\": false, \"decompose_mem_bound_mm\": false, \"developer_warnings\": true, \"disable_cpp_codegen\": false, \"disable_padding_cpu\": true, \"disable_progress\": true, \"dynamic_scale_rblock\": true, \"efficient_conv_bn_eval_fx_passes\": false, \"emulate_precision_casts\": false, \"enable_auto_functionalized_v2\": true, \"enable_caching_generated_triton_templates\": true, \"enable_linear_binary_folding\": false, \"enabled_metric_tables\": \"\", \"epilogue_fusion\": true, \"epilogue_fusion_first\": false, \"estimate_op_runtime\": \"default\", \"external_matmul\": [], \"fallback_random\": false, \"force_fuse_int_mm_with_mul\": false, \"force_layout_optimization\": false, \"force_pointwise_cat\": false, \"force_same_precision\": false, \"force_shape_pad\": false, \"freezing\": false, \"freezing_discard_parameters\": false, \"fx_graph_cache\": true, \"fx_graph_remote_cache\": null, \"fx_passes_numeric_check\": {\"num_iterations\": 1, \"pre_grad\": false, \"precision\": 0.0001, \"requires_optimizer\": true}, \"generate_intermediate_hooks\": false, \"global_cache_dir\": null, \"graph_partition\": false, \"group_fusion\": false, \"halide.asserts\": false, \"halide.cpu_target\": \"host\", \"halide.debug\": false, \"halide.gpu_target\": \"host-cuda\", \"halide.scan_kernels\": false, \"halide.scheduler_cpu\": \"Adams2019\", \"halide.scheduler_cuda\": \"Anderson2021\", \"implicit_fallbacks\": true, \"inplace_buffers\": true, \"inplace_padding\": true, \"inter_node_bw\": 25, \"intra_node_bw\": 300, \"is_nightly_or_source\": true, \"is_predispatch\": false, \"joint_custom_post_pass\": null, \"joint_custom_pre_pass\": null, \"joint_graph_constant_folding\": true, \"keep_output_stride\": true, \"kernel_name_max_ops\": 10, \"layout_opt_default\": \"1\", \"layout_optimization\": true, \"loop_ordering_after_fusion\": false, \"max_autotune\": false, \"max_autotune_conv_backends\": \"ATEN,TRITON\", \"max_autotune_flex_search_space\": \"DEFAULT\", \"max_autotune_gemm\": false, \"max_autotune_gemm_backends\": \"ATEN,TRITON,CPP\", \"max_autotune_gemm_search_space\": \"DEFAULT\", \"max_autotune_pointwise\": false, \"max_autotune_report_choices_stats\": true, \"max_autotune_subproc_graceful_timeout_seconds\": 0.0, \"max_autotune_subproc_result_timeout_seconds\": 60.0, \"max_autotune_subproc_terminate_timeout_seconds\": 0.0, \"max_epilogue_benchmarked_choices\": 1, \"max_fusion_buffer_group_pairwise_attempts\": 64, \"max_fusion_size\": 64, \"max_pointwise_cat_inputs\": 8, \"memory_planning\": false, \"memory_pool\": \"intermediates\", \"min_num_split\": 0, \"mixed_mm_choice\": \"heuristic\", \"multi_kernel_hints\": [], \"nan_asserts\": false, \"non_blocking_remote_cache_write\": true, \"online_softmax\": true, \"optimize_scatter_upon_const_tensor\": true, \"pad_channels_last\": false, \"pad_outputs\": false, \"padding_alignment_bytes\": 128, \"padding_stride_threshold\": 1024, \"pattern_matcher\": true, \"permute_fusion\": false, \"pick_loop_orders\": true, \"post_grad_custom_post_pass\": null, \"post_grad_custom_pre_pass\": null, \"post_grad_fusion_options\": {}, \"pre_grad_custom_pass\": null, \"pre_grad_fusion_options\": {}, \"precompilation_timeout_seconds\": 3600, \"profile_bandwidth\": false, \"profile_bandwidth_output\": null, \"profile_bandwidth_regex\": \"\", \"profile_bandwidth_with_do_bench_using_profiling\": false, \"profiler_mark_wrapper_call\": false, \"prologue_fusion\": true, \"quiesce_async_compile_pool\": false, \"realize_acc_reads_size_threshold\": null, \"realize_acc_reads_threshold\": 8, \"realize_opcount_threshold\": 30, \"realize_reads_threshold\": 4, \"remove_pre_grad_passes\": null, \"reorder_for_compute_comm_overlap\": false, \"reorder_for_compute_comm_overlap_passes\": [\"reorder_compute_for_overlap\", \"sink_waits\", \"raise_comms\"], \"reorder_for_locality\": true, \"reorder_for_peak_memory\": true, \"reorder_prefetch_limit\": null, \"rocm.arch\": [], \"rocm.ck_dir\": null, \"rocm.ck_max_profiling_configs\": null, \"rocm.ck_supported_arch\": [\"gfx90a\", \"gfx942\", \"gfx950\"], \"rocm.ck_tile_max_profiling_configs\": null, \"rocm.compile_opt_level\": \"-O2\", \"rocm.flush_denormals\": true, \"rocm.generate_test_runner\": false, \"rocm.is_debug\": false, \"rocm.kBatch_sweep\": null, \"rocm.n_max_profiling_configs\": null, \"rocm.print_kernel_resource_usage\": false, \"rocm.rocm_home\": null, \"rocm.save_temps\": false, \"rocm.split_k_threshold\": 16, \"rocm.use_fast_math\": true, \"rocm.use_preselected_instances\": false, \"save_args\": false, \"scalar_asserts\": true, \"score_fusion_memory_threshold\": 10, \"search_autotune_cache\": false, \"shape_padding\": true, \"size_asserts\": true, \"sleep_sec_TESTING_ONLY\": null, \"split_cat_fx_passes\": true, \"split_reductions\": true, \"static_launch_user_defined_triton_kernels\": false, \"static_weight_shapes\": true, \"strict_static_cuda_launcher\": false, \"test_configs.autotune_choice_desc_regex\": null, \"test_configs.autotune_choice_name_regex\": null, \"test_configs.force_extern_kernel_in_multi_template\": false, \"test_configs.graphsafe_rng_func_ignores_fallback_random\": false, \"test_configs.max_mm_configs\": null, \"test_configs.runtime_triton_dtype_assert\": false, \"test_configs.static_cpp_dtype_assert\": false, \"trace.compile_profile\": false, \"trace.debug_dir\": null, \"trace.debug_log\": false, \"trace.dot_graph_shape\": null, \"trace.draw_orig_fx_graph\": false, \"trace.enabled\": true, \"trace.fx_graph\": true, \"trace.fx_graph_transformed\": true, \"trace.graph_diagram\": false, \"trace.info_log\": false, \"trace.ir_post_fusion\": true, \"trace.ir_pre_fusion\": true, \"trace.log_autotuning_results\": false, \"trace.log_url_for_graph_xform\": null, \"trace.output_code\": true, \"trace.provenance_tracking\": true, \"trace.save_real_tensors\": false, \"trace.upload_tar\": null, \"triton.autotune_at_compile_time\": null, \"triton.autotune_cublasLt\": true, \"triton.autotune_pointwise\": true, \"triton.autotune_with_sample_inputs\": false, \"triton.coalesce_tiling_analysis\": true, \"triton.codegen_upcast_to_fp32\": true, \"triton.cooperative_reductions\": false, \"triton.cudagraph_capture_sizes\": null, \"triton.cudagraph_dynamic_shape_warn_limit\": 50, \"triton.cudagraph_skip_dynamic_graphs\": false, \"triton.cudagraph_support_input_mutation\": true, \"triton.cudagraph_trees\": true, \"triton.cudagraph_trees_history_recording\": false, \"triton.cudagraph_unexpected_rerecord_limit\": 128, \"triton.cudagraphs\": false, \"triton.debug_sync_graph\": false, \"triton.debug_sync_kernel\": false, \"triton.decompose_k_threshold\": 32, \"triton.dense_indexing\": false, \"triton.descriptive_names\": \"original_aten\", \"triton.disallow_failing_autotune_kernels_TESTING_ONLY\": false, \"triton.divisible_by_16\": true, \"triton.enable_persistent_tma_matmul\": false, \"triton.fast_path_cudagraph_asserts\": false, \"triton.force_cooperative_reductions\": false, \"triton.force_cudagraph_sync\": false, \"triton.force_cudagraphs_warmup\": false, \"triton.inject_relu_bug_TESTING_ONLY\": null, \"triton.max_tiles\": null, \"triton.min_split_scan_rblock\": 256, \"triton.multi_kernel\": 0, \"triton.num_decompose_k_splits\": 10, \"triton.persistent_reductions\": true, \"triton.prefer_nd_tiling\": false, \"triton.skip_cudagraph_warmup\": false, \"triton.skip_l1_cache\": false, \"triton.slow_path_cudagraph_asserts\": true, \"triton.spill_threshold\": 16, \"triton.store_cubin\": false, \"triton.tile_reductions\": false, \"triton.tiling_prevents_pointwise_fusion\": true, \"triton.tiling_prevents_reduction_fusion\": true, \"triton.unique_kernel_names\": true, \"triton.unique_user_kernel_names\": false, \"triton.use_block_ptr\": false, \"triton.use_tensor_descriptor\": false, \"triton_kernel_default_layout_constraint\": \"needs_fixed_stride_order\", \"unbacked_symint_fallback\": 8192, \"unroll_reductions_threshold\": 8, \"unsafe_ignore_unsupported_triton_autotune_args\": false, \"unsafe_marked_cacheable_functions\": {}, \"unsafe_skip_cache_dynamic_shape_guards\": false, \"use_experimental_benchmarker\": true, \"use_fast_math\": false, \"use_mixed_mm\": true, \"use_static_cuda_launcher\": true, \"verbose_progress\": false, \"warn_mix_layout\": false, \"worker_start_method\": \"subprocess\", \"worker_suppress_logging\": true}", "remote_cache_version": null, "inductor_fx_remote_cache_hit_count": null, "inductor_fx_remote_cache_miss_count": null, "inductor_fx_remote_cache_backend_type": null, "inductor_fx_remote_cache_hit_keys": null, "inductor_fx_remote_cache_miss_keys": null, "cuda_version": "12.4", "triton_version": "3.4.0", "feature_usage": {"aot_autograd_remote_cache": false, "fx_cache": true, "parallel_compile_post_warmup": false, "static_cuda_launcher": true, "triton_bundling": true}, "compile_time_autotune_time_us": 4000, "is_runtime": false, "gc_time_us": 935, "tensorify_float_attempt": null, "tensorify_float_success": null, "tensorify_float_failure": null, "guard_latency_us": 107, "recompile_reason": null, "num_graph_breaks": 0, "triton_kernel_compile_times_us": "[[\"triton_poi_fused_all_reduce_silu_0\", 285427], [\"triton_poi_fused_relu_1\", 246411]]", "ir_count": 53, "cudagraph_skip_reason": null, "python_version": "3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]", "pgo_put_remote_code_state_time_us": null, "pgo_get_remote_code_state_time_us": null, "param_numel": 2097152, "param_bytes": 4194304, "param_count": 2, "recompile_user_contexts": null}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0804 12:34:15.378000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "ac2276310a68fca934cd0f3d092af545"}
	{
	"name": "dynamo",
	"ts": 1754336055378071.0,
	"args": {
	"compile_id": "0/0",
	"num_graph_breaks": 0,
	"guard_latency_us": 107,
	"frame_key": "1",
	"co_name": "inner",
	"co_filename": "/home/skarjala/pytorch/torch/_dynamo/external_utils.py",
	"co_firstlineno": 66,
	"cache_size": 0,
	"accumulated_cache_size": 0,
	"guard_count": 53,
	"shape_env_guard_count": 0,
	"graph_op_count": 8,
	"graph_node_count": 12,
	"graph_input_count": 3,
	"fail_type": null,
	"fail_reason": null,
	"fail_user_frame_filename": null,
	"fail_user_frame_lineno": null,
	"non_compliant_ops": [],
	"compliant_custom_ops": [
	"_c10d_functional::all_reduce",
	"_c10d_functional::wait_tensor"
	],
	"restart_reasons": [],
	"dynamo_time_before_restart_s": 0.0,
	"has_guarded_code": true,
	"dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.626000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "f1510ffe1633c85065e32e04dc4ba319"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336055626723.8,
	"args": {
	"kernel_name": "triton_poi_fused_all_reduce_silu_0",
	"is_backward": false,
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.630000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "47316a27a9284e27effa2cb0e16e989f"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336055629900.2,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.658000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "8ec9663032de0ecf93c022df9c1884b6"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336055658725.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.659000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "2c0085b5eccdc697ef69c5231634e6cb"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336055659833.5,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.673000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "eb6ee05a7664ab224e6a25c1415df157"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336055673788.2,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:15.674000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "1836f6279ebe0d29ad11acdc6847049e"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336055674356.8,
	"args": {
	"kernel_name": "triton_poi_fused_all_reduce_silu_0",
	"is_backward": false,
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.280000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "4fda830de6d8ea8963e3d31208459d6b"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336056280826.8,
	"args": {
	"kernel_name": "triton_poi_fused_relu_1",
	"is_backward": false,
	"compile_id": "0/0"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.282000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "4cd573aa01d460afa70cf96d9a249f6b"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336056281979.2,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.295000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "a848adf8d506d0a26eea1366f3adde50"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336056295792.2,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.296000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "02b2fe555d92f292bda05b1b11531a6c"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336056296591.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.309000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "77e19ad21379b34fac588ef67da6ad49"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336056309305.2,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.309000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "06e324401d95d11d5abf31f62376c4cf"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336056309757.0,
	"args": {
	"kernel_name": "triton_poi_fused_relu_1",
	"is_backward": false,
	"compile_id": "0/0"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.312000 1142858 torch/_dynamo/utils.py:1626] {"compilation_metrics_runtime": {"compile_id": "0/0", "frame_key": null, "co_name": null, "co_filename": null, "co_firstlineno": null, "cache_size": null, "accumulated_cache_size": null, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1754336055.674697, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": null, "compliant_custom_ops": null, "restart_reasons": null, "dynamo_time_before_restart_s": null, "has_guarded_code": null, "remote_cache_time_saved_s": null, "structured_logging_overhead_s": null, "config_suppress_errors": false, "config_inline_inbuilt_nn_modules": true, "specialize_float": null, "dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}", "is_forward": true, "num_triton_bundles": null, "remote_fx_graph_cache_get_time_ms": null, "remote_fx_graph_cache_put_time_ms": null, "start_time_us": 1754336055674697, "duration_us": 76563, "dynamo_cumulative_compile_time_us": null, "aot_autograd_cumulative_compile_time_us": null, "inductor_cumulative_compile_time_us": null, "inductor_code_gen_cumulative_compile_time_us": null, "triton_compile_time_us": null, "runtime_cudagraphify_time_us": null, "runtime_triton_autotune_time_us": 76563, "dynamo_compile_time_before_restart_us": null, "distributed_ephemeral_timeout_us": null, "structured_logging_overhead_us": null, "remote_fx_graph_cache_get_time_us": null, "remote_fx_graph_cache_put_time_us": null, "backward_cumulative_compile_time_us": null, "end_time_us": 1754336056310642, "pre_grad_pass_time_us": null, "post_grad_pass_time_us": null, "joint_graph_pass_time_us": null, "log_format_version": 3, "inductor_config": "{\"TYPE_CHECKING\": false, \"_cache_config_ignore_prefix\": [\"trace\", \"cuda.cutlass_dir\", \"worker_start_method\", \"compile_threads\", \"post_grad_custom_post_pass\", \"post_grad_custom_pre_pass\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\", \"always_complex_memory_overlap_TESTING_ONLY\", \"fx_graph_cache\", \"fx_graph_remote_cache\", \"autotune_local_cache\", \"autotune_remote_cache\"], \"_collective.auto_select\": false, \"_collective.one_shot_all_reduce_threshold_bytes\": 131072, \"_fuse_ddp_bucket_size\": 25, \"_fuse_ddp_communication\": false, \"_fuse_ddp_communication_passes\": [\"fuse_ddp_with_concat_op\", \"schedule_comm_wait\"], \"_micro_pipeline_tp\": false, \"_post_fusion_custom_pass\": null, \"_pre_fusion_custom_pass\": null, \"_profile_var\": \"\", \"_raise_error_for_testing\": false, \"_save_config_ignore\": [\"trace.upload_tar\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"pre_grad_custom_pass\", \"aot_inductor.repro_level\", \"aot_inductor.dump_aoti_minifier\", \"post_grad_custom_pre_pass\", \"post_grad_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\"], \"add_pre_grad_passes\": null, \"aggressive_fusion\": false, \"alignment_asserts\": true, \"allow_buffer_reuse\": true, \"always_complex_memory_overlap_TESTING_ONLY\": false, \"always_keep_tensor_constants\": false, \"annotate_training\": false, \"aot_inductor.allow_stack_allocation\": false, \"aot_inductor.compile_standalone\": false, \"aot_inductor.compile_wrapper_opt_level\": \"O1\", \"aot_inductor.custom_op_libs\": null, \"aot_inductor.custom_ops_to_c_shims\": {}, \"aot_inductor.debug_compile\": false, \"aot_inductor.debug_intermediate_value_printer\": \"0\", \"aot_inductor.dump_aoti_minifier\": false, \"aot_inductor.embed_kernel_binary\": false, \"aot_inductor.emit_multi_arch_kernel\": false, \"aot_inductor.enable_lto\": false, \"aot_inductor.filtered_kernel_names\": null, \"aot_inductor.force_mmap_weights\": false, \"aot_inductor.metadata\": {}, \"aot_inductor.model_name_for_generated_files\": null, \"aot_inductor.output_path\": \"\", \"aot_inductor.package\": false, \"aot_inductor.package_constants_in_so\": true, \"aot_inductor.package_constants_on_disk\": false, \"aot_inductor.package_cpp_only\": null, \"aot_inductor.precompile_headers\": true, \"aot_inductor.presets\": {}, \"aot_inductor.raise_error_on_ignored_optimization\": true, \"aot_inductor.repro_level\": 2, \"aot_inductor.serialized_in_spec\": \"\", \"aot_inductor.serialized_out_spec\": \"\", \"aot_inductor.use_consts_asm_build\": true, \"aot_inductor.use_minimal_arrayref_interface\": false, \"aot_inductor.use_runtime_constant_folding\": false, \"aot_inductor.weight_use_caching_allocator\": false, \"assert_indirect_indexing\": true, \"assume_aligned_inputs\": false, \"assume_unaligned_fallback_output\": false, \"autoheuristic_collect\": \"\", \"autoheuristic_log_path\": \"DEFAULT\", \"autoheuristic_use\": \"mixed_mm\", \"autotune_fallback_to_aten\": false, \"autotune_in_subproc\": false, \"autotune_local_cache\": true, \"autotune_lookup_table\": {}, \"autotune_multi_device\": false, \"autotune_num_choices_displayed\": 10, \"autotune_remote_cache\": null, \"b2b_gemm_pass\": false, \"batch_fusion\": true, \"benchmark_combo_kernel\": false, \"benchmark_epilogue_fusion\": true, \"benchmark_fusion\": false, \"benchmark_harness\": true, \"benchmark_kernel\": false, \"bfloat16_atomic_adds_enabled\": true, \"bucket_all_gathers_fx\": \"none\", \"bucket_all_gathers_fx_bucket_size_determinator\": null, \"bucket_reduce_scatters_fx\": \"none\", \"bucket_reduce_scatters_fx_bucket_size_determinator\": null, \"bundle_triton_into_fx_graph_cache\": true, \"bundled_autotune_remote_cache\": null, \"bw_outputs_user_visible\": true, \"can_inplace_pad_graph_input\": false, \"check_stack_no_cycles_TESTING_ONLY\": false, \"combo_kernel_allow_mixed_sizes\": 1, \"combo_kernel_foreach_dynamic_shapes\": true, \"combo_kernels\": false, \"combo_kernels_autotune\": 1, \"comment_origin\": false, \"compile_threads\": 32, \"comprehensive_padding\": true, \"compute_all_bounds\": false, \"constant_and_index_propagation\": true, \"conv_1x1_as_mm\": false, \"coordinate_descent_check_all_directions\": false, \"coordinate_descent_search_radius\": 1, \"coordinate_descent_tuning\": false, \"cpp.cxx\": [null, \"g++\"], \"cpp.descriptive_names\": \"original_aten\", \"cpp.dynamic_threads\": false, \"cpp.enable_concat_linear\": false, \"cpp.enable_floating_point_contract_flag\": \"off\", \"cpp.enable_grouped_gemm_template\": false, \"cpp.enable_kernel_profile\": false, \"cpp.enable_loop_tail_vec\": true, \"cpp.enable_tiling_heuristics\": true, \"cpp.enable_unsafe_math_opt_flag\": false, \"cpp.fallback_scatter_reduce_sum\": true, \"cpp.force_inline_kernel\": false, \"cpp.gemm_cache_blocking\": null, \"cpp.gemm_max_k_slices\": 1, \"cpp.gemm_thread_factors\": null, \"cpp.inject_log1p_bug_TESTING_ONLY\": null, \"cpp.inject_relu_bug_TESTING_ONLY\": null, \"cpp.max_horizontal_fusion_size\": 16, \"cpp.min_chunk_size\": 512, \"cpp.no_redundant_loops\": true, \"cpp.simdlen\": null, \"cpp.threads\": -1, \"cpp.use_decompose_tanh\": false, \"cpp.use_small_dequant_buffer\": false, \"cpp.vec_isa_ok\": null, \"cpp.weight_prepack\": true, \"cpp_cache_precompile_headers\": true, \"cpp_wrapper\": false, \"cpp_wrapper_build_separate\": false, \"cpu_backend\": \"cpp\", \"cuda.arch\": null, \"cuda.binary_remote_cache_force_write\": false, \"cuda.compile_opt_level\": \"-O1\", \"cuda.cuda_cxx\": null, \"cuda.cutlass_backend_min_gemm_size\": 1, \"cuda.cutlass_dir\": \"/home/skarjala/pytorch/third_party/cutlass\", \"cuda.cutlass_enabled_ops\": \"all\", \"cuda.cutlass_epilogue_fusion_enabled\": false, \"cuda.cutlass_hash_with_compile_cmd\": false, \"cuda.cutlass_instantiation_level\": \"0\", \"cuda.cutlass_max_profiling_configs\": null, \"cuda.cutlass_max_profiling_swizzle_options\": [1, 2, 4, 8], \"cuda.cutlass_op_allowlist_regex\": null, \"cuda.cutlass_op_denylist_regex\": null, \"cuda.cutlass_prescreening\": true, \"cuda.cutlass_presets\": null, \"cuda.cutlass_tma_only\": false, \"cuda.enable_caching_codegen\": true, \"cuda.enable_cuda_lto\": false, \"cuda.enable_debug_info\": false, \"cuda.enable_ptxas_info\": false, \"cuda.generate_test_runner\": false, \"cuda.upload_to_binary_remote_cache\": false, \"cuda.use_binary_remote_cache\": true, \"cuda.use_fast_math\": false, \"cuda.version\": null, \"cuda_backend\": \"triton\", \"dce\": false, \"debug\": false, \"debug_fusion\": false, \"debug_index_asserts\": false, \"debug_ir_traceback\": false, \"decompose_mem_bound_mm\": false, \"developer_warnings\": true, \"disable_cpp_codegen\": false, \"disable_padding_cpu\": true, \"disable_progress\": true, \"dynamic_scale_rblock\": true, \"efficient_conv_bn_eval_fx_passes\": false, \"emulate_precision_casts\": false, \"enable_auto_functionalized_v2\": true, \"enable_caching_generated_triton_templates\": true, \"enable_linear_binary_folding\": false, \"enabled_metric_tables\": \"\", \"epilogue_fusion\": true, \"epilogue_fusion_first\": false, \"estimate_op_runtime\": \"default\", \"external_matmul\": [], \"fallback_random\": false, \"force_fuse_int_mm_with_mul\": false, \"force_layout_optimization\": false, \"force_pointwise_cat\": false, \"force_same_precision\": false, \"force_shape_pad\": false, \"freezing\": false, \"freezing_discard_parameters\": false, \"fx_graph_cache\": true, \"fx_graph_remote_cache\": null, \"fx_passes_numeric_check\": {\"num_iterations\": 1, \"pre_grad\": false, \"precision\": 0.0001, \"requires_optimizer\": true}, \"generate_intermediate_hooks\": false, \"global_cache_dir\": null, \"graph_partition\": false, \"group_fusion\": false, \"halide.asserts\": false, \"halide.cpu_target\": \"host\", \"halide.debug\": false, \"halide.gpu_target\": \"host-cuda\", \"halide.scan_kernels\": false, \"halide.scheduler_cpu\": \"Adams2019\", \"halide.scheduler_cuda\": \"Anderson2021\", \"implicit_fallbacks\": true, \"inplace_buffers\": true, \"inplace_padding\": true, \"inter_node_bw\": 25, \"intra_node_bw\": 300, \"is_nightly_or_source\": true, \"is_predispatch\": false, \"joint_custom_post_pass\": null, \"joint_custom_pre_pass\": null, \"joint_graph_constant_folding\": true, \"keep_output_stride\": true, \"kernel_name_max_ops\": 10, \"layout_opt_default\": \"1\", \"layout_optimization\": true, \"loop_ordering_after_fusion\": false, \"max_autotune\": false, \"max_autotune_conv_backends\": \"ATEN,TRITON\", \"max_autotune_flex_search_space\": \"DEFAULT\", \"max_autotune_gemm\": false, \"max_autotune_gemm_backends\": \"ATEN,TRITON,CPP\", \"max_autotune_gemm_search_space\": \"DEFAULT\", \"max_autotune_pointwise\": false, \"max_autotune_report_choices_stats\": true, \"max_autotune_subproc_graceful_timeout_seconds\": 0.0, \"max_autotune_subproc_result_timeout_seconds\": 60.0, \"max_autotune_subproc_terminate_timeout_seconds\": 0.0, \"max_epilogue_benchmarked_choices\": 1, \"max_fusion_buffer_group_pairwise_attempts\": 64, \"max_fusion_size\": 64, \"max_pointwise_cat_inputs\": 8, \"memory_planning\": false, \"memory_pool\": \"intermediates\", \"min_num_split\": 0, \"mixed_mm_choice\": \"heuristic\", \"multi_kernel_hints\": [], \"nan_asserts\": false, \"non_blocking_remote_cache_write\": true, \"online_softmax\": true, \"optimize_scatter_upon_const_tensor\": true, \"pad_channels_last\": false, \"pad_outputs\": false, \"padding_alignment_bytes\": 128, \"padding_stride_threshold\": 1024, \"pattern_matcher\": true, \"permute_fusion\": false, \"pick_loop_orders\": true, \"post_grad_custom_post_pass\": null, \"post_grad_custom_pre_pass\": null, \"post_grad_fusion_options\": {}, \"pre_grad_custom_pass\": null, \"pre_grad_fusion_options\": {}, \"precompilation_timeout_seconds\": 3600, \"profile_bandwidth\": false, \"profile_bandwidth_output\": null, \"profile_bandwidth_regex\": \"\", \"profile_bandwidth_with_do_bench_using_profiling\": false, \"profiler_mark_wrapper_call\": false, \"prologue_fusion\": true, \"quiesce_async_compile_pool\": false, \"realize_acc_reads_size_threshold\": null, \"realize_acc_reads_threshold\": 8, \"realize_opcount_threshold\": 30, \"realize_reads_threshold\": 4, \"remove_pre_grad_passes\": null, \"reorder_for_compute_comm_overlap\": false, \"reorder_for_compute_comm_overlap_passes\": [\"reorder_compute_for_overlap\", \"sink_waits\", \"raise_comms\"], \"reorder_for_locality\": true, \"reorder_for_peak_memory\": true, \"reorder_prefetch_limit\": null, \"rocm.arch\": [], \"rocm.ck_dir\": null, \"rocm.ck_max_profiling_configs\": null, \"rocm.ck_supported_arch\": [\"gfx90a\", \"gfx942\", \"gfx950\"], \"rocm.ck_tile_max_profiling_configs\": null, \"rocm.compile_opt_level\": \"-O2\", \"rocm.flush_denormals\": true, \"rocm.generate_test_runner\": false, \"rocm.is_debug\": false, \"rocm.kBatch_sweep\": null, \"rocm.n_max_profiling_configs\": null, \"rocm.print_kernel_resource_usage\": false, \"rocm.rocm_home\": null, \"rocm.save_temps\": false, \"rocm.split_k_threshold\": 16, \"rocm.use_fast_math\": true, \"rocm.use_preselected_instances\": false, \"save_args\": false, \"scalar_asserts\": true, \"score_fusion_memory_threshold\": 10, \"search_autotune_cache\": false, \"shape_padding\": true, \"size_asserts\": true, \"sleep_sec_TESTING_ONLY\": null, \"split_cat_fx_passes\": true, \"split_reductions\": true, \"static_launch_user_defined_triton_kernels\": false, \"static_weight_shapes\": true, \"strict_static_cuda_launcher\": false, \"test_configs.autotune_choice_desc_regex\": null, \"test_configs.autotune_choice_name_regex\": null, \"test_configs.force_extern_kernel_in_multi_template\": false, \"test_configs.graphsafe_rng_func_ignores_fallback_random\": false, \"test_configs.max_mm_configs\": null, \"test_configs.runtime_triton_dtype_assert\": false, \"test_configs.static_cpp_dtype_assert\": false, \"trace.compile_profile\": false, \"trace.debug_dir\": null, \"trace.debug_log\": false, \"trace.dot_graph_shape\": null, \"trace.draw_orig_fx_graph\": false, \"trace.enabled\": true, \"trace.fx_graph\": true, \"trace.fx_graph_transformed\": true, \"trace.graph_diagram\": false, \"trace.info_log\": false, \"trace.ir_post_fusion\": true, \"trace.ir_pre_fusion\": true, \"trace.log_autotuning_results\": false, \"trace.log_url_for_graph_xform\": null, \"trace.output_code\": true, \"trace.provenance_tracking\": true, \"trace.save_real_tensors\": false, \"trace.upload_tar\": null, \"triton.autotune_at_compile_time\": null, \"triton.autotune_cublasLt\": true, \"triton.autotune_pointwise\": true, \"triton.autotune_with_sample_inputs\": false, \"triton.coalesce_tiling_analysis\": true, \"triton.codegen_upcast_to_fp32\": true, \"triton.cooperative_reductions\": false, \"triton.cudagraph_capture_sizes\": null, \"triton.cudagraph_dynamic_shape_warn_limit\": 50, \"triton.cudagraph_skip_dynamic_graphs\": false, \"triton.cudagraph_support_input_mutation\": true, \"triton.cudagraph_trees\": true, \"triton.cudagraph_trees_history_recording\": false, \"triton.cudagraph_unexpected_rerecord_limit\": 128, \"triton.cudagraphs\": false, \"triton.debug_sync_graph\": false, \"triton.debug_sync_kernel\": false, \"triton.decompose_k_threshold\": 32, \"triton.dense_indexing\": false, \"triton.descriptive_names\": \"original_aten\", \"triton.disallow_failing_autotune_kernels_TESTING_ONLY\": false, \"triton.divisible_by_16\": true, \"triton.enable_persistent_tma_matmul\": false, \"triton.fast_path_cudagraph_asserts\": false, \"triton.force_cooperative_reductions\": false, \"triton.force_cudagraph_sync\": false, \"triton.force_cudagraphs_warmup\": false, \"triton.inject_relu_bug_TESTING_ONLY\": null, \"triton.max_tiles\": null, \"triton.min_split_scan_rblock\": 256, \"triton.multi_kernel\": 0, \"triton.num_decompose_k_splits\": 10, \"triton.persistent_reductions\": true, \"triton.prefer_nd_tiling\": false, \"triton.skip_cudagraph_warmup\": false, \"triton.skip_l1_cache\": false, \"triton.slow_path_cudagraph_asserts\": true, \"triton.spill_threshold\": 16, \"triton.store_cubin\": false, \"triton.tile_reductions\": false, \"triton.tiling_prevents_pointwise_fusion\": true, \"triton.tiling_prevents_reduction_fusion\": true, \"triton.unique_kernel_names\": true, \"triton.unique_user_kernel_names\": false, \"triton.use_block_ptr\": false, \"triton.use_tensor_descriptor\": false, \"triton_kernel_default_layout_constraint\": \"needs_fixed_stride_order\", \"unbacked_symint_fallback\": 8192, \"unroll_reductions_threshold\": 8, \"unsafe_ignore_unsupported_triton_autotune_args\": false, \"unsafe_marked_cacheable_functions\": {}, \"unsafe_skip_cache_dynamic_shape_guards\": false, \"use_experimental_benchmarker\": true, \"use_fast_math\": false, \"use_mixed_mm\": true, \"use_static_cuda_launcher\": true, \"verbose_progress\": false, \"warn_mix_layout\": false, \"worker_start_method\": \"subprocess\", \"worker_suppress_logging\": true}", "remote_cache_version": null, "inductor_fx_remote_cache_hit_count": null, "inductor_fx_remote_cache_miss_count": null, "inductor_fx_remote_cache_backend_type": null, "inductor_fx_remote_cache_hit_keys": null, "inductor_fx_remote_cache_miss_keys": null, "cuda_version": "12.4", "triton_version": "3.4.0", "feature_usage": null, "compile_time_autotune_time_us": null, "is_runtime": true, "gc_time_us": null, "tensorify_float_attempt": null, "tensorify_float_success": null, "tensorify_float_failure": null, "guard_latency_us": null, "recompile_reason": null, "num_graph_breaks": null, "triton_kernel_compile_times_us": null, "ir_count": null, "cudagraph_skip_reason": null, "python_version": "3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]", "pgo_put_remote_code_state_time_us": null, "pgo_get_remote_code_state_time_us": null, "param_numel": null, "param_bytes": null, "param_count": null, "recompile_user_contexts": null}, "rank": 3, "frame_id": 0, "frame_compile_id": 0}
V0804 12:34:16.314000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "7c90a21f65537fe33bd4da7786393ffb"}
	{
	"name": "dynamo",
	"ts": 1754336056313939.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.314000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "47c40858947eb348e0dc5db36fb282e9"}
	{
	"name": "entire_frame_compile",
	"ts": 1754336056314332.0,
	"args": {
	"fn_name": "_compile.compile_inner",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.315000 1142858 torch/_dynamo/guards.py:3824] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "7dde321851e25222fcdf3cd24a328e08"}
	[
	"0/0: ___check_obj_id(fn, 139645370122560)                   "
	]
V0804 12:34:16.315000 1142858 torch/_dynamo/convert_frame.py:231] {"dynamo_start": {"stack": [{"line": 191, "name": "<module>", "filename": 1, "loc": "main()"}, {"line": 165, "name": "main", "filename": 1, "loc": "_ = compiled_graph_one(x, y, world_size)"}, {"line": 804, "name": "compile_wrapper", "filename": 2, "loc": "return fn(*args, **kwargs)"}, {"line": 66, "name": "inner", "filename": 3}]}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.315000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "d30538d5b5348faacbd331f749954da1"}
	{
	"name": "compile_attempt_0",
	"ts": 1754336056315927.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.317000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "d366bef3b9e6e50ef36d2283ae9dd85c"}
	{
	"name": "bytecode_tracing",
	"ts": 1754336056317708.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.325000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 0, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.326000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1024, 1], "storage": 0, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0275d78370>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.326000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 0, "source": "L['fn'].__self__._modules['lin1']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.328000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 1, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.329000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "stride": [1024, 1], "storage": 1, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Tensor object at 0x7f02578e68a0>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.329000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 1, "source": "L['args'][0]"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.337000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 2, "describer_id": 7, "size": 2048}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.338000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 2, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0276252c60>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.338000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 3, "source": "L['fn'].__self__._modules['norm']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.340000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 3, "describer_id": 7, "size": 2048}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.340000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 3, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f02762520d0>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.341000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 4, "source": "L['fn'].__self__._modules['norm']._parameters['bias']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.363000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 4, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.363000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 15, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1024, 1], "storage": 4, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0276250c80>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.364000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 15, "source": "L['fn'].__self__._modules['lin2']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.373000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 5, "describer_id": 7, "size": 4194304}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.373000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 19, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [2048, 1024], "is_leaf": true, "stride": [1024, 1], "storage": 5, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Tensor object at 0x7f0276250690>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.374000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 19, "source": "L['args'][1]"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:16.380000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5280f2dfd9df0aa55464b0bd925840f8"}
	{
	"name": "bytecode_tracing",
	"ts": 1754336056380758.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.385000 1142858 torch/_dynamo/output_graph.py:1686] {"dynamo_output_graph": {"sizes": {"l_fn_self_modules_lin1_parameters_weight_": [1024, 1024], "l_args_0_": [1024, 1024], "l_fn_self_modules_norm_parameters_weight_": [1024], "l_fn_self_modules_norm_parameters_bias_": [1024], "l_fn_self_modules_lin2_parameters_weight_": [1024, 1024], "l_args_1_": [2048, 1024], "h": [1024, 1024], "h_1": [1024, 1024], "h_2": [1024, 1024], "all_reduce_default": [1024, 1024], "h_3": [1024, 1024], "h2": [1024, 1024], "h2_1": [1024, 1024], "all_gather_into_tensor_default": [2048, 1024], "gathered": [2048, 1024], "g": [2048, 1024], "reduce_scatter_tensor_default": [1024, 1024], "rs": [1024, 1024], "rs_expanded": [2048, 1024], "out": [2048, 1024]}}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "a887576c59d8b651fcb075634b10ab10"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
V0804 12:34:16.386000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "2be60ddb9bc5333c2c380c178be9bbaa"}
	{
	"name": "backend_compile",
	"ts": 1754336056386431.8,
	"args": {
	"fn_name": "OutputGraph.call_user_compiler",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.388000 1142858 torch/_inductor/compile_fx.py:2185] {"artifact": {"name": "before_pre_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "9f30354df593b94d410ba0c8b868cf1d"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
	
	 # graph id: 139645242301984
V0804 12:34:16.388000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "9f6e9cb61b8237dce327a717ec937586"}
	{
	"name": "_recursive_pre_grad_passes",
	"ts": 1754336056388510.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.389000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "0d1b28d37d9e0bbbc36cc9e003a76368"}
	{
	"name": "_recursive_pre_grad_passes",
	"ts": 1754336056389709.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.391000 1142858 torch/_inductor/compile_fx.py:2216] {"artifact": {"name": "after_pre_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "9f30354df593b94d410ba0c8b868cf1d"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
	
	 # graph id: 139645242301984
V0804 12:34:16.406000 1142858 torch/_dynamo/utils.py:1970] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "9a6a23ab58ab474257f3a4e893130f53"}
	{
	"name": "autograd_cache_miss",
	"ts": 1754336056406148.5,
	"args": {
	"cache_status_detailed": "full_miss",
	"key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp",
	"cache_state": "miss",
	"components": [
	"[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False",
	"[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>",
	"[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])",
	"[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"compile_id": "0/1"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0804 12:34:16.407000 1142858 torch/_functorch/_aot_autograd/autograd_cache.py:1231] {"artifact": {"name": "aotautograd_cache_miss", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "788d107aba066052e238c3a6e11503b1"}
	{"cache_status_detailed": "full_miss", "key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp", "cache_state": "miss", "components": ["[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False", "[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>", "[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])", "[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ", "[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)", "[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>", "[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}", "[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}", "[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False", "[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10", "[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True", "[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']", "[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None", "[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op", "[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait", "[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"], "compile_id": "0/1"}
V0804 12:34:16.408000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "2672a8794196028615a8c5dc0cd4545d"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1754336056408019.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.411000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "37dbf44617e2cc9cf4cb8f87dcd2168b"}
	{
	"name": "aot_collect_metadata",
	"ts": 1754336056411498.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.430000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "b4dd7b13c294c54c6c350813d71e311f"}
	{
	"name": "aot_collect_metadata",
	"ts": 1754336056430062.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.489000 1142858 torch/_functorch/_aot_autograd/graph_capture.py:301] {"artifact": {"name": "aot_forward_graph_fw_metadata", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "083ebbd57ef41f8da24878484b104f67"}
	ViewAndMutationMeta(input_info=[InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=False,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=False,
	                                              keep_input_mutations=True)],
	                    output_info=[OutputAliasInfo(output_type=<OutputType.non_alias: 1>,
	                                                raw_type=<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,
	                                                base_idx=None,
	                                                dynamic_dims=set(),
	                                                requires_grad=False,
	                                                functional_tensor=None)],
	                    num_intermediate_bases=0,
	                    keep_input_mutations=True,
	                    traced_tangents=[],
	                    traced_tangents_descs=[],
	                    subclass_inp_meta=[PlainTensorMeta(unwrapped_idx=0,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=1,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=2,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=3,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=4,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=5,
	                                                      memory_format=None)],
	                    subclass_fw_graph_out_meta=[PlainTensorMeta(unwrapped_idx=0,
	                                                               memory_format=None)],
	                    subclass_tangent_meta=[],
	                    is_train=False,
	                    traced_tangent_metas=None,
	                    num_symints_saved_for_bw=None,
	                    grad_enabled_mutation=None,
	                    deterministic=False,
	                    static_input_indices=[0, 2, 3, 4],
	                    tokens={},
	                    indices_of_inputs_that_requires_grad_with_mutations_in_bw=[],
	                    bw_donated_idxs=None,
	                    num_backward_tokens=0,
	                    num_graphsafe_rng_states=0,
	                    graphsafe_rng_state_index=None)
V0804 12:34:16.491000 1142858 torch/_functorch/_aot_autograd/graph_capture.py:319] {"aot_inference_graph": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "11e47da400b78de48aca98e293efdee2"}
	class <lambda>(torch.nn.Module):
	    def forward(
	        self,
	        arg0_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=0)
	        arg1_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=1)
	        arg2_1: "f16[1024][1]cuda:1",  # PlainAOTInput(idx=2)
	        arg3_1: "f16[1024][1]cuda:1",  # PlainAOTInput(idx=3)
	        arg4_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=4)
	        arg5_1: "f16[2048, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=5)
	    ):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        convert_element_type_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul_2, torch.float16);  mul_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        convert_element_type_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(convert_element_type_3, torch.float32);  convert_element_type_3 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_4, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(convert_element_type_4, getitem_1);  convert_element_type_4 = getitem_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (
	            add_3,  # PlainAOTOutput(idx=0)
	        )
	        
V0804 12:34:16.494000 1142858 torch/_functorch/_aot_autograd/graph_compile.py:285] {"artifact": {"name": "torch._functorch.config", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "7b8fae87b220765c393a4321db77304b"}
	{
	"TYPE_CHECKING": false,
	"functionalize_rng_ops": false,
	"fake_tensor_allow_meta": true,
	"debug_assert": false,
	"debug_partitioner": true,
	"decompose_custom_triton_ops": true,
	"static_weight_shapes": true,
	"treat_parameters_as_free_to_save": true,
	"cse": true,
	"enable_autograd_cache": true,
	"autograd_cache_allow_custom_autograd_functions": false,
	"bundled_autograd_cache": false,
	"autograd_cache_normalize_inputs": true,
	"enable_remote_autograd_cache": null,
	"view_replay_for_aliased_outputs": true,
	"max_dist_from_bw": 1000,
	"ban_recompute_used_far_apart": true,
	"ban_recompute_long_fusible_chains": true,
	"ban_recompute_materialized_backward": true,
	"ban_recompute_not_in_allowlist": true,
	"ban_recompute_reductions": true,
	"recompute_views": false,
	"activation_memory_budget": 1.0,
	"activation_memory_budget_runtime_estimator": "flops",
	"activation_memory_budget_solver": "dp",
	"visualize_memory_budget_pareto": false,
	"memory_budget_pareto_dir": null,
	"aggressive_recomputation": false,
	"fake_tensor_allow_unsafe_data_ptr_access": true,
	"unlift_effect_tokens": true,
	"custom_op_default_layout_constraint": "needs_exact_strides",
	"fake_tensor_crossref": false,
	"fake_tensor_propagate_real_tensors": false,
	"backward_pass_autocast": "same_as_forward",
	"donated_buffer": true,
	"torch_compile_graph_format": "svg",
	"generate_fake_kernels_from_real_mismatches": false,
	"graphsafe_rng_functionalization": true,
	"strict_autograd_cache": false,
	"unsafe_allow_optimization_of_collectives": false,
	"disable_guess_zero_tangent_for_mutated_input_subclass": false,
	"guess_tangent_strides_as_outputs": false,
	"_sync_decision_cross_ranks": false,
	"saved_tensors_hooks_filtering_mode": "donated"
	}
V0804 12:34:16.494000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "90d6ee195e45d620693546d5a31f80d7"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1754336056494891.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.495000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "a745cad32948a652f398e9732e150a31"}
	{
	"name": "_recursive_joint_graph_passes",
	"ts": 1754336056495829.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.499000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "0375ea534b3c7296346d7d52154cb3e0"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056499276.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.499000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5ff2046b3b8de35076afe914b1ad0582"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056499864.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.500000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "a4c9e1e03b6b998c7524a61aa4d56d98"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056500562.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.501000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "78f3cf7069e6fafb287e6822cc6054be"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056501055.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.502000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "870b6872e1d05e7fc333bf822a90f062"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056502713.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.503000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "2162fddf032e66b24405540862f234d7"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056503290.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.504000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "623f6ee68cae3e526ccdccbe048ac375"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056503946.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.504000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "6c436b15a2c5c82cedf0ab24a18c5a94"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056504654.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.506000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "d524e3c70c61cd1422f2543f01744d21"}
	{
	"name": "_recursive_joint_graph_passes",
	"ts": 1754336056506002.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.506000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "aa3d7f9f3a5df299acc578e9c36d5736"}
	{
	"name": "inductor_compile",
	"ts": 1754336056506517.2,
	"args": {
	"fn_name": "compile_fx_inner",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.508000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "17532b2e7096e364ab2621f72faf8e2b"}
	{
	"name": "fx_codegen_and_compile",
	"ts": 1754336056508161.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.521000 1142858 torch/_inductor/compile_fx.py:1218] {"artifact": {"name": "fx_graph_runnable", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "c8dffcf090b13a05ef569d7c2e98e0ff"}
	
	import os
	os.environ['TORCH_TRACE'] = '1'
	os.environ['TORCHELASTIC_RESTART_COUNT'] = '0'
	os.environ['TORCHELASTIC_MAX_RESTARTS'] = '0'
	os.environ['TORCHELASTIC_RUN_ID'] = 'none'
	os.environ['TORCHELASTIC_USE_AGENT_STORE'] = 'True'
	os.environ['TORCH_NCCL_ASYNC_ERROR_HANDLING'] = '1'
	os.environ['TORCHELASTIC_ERROR_FILE'] = '/tmp/torchelastic_krot7efo/none_58jhr50i/attempt_0/1/error.json'
	os.environ['TORCH_COMPILE_DEBUG'] = '1'
	os.environ['TORCH_LOGS_FORMAT'] = '[%(filename)s:%(lineno)d %(levelname)s] %(message)s'
	os.environ['TORCH_LOGS_OUT'] = '/dev/stdout'
	os.environ['TORCHINDUCTOR_CACHE_DIR'] = '/tmp/torchinductor_cache'
	os.environ['TRITON_CACHE_DIR'] = '/tmp/torchinductor_cache/triton/1'
	
	import torch
	from torch import tensor, device
	import torch.fx as fx
	from torch._dynamo.testing import rand_strided
	from math import inf
	import torch._inductor.inductor_prims
	import torch.distributed as dist
	from torch.testing._internal.distributed.fake_pg import FakeStore
	
	import torch._dynamo.config
	import torch._inductor.config
	import torch._functorch.config
	import torch.fx.experimental._config
	
	torch._inductor.config.triton.store_cubin = False
	torch._inductor.config.trace.enabled = True
	torch._inductor.config.trace.save_real_tensors = False
	torch._functorch.config.functionalize_rng_ops = False
	torch._functorch.config.debug_partitioner = True
	torch._functorch.config.fake_tensor_allow_unsafe_data_ptr_access = True
	torch._functorch.config.unlift_effect_tokens = True
	
	
	
	isolate_fails_code_str = None
	
	
	
	
	# torch version: 2.9.0a0+git2249284
	# torch cuda version: 12.4
	# torch git version: 22492848b66f13637b01a4d8f98a16e3004940a9
	
	
	# CUDA Info: 
	# nvcc: NVIDIA (R) Cuda compiler driver 
	# Copyright (c) 2005-2024 NVIDIA Corporation 
	# Built on Thu_Mar_28_02:18:24_PDT_2024 
	# Cuda compilation tools, release 12.4, V12.4.131 
	# Build cuda_12.4.r12.4/compiler.34097967_0 
	
	# GPU Hardware Info: 
	# NVIDIA PG509-210 : 2 
	
	
	from torch.nn import *
	class Repro(torch.nn.Module):
	    def __init__(self) -> None:
	        super().__init__()
	
	    
	    
	    def forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):
	        permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)
	        getitem = var_mean[0]
	        getitem_1 = var_mean[1];  var_mean = None
	        add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None
	        mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
	def load_args(reader):
	    buf0 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf0, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg0_1
	    buf1 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf1, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg1_1
	    buf2 = reader.storage(None, 2048, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf2, (1024,), dtype=torch.float16, is_leaf=True)  # arg2_1
	    buf3 = reader.storage(None, 2048, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf3, (1024,), dtype=torch.float16, is_leaf=True)  # arg3_1
	    buf4 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf4, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg4_1
	    buf5 = reader.storage(None, 4194304, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf5, (2048, 1024), dtype=torch.float16, is_leaf=True)  # arg5_1
	load_args._version = 0
	mod = Repro()
	if __name__ == '__main__':
	    from torch._dynamo.repro.after_aot import run_repro
	    # Initialize FakeProcessGroup for distributed operations
	    store = FakeStore()
	    dist.init_process_group(
	        backend="fake",
	        rank=0,
	        world_size=2,
	        store=store
	    )
	    with torch.no_grad():
	        run_repro(mod, load_args, accuracy=False, command='run', save_dir=None, tracing_mode='real', check_str=None)
	        # To run it separately, do 
	        # mod, args = run_repro(mod, load_args, accuracy=False, command='get_args', save_dir=None, tracing_mode='real', check_str=None)
	        # mod(*args)
	    dist.destroy_process_group()
	
V0804 12:34:16.525000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "890cf167d834bdb0fd317483764155dd"}
	{
	"name": "additional_fake_tensor_prop",
	"ts": 1754336056525165.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.541000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "d5b6e6d2824fe175227f4f7635f712d4"}
	{
	"name": "additional_fake_tensor_prop",
	"ts": 1754336056541768.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.544000 1142858 torch/_inductor/compile_fx.py:1267] {"artifact": {"name": "before_post_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "97a46234dae257bf8fd40d911b84825f"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f16[1024, 1024][1024, 1]cuda:1", arg1_1: "f16[1024, 1024][1024, 1]cuda:1", arg2_1: "f16[1024][1]cuda:1", arg3_1: "f16[1024][1]cuda:1", arg4_1: "f16[1024, 1024][1024, 1]cuda:1", arg5_1: "f16[2048, 1024][1024, 1]cuda:1"):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        convert_element_type_default: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
V0804 12:34:16.544000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "138b38f013feea2c2810d94ad007029a"}
	{
	"name": "_recursive_post_grad_passes",
	"ts": 1754336056544536.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.551000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "831c49aa2f1d0d302e85378c26b2a1ba"}
	{
	"name": "_recursive_post_grad_passes",
	"ts": 1754336056551269.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.554000 1142858 torch/_inductor/compile_fx.py:1305] {"artifact": {"name": "after_post_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "ed435d7c02e74345e0a9c2504ca76b90"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f16[1024, 1024][1024, 1]cuda:1", arg1_1: "f16[1024, 1024][1024, 1]cuda:1", arg2_1: "f16[1024][1]cuda:1", arg3_1: "f16[1024][1]cuda:1", arg4_1: "f16[1024, 1024][1024, 1]cuda:1", arg5_1: "f16[2048, 1024][1024, 1]cuda:1"):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        var_mean = torch.ops.aten.var_mean.correction(mul_2, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(mul_2, getitem_1);  mul_2 = getitem_1 = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce_.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
V0804 12:34:16.555000 1142858 torch/_inductor/compile_fx.py:1317] {"artifact": {"name": "inductor_post_to_pre_grad_nodes", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5385faa7da9add5b8aed080ce40f0a99"}
	{"permute": [{"name": "h", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm": [{"name": "h", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_2": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "erf": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default", "target": "prims.convert_element_type.default", "graph_id": 139644951478880, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_4", "target": "prims.convert_element_type.default", "graph_id": 139644951478880, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}], "var_mean": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_1": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_3": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_4": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_5": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "all_reduce": [{"name": "all_reduce_default", "target": "_c10d_functional.all_reduce.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor": [{"name": "h_3", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_1": [{"name": "h2", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_1": [{"name": "h2", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "relu": [{"name": "h2_1", "target": "<function relu at 0x7f01fe16da80>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "all_gather_into_tensor": [{"name": "all_gather_into_tensor_default", "target": "_c10d_functional.all_gather_into_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "reduce_scatter_tensor": [{"name": "reduce_scatter_tensor_default", "target": "_c10d_functional.reduce_scatter_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor_1": [{"name": "gathered", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_5": [{"name": "g", "target": "<built-in function mul>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor_2": [{"name": "rs", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "repeat": [{"name": "rs_expanded", "target": "repeat", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3": [{"name": "out", "target": "<built-in function add>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}
V0804 12:34:16.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "f75821924e9c2353b4f3946eb6d366e4"}
	{
	"name": "GraphLowering.run",
	"ts": 1754336056556702.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.609000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5d5a2e0aa081fdb84e1a9f7dcc0b0de4"}
	{
	"name": "GraphLowering.run",
	"ts": 1754336056609207.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.609000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "707c9051d9f97b6d7cd849b21b3d3fc7"}
	{
	"name": "GraphLowering.compile_to_fn",
	"ts": 1754336056609873.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.610000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5da1bf862b530ce7c88172e7faecf15c"}
	{
	"name": "code_gen",
	"ts": 1754336056610300.5,
	"args": {
	"fn_name": "GraphLowering.compile_to_module",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.610000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "54f75962f2756f3767b9eca10b5d9572"}
	{
	"name": "GraphLowering.codegen",
	"ts": 1754336056610684.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.612000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "cac084576df4ba9a7be6fb75151dfe66"}
	{
	"name": "Scheduler.__init__",
	"ts": 1754336056611882.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "446e4d8da5f2286816636dc91a4f1bc4"}
	{
	"name": "Scheduler.fused_nodes",
	"ts": 1754336056685976.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.691000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "ebb17982755a3bdc3fcad80ac6e602d7"}
	{
	"name": "Scheduler.fused_nodes",
	"ts": 1754336056691301.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.709000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "a0caa68cff431e5beac07b0edf24a84d"}
	{
	"name": "Scheduler.__init__",
	"ts": 1754336056709536.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.710000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "313d0d26537e0a05ef7d76bb2de559a4"}
	{
	"name": "Scheduler.codegen",
	"ts": 1754336056709973.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.789000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "6fcfa50a2cd6a4efe8f8743fb05ecb52"}
	{
	"name": "Scheduler.codegen",
	"ts": 1754336056789863.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.790000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "f5204ac80a5d2e97475762d96f156661"}
	{
	"name": "PythonWrapperCodegen.generate",
	"ts": 1754336056790474.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.797000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "4f5733ae18760680d73c9df46e2033c5"}
	{
	"name": "PythonWrapperCodegen.generate",
	"ts": 1754336056797837.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.798000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "c533d8799308abcb9db51d192da55f1a"}
	{
	"name": "GraphLowering.codegen",
	"ts": 1754336056798311.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.799000 1142858 torch/_inductor/graph.py:2390] {"inductor_output_code": {"filename": "/tmp/torchinductor_cache/2o/c2o2b5knsvinu3iyv2ufo3zaumqmodn4ad2mi47uizpf6he7ropv.py"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "3e05e0147dcb3f5d92e520c435f93996"}
	# AOT ID: ['1_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from cmath import nanj
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	import triton
	import triton.language as tl
	from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
	from torch._C import _cuda_getCurrentRawStream as get_raw_stream
	from torch._C import _cuda_getCurrentRawStream as get_raw_stream
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	assert_alignment = torch._C._dynamo.guards.assert_alignment
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
	
	
	# kernel path: /tmp/torchinductor_cache/y5/cy5cpjsbzjqu5acybwozmucja7k3xuwvs6mwcifuppxwyfxv2xcf.py
	# Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	# Source node to ATen node mapping:
	#   all_reduce_default => all_reduce
	#   h_1 => add, convert_element_type_2, erf, mul, mul_1, mul_2
	#   h_2 => add_1, add_2, convert_element_type_5, mul_3, mul_4, rsqrt, sub, var_mean
	# Graph fragment:
	#   %mm : Tensor "f16[1024, 1024][1024, 1]cuda:1" = PlaceHolder[target=mm]
	#   %getitem_1 : Tensor "f32[1024, 1][1, 1024]cuda:1" = PlaceHolder[target=getitem_1]
	#   %buf2 : Tensor "f32[1024, 1][1, 1024]cuda:1" = PlaceHolder[target=buf2]
	#   %arg2_1 : Tensor "f16[1024][1]cuda:1" = PlaceHolder[target=arg2_1]
	#   %arg3_1 : Tensor "f16[1024][1]cuda:1" = PlaceHolder[target=arg3_1]
	#   %convert_element_type_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=2] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%mm, torch.float32), kwargs = {})
	#   %mul : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 0.5), kwargs = {})
	#   %mul_1 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 0.7071067811865476), kwargs = {})
	#   %erf : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_1,), kwargs = {})
	#   %add : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf, 1), kwargs = {})
	#   %mul_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul, %add), kwargs = {})
	#   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%mul_2, [1]), kwargs = {correction: 0, keepdim: True})
	#   %sub : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2, %getitem_1), kwargs = {})
	#   %add_1 : Tensor "f32[1024, 1][1, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem, 1e-05), kwargs = {})
	#   %rsqrt : Tensor "f32[1024, 1][1, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1,), kwargs = {})
	#   %mul_3 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, %rsqrt), kwargs = {})
	#   %mul_4 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3, %arg2_1), kwargs = {})
	#   %add_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_4, %arg3_1), kwargs = {})
	#   %convert_element_type_5 : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%add_2, torch.float16), kwargs = {})
	#   %all_reduce : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops._c10d_functional.all_reduce_.default](args = (%convert_element_type_5, sum, 0), kwargs = {})
	#   return %getitem_1,%buf2,%wait_tensor
	triton_per_fused_all_reduce_gelu_native_layer_norm_0 = async_compile.triton('triton_per_fused_all_reduce_gelu_native_layer_norm_0', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.persistent_reduction(
	    size_hints={'x': 1024, 'r0_': 1024},
	    reduction_hint=ReductionHint.INNER,
	    filename=__file__,
	    triton_meta={'signature': {'in_out_ptr0': '*fp16', 'in_ptr0': '*fp16', 'in_ptr1': '*fp16', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': True, 'num_load': 3, 'num_reduction': 4, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 0, 'r0_': 6295552}}
	)
	@triton.jit
	def triton_per_fused_all_reduce_gelu_native_layer_norm_0(in_out_ptr0, in_ptr0, in_ptr1, xnumel, r0_numel):
	    xnumel = 1024
	    XBLOCK: tl.constexpr = 1
	    r0_numel = 1024
	    R0_BLOCK: tl.constexpr = 1024
	    rnumel = r0_numel
	    RBLOCK: tl.constexpr = R0_BLOCK
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = tl.full([1], xoffset, tl.int32)
	    xmask = tl.full([R0_BLOCK], True, tl.int1)
	    r0_index = tl.arange(0, R0_BLOCK)[:]
	    r0_offset = 0
	    r0_mask = tl.full([R0_BLOCK], True, tl.int1)
	    roffset = r0_offset
	    rindex = r0_index
	    r0_1 = r0_index
	    x0 = xindex
	    tmp0 = tl.load(in_out_ptr0 + (r0_1 + 1024*x0), None).to(tl.float32)
	    tmp30 = tl.load(in_ptr0 + (r0_1), None, eviction_policy='evict_last').to(tl.float32)
	    tmp33 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last').to(tl.float32)
	    tmp1 = tmp0.to(tl.float32)
	    tmp2 = 0.5
	    tmp3 = tmp1 * tmp2
	    tmp4 = 0.7071067811865476
	    tmp5 = tmp1 * tmp4
	    tmp6 = libdevice.erf(tmp5)
	    tmp7 = 1.0
	    tmp8 = tmp6 + tmp7
	    tmp9 = tmp3 * tmp8
	    tmp10 = tl.broadcast_to(tmp9, [R0_BLOCK])
	    tmp12 = tl.broadcast_to(tmp10, [R0_BLOCK])
	    tmp14 = triton_helpers.promote_to_tensor(tl.sum(tmp12, 0))
	    tmp15 = tl.full([1], 1024, tl.int32)
	    tmp16 = tmp15.to(tl.float32)
	    tmp17 = (tmp14 / tmp16)
	    tmp18 = tmp10 - tmp17
	    tmp19 = tmp18 * tmp18
	    tmp20 = tl.broadcast_to(tmp19, [R0_BLOCK])
	    tmp22 = triton_helpers.promote_to_tensor(tl.sum(tmp20, 0))
	    tmp23 = tmp9 - tmp17
	    tmp24 = 1024.0
	    tmp25 = (tmp22 / tmp24)
	    tmp26 = 1e-05
	    tmp27 = tmp25 + tmp26
	    tmp28 = libdevice.rsqrt(tmp27)
	    tmp29 = tmp23 * tmp28
	    tmp31 = tmp30.to(tl.float32)
	    tmp32 = tmp29 * tmp31
	    tmp34 = tmp33.to(tl.float32)
	    tmp35 = tmp32 + tmp34
	    tmp36 = tmp35.to(tl.float32)
	    tl.store(in_out_ptr0 + (r0_1 + 1024*x0), tmp36, None)
	''', device_str='cuda')
	
	
	# kernel path: /tmp/torchinductor_cache/au/caue5kfnaqefl7zlwh5ro3lh64raqnztcacwv7es3k55dzeyjtqa.py
	# Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	# Source node to ATen node mapping:
	#   all_gather_into_tensor_default => all_gather_into_tensor
	#   h2_1 => relu
	# Graph fragment:
	#   %mm_1 : Tensor "f16[1024, 1024][1024, 1]cuda:1" = PlaceHolder[target=mm_1]
	#   %relu : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%mm_1,), kwargs = {})
	#   %all_gather_into_tensor : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%relu, 2, 0), kwargs = {})
	#   return %buf10
	triton_poi_fused_all_gather_into_tensor_relu_1 = async_compile.triton('triton_poi_fused_all_gather_into_tensor_relu_1', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.pointwise(
	    size_hints={'x': 1048576}, 
	    filename=__file__,
	    triton_meta={'signature': {'in_out_ptr0': '*fp16', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_all_gather_into_tensor_relu_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 6291456}},
	    min_elem_per_thread=0
	)
	@triton.jit
	def triton_poi_fused_all_gather_into_tensor_relu_1(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
	    xnumel = 1048576
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = xoffset + tl.arange(0, XBLOCK)[:]
	    xmask = tl.full([XBLOCK], True, tl.int1)
	    x0 = xindex
	    tmp0 = tl.load(in_out_ptr0 + (x0), None).to(tl.float32)
	    tmp1 = tl.full([1], 0, tl.int32)
	    tmp2 = triton_helpers.maximum(tmp1, tmp0)
	    tl.store(in_out_ptr0 + (x0), tmp2, None)
	''', device_str='cuda')
	
	
	# kernel path: /tmp/torchinductor_cache/wv/cwv6cxclgtrt3hams2kloxex2znci73vsksvlyvcuj7liuhc6676.py
	# Topologically Sorted Source Nodes: [g, rs_expanded, out], Original ATen: [aten.mul, aten.repeat, aten.add]
	# Source node to ATen node mapping:
	#   g => mul_5
	#   out => add_3
	#   rs_expanded => repeat
	# Graph fragment:
	#   %buf14 : Tensor  = PlaceHolder[target=buf14]
	#   %buf16 : Tensor  = PlaceHolder[target=buf16]
	#   %mul_5 : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%wait_tensor_1, 0.7071067811865476), kwargs = {})
	#   %repeat : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.repeat.default](args = (%wait_tensor_2, [2, 1]), kwargs = {})
	#   %add_3 : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_5, %repeat), kwargs = {})
	#   return %add_3
	triton_poi_fused_add_mul_repeat_2 = async_compile.triton('triton_poi_fused_add_mul_repeat_2', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.pointwise(
	    size_hints={'x': 2097152}, 
	    filename=__file__,
	    triton_meta={'signature': {'in_ptr0': '*fp16', 'in_ptr1': '*fp16', 'out_ptr0': '*fp16', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_mul_repeat_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 8388608}},
	    min_elem_per_thread=0
	)
	@triton.jit
	def triton_poi_fused_add_mul_repeat_2(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
	    xnumel = 2097152
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = xoffset + tl.arange(0, XBLOCK)[:]
	    xmask = tl.full([XBLOCK], True, tl.int1)
	    x2 = xindex
	    x0 = (xindex % 1024)
	    x1 = xindex // 1024
	    tmp0 = tl.load(in_ptr0 + (x2), None).to(tl.float32)
	    tmp3 = tl.load(in_ptr1 + (x0 + 1024*((x1 % 1024))), None).to(tl.float32)
	    tmp1 = 0.7071067811865476
	    tmp2 = tmp0 * tmp1
	    tmp4 = tmp2 + tmp3
	    tl.store(out_ptr0 + (x2), tmp4, None)
	''', device_str='cuda')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg2_1, (1024, ), (1, ))
	    assert_size_stride(arg3_1, (1024, ), (1, ))
	    assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg5_1, (2048, 1024), (1024, 1))
	    with torch.cuda._DeviceGuard(1):
	        torch.cuda.set_device(1)
	        buf0 = empty_strided_cuda((1024, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [h], Original ATen: [aten.mm]
	        extern_kernels.mm(arg1_1, reinterpret_tensor(arg0_1, (1024, 1024), (1, 1024), 0), out=buf0)
	        del arg0_1
	        del arg1_1
	        buf4 = buf0; del buf0  # reuse
	        # Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	        stream1 = get_raw_stream(1)
	        triton_per_fused_all_reduce_gelu_native_layer_norm_0.run(buf4, arg2_1, arg3_1, 1024, 1024, stream=stream1)
	        del arg2_1
	        del arg3_1
	        # Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	        torch.ops._c10d_functional.all_reduce_.default(buf4, 'sum', '0')
	        # Topologically Sorted Source Nodes: [h_3], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf4)
	        buf9 = empty_strided_cuda((1024, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [h2], Original ATen: [aten.mm]
	        extern_kernels.mm(buf4, reinterpret_tensor(arg4_1, (1024, 1024), (1, 1024), 0), out=buf9)
	        del arg4_1
	        buf10 = buf9; del buf9  # reuse
	        # Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	        stream1 = get_raw_stream(1)
	        triton_poi_fused_all_gather_into_tensor_relu_1.run(buf10, 1048576, stream=stream1)
	        # Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	        buf11 = torch.ops._c10d_functional.all_gather_into_tensor.default(buf10, 2, '0')
	        assert_size_stride(buf11, (2048, 1024), (1024, 1), 'torch.ops._c10d_functional.all_gather_into_tensor.default')
	        assert_alignment(buf11, 16, 'torch.ops._c10d_functional.all_gather_into_tensor.default')
	        del buf4
	        # Topologically Sorted Source Nodes: [reduce_scatter_tensor_default], Original ATen: [_c10d_functional.reduce_scatter_tensor]
	        buf12 = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0')
	        assert_size_stride(buf12, (1024, 1024), (1024, 1), 'torch.ops._c10d_functional.reduce_scatter_tensor.default')
	        assert_alignment(buf12, 16, 'torch.ops._c10d_functional.reduce_scatter_tensor.default')
	        # Topologically Sorted Source Nodes: [gathered], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf11)
	        del buf10
	        # Topologically Sorted Source Nodes: [rs], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf12)
	        del arg5_1
	        buf17 = empty_strided_cuda((2048, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [g, rs_expanded, out], Original ATen: [aten.mul, aten.repeat, aten.add]
	        stream1 = get_raw_stream(1)
	        triton_poi_fused_add_mul_repeat_2.run(buf11, buf12, buf17, 2097152, stream=stream1)
	        del buf11
	        del buf12
	    return (buf17, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg1_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg2_1 = rand_strided((1024, ), (1, ), device='cuda:1', dtype=torch.float16)
	    arg3_1 = rand_strided((1024, ), (1, ), device='cuda:1', dtype=torch.float16)
	    arg4_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg5_1 = rand_strided((2048, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0804 12:34:16.799000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "80236dd3153279aef925f754b0c47b70"}
	{
	"name": "PyCodeCache.load_by_key_path",
	"ts": 1754336056799696.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.802000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "12ad482937cfff8aece2cbc039844561"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336056802091.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.001000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "4d64653ef1d8d8c32ab4de360b189449"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057001688.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.002000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "80f978ac4c35bb3c9cb156c4c9c7212b"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057002558.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.003000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "3c142d9837ec0dfbc99fecfab8653418"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057003600.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.004000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5777ab745f33880ba17d9f6a14a0f70c"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057004106.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.277000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "4e663a4bec69ea28d39d17c2f748072b"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057277526.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.278000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "4f1a3e38895dbbdf80c453694838a888"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057278400.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.279000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "df182e15284e055cf323e429492b08af"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057279661.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.280000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "894894af91c31053d3d1aa05047df5ad"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057280180.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.520000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5cf06f1b29da2c07e13fdebaaaee8d77"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057520536.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.521000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "7ed1e0e9f925f1a7c72242bb070be0f4"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057521421.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.522000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "e02e32b9c735425ff82cb524f6118aa4"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057522678.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.523000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "94801603d69e385f61d2cdf0a7f3542f"}
	{
	"name": "async_compile.wait",
	"ts": 1754336057523139.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.523000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "9ad23fc92a8e4f2a15ffaedb2bf2a062"}
	{
	"name": "async_compile.wait",
	"ts": 1754336057523699.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.524000 1142858 torch/_inductor/async_compile.py:116] {"artifact": {"name": "triton_kernel_info", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "911ae427d653658a7be1def130de511a"}
	{"triton_per_fused_all_reduce_gelu_native_layer_norm_0": {"autotune_cache_state": "only 1 config", "only_config": [["XBLOCK", 1], ["num_warps", 8], ["num_stages", 1]], "compile_time_us": 200965}, "triton_poi_fused_add_mul_repeat_2": {"autotune_cache_state": "miss", "num_configs": 2, "compile_time_us": 241968}, "triton_poi_fused_all_gather_into_tensor_relu_1": {"autotune_cache_state": "miss", "num_configs": 2, "compile_time_us": 275030}}
V0804 12:34:17.524000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "bee9239babd4825a4636a5bbc00edc0a"}
	{
	"name": "PyCodeCache.load_by_key_path",
	"ts": 1754336057524497.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.526000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5d61db82333d22acbcf73f9db933c20c"}
	{
	"name": "code_gen",
	"ts": 1754336057526188.5,
	"args": {
	"fn_name": "GraphLowering.compile_to_module",
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.528000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "c96d85c4e6d3a3185d3045f553d66b16"}
	{
	"name": "GraphLowering.compile_to_fn",
	"ts": 1754336057528082.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.528000 1142858 torch/_inductor/debug.py:700] {"artifact": {"name": "inductor_collective_schedule", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "e255b7f099207a3c7478df9c470be5fb"}
	[
	"torch.ops._c10d_functional.all_reduce_.default",
	"torch.ops._c10d_functional.wait_tensor.default",
	"torch.ops._c10d_functional.all_gather_into_tensor.default",
	"torch.ops._c10d_functional.reduce_scatter_tensor.default",
	"torch.ops._c10d_functional.wait_tensor.default",
	"torch.ops._c10d_functional.wait_tensor.default"
	]
V0804 12:34:17.536000 1142858 torch/_inductor/debug.py:734] {"artifact": {"name": "inductor_runtime_and_tensor_meta", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "5bdf44b46ade21759085f713237b436d"}
	{
	"ops": [
	{
	"name": "extern_kernels.mm",
	"type": "compute",
	"estimated_runtime_ns": 7918718.150774888,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "op1_op2_op4",
	"type": "compute",
	"estimated_runtime_ns": 2494.708994708994,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.all_reduce_.default",
	"type": "collective",
	"estimated_runtime_ns": 34581.10319270239,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "extern_kernels.mm",
	"type": "compute",
	"estimated_runtime_ns": 7918718.150774888,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "op8",
	"type": "compute",
	"estimated_runtime_ns": 2492.275132275132,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.all_gather_into_tensor.default",
	"type": "collective",
	"estimated_runtime_ns": 21085.55159635119,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.reduce_scatter_tensor.default",
	"type": "collective",
	"estimated_runtime_ns": 33891.10319270239,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "op13",
	"type": "compute",
	"estimated_runtime_ns": 6230.68783068783,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	}
	]
	}
V0804 12:34:17.537000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "ca8ccf8344ba48c785e79204ca585441"}
	{
	"name": "TritonBundler.collect",
	"ts": 1754336057536993.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.538000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "ef094d43c568c6c3ba97e4ecc345ebd5"}
	{
	"name": "TritonBundler.collect",
	"ts": 1754336057538643.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.542000 1142858 torch/_dynamo/utils.py:1970] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "15cbcc011ff940cc5afe9aba4d908989"}
	{
	"name": "fx_graph_cache_miss",
	"ts": 1754336056508661.2,
	"args": {
	"cache_status_detailed": "full_miss",
	"key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia",
	"components": [
	"[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1",
	"[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_event_time": 1754336056519882928,
	"cache_state": "miss",
	"triton_bundler_meta": "TritonBundlerMetadata(cached_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2', 'triton_poi_fused_add_mul_repeat_2'], statically_launched_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2'])",
	"time_taken_ns": 1028276620,
	"compile_id": "0/1"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0804 12:34:17.543000 1142858 torch/_inductor/compile_fx.py:1046] {"artifact": {"name": "fx_graph_cache_miss", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "e6fdbc08f0c63f46936e51c6e9971b97"}
	{"cache_status_detailed": "full_miss", "key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia", "components": ["[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ", "[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1", "[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)", "[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>", "[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}", "[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}", "[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False", "[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10", "[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True", "[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']", "[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None", "[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op", "[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait", "[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"], "cache_event_time": 1754336056519882928, "cache_state": "miss", "triton_bundler_meta": "TritonBundlerMetadata(cached_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2', 'triton_poi_fused_add_mul_repeat_2'], statically_launched_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2'])", "time_taken_ns": 1028276620, "compile_id": "0/1"}
V0804 12:34:17.544000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "14540daa5eed5d60e04d8d90d1acad9b"}
	{
	"name": "fx_codegen_and_compile",
	"ts": 1754336057544033.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.545000 1142858 torch/_inductor/compile_fx.py:1063] {"artifact": {"name": "inductor_provenance_tracking_node_mappings", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "76d2422b3e3af0e2c6da07ed7be908de"}
	{"preToPost": {"h": ["permute", "mm"], "h_1": ["convert_element_type_2", "mul", "mul_1", "erf", "add", "mul_2"], "h_2": ["mul_2", "var_mean", "getitem", "getitem_1", "sub", "add_1", "rsqrt", "mul_3", "mul_4", "add_2", "convert_element_type_5"], "all_reduce_default": ["all_reduce"], "h_3": ["wait_tensor"], "h2": ["permute_1", "mm_1"], "h2_1": ["relu"], "all_gather_into_tensor_default": ["all_gather_into_tensor"], "reduce_scatter_tensor_default": ["reduce_scatter_tensor"], "gathered": ["wait_tensor_1"], "g": ["mul_5"], "rs": ["wait_tensor_2"], "rs_expanded": ["repeat"], "out": ["add_3"]}, "postToPre": {"permute": ["h"], "mm": ["h"], "convert_element_type_2": ["h_1"], "mul": ["h_1"], "mul_1": ["h_1"], "erf": ["h_1"], "add": ["h_1"], "mul_2": ["h_1", "h_2"], "var_mean": ["h_2"], "getitem": ["h_2"], "getitem_1": ["h_2"], "sub": ["h_2"], "add_1": ["h_2"], "rsqrt": ["h_2"], "mul_3": ["h_2"], "mul_4": ["h_2"], "add_2": ["h_2"], "convert_element_type_5": ["h_2"], "all_reduce": ["all_reduce_default"], "wait_tensor": ["h_3"], "permute_1": ["h2"], "mm_1": ["h2"], "relu": ["h2_1"], "all_gather_into_tensor": ["all_gather_into_tensor_default"], "reduce_scatter_tensor": ["reduce_scatter_tensor_default"], "wait_tensor_1": ["gathered"], "mul_5": ["g"], "wait_tensor_2": ["rs"], "repeat": ["rs_expanded"], "add_3": ["out"]}, "cppCodeToPost": {"triton_per_fused_all_reduce_gelu_native_layer_norm_0": ["var_mean", "mul_2", "mul", "convert_element_type_2", "add", "erf", "mul_1", "all_reduce", "convert_element_type_5", "add_2", "mul_4", "mul_3", "sub", "rsqrt", "add_1"], "triton_poi_fused_all_gather_into_tensor_relu_1": ["all_gather_into_tensor", "relu"], "triton_poi_fused_add_mul_repeat_2": ["add_3", "mul_5", "repeat"], "extern_kernels.mm": ["mm", "mm_1"]}, "postToCppCode": {"var_mean": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "convert_element_type_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "erf": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_1": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "all_reduce": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "convert_element_type_5": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_4": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_3": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "sub": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "rsqrt": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add_1": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "all_gather_into_tensor": ["triton_poi_fused_all_gather_into_tensor_relu_1"], "relu": ["triton_poi_fused_all_gather_into_tensor_relu_1"], "add_3": ["triton_poi_fused_add_mul_repeat_2"], "mul_5": ["triton_poi_fused_add_mul_repeat_2"], "repeat": ["triton_poi_fused_add_mul_repeat_2"], "mm": ["extern_kernels.mm"], "mm_1": ["extern_kernels.mm"]}}
V0804 12:34:17.546000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "aa82c2077ddbafd7cce2517078b3da43"}
	{
	"name": "inductor_compile",
	"ts": 1754336057545927.5,
	"args": {
	"fn_name": "compile_fx_inner",
	"compile_id": "0/1",
	"is_backward": false,
	"cache_state": "miss",
	"cache_event_time": 1754336056508661133,
	"key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia",
	"components": [
	"[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1",
	"[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_bypass_reason": null,
	"remote_cache_enabled": false,
	"local_cache_enabled": true
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.547000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "575fb830502bd4aef41be843d415bd81"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1754336057547051.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.551000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "c93ee0f5660e1303f99b3bb6658dba22"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1754336057551887.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.553000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "29b59e021e5c79f63433f5cc4dd58004"}
	{
	"name": "backend_compile",
	"ts": 1754336057552910.0,
	"args": {
	"fn_name": "OutputGraph.call_user_compiler",
	"compile_id": "0/1",
	"cache_state": "miss",
	"cache_event_time": 1754336056406148383,
	"key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp",
	"components": [
	"[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False",
	"[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>",
	"[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])",
	"[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_bypass_reason": null,
	"remote_cache_enabled": false,
	"local_cache_enabled": true,
	"requires_subclass_dispatch": false,
	"dispatch_mode": "inference"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "993d974dfe8f1e85e9bfd2447147f6a8"}
	{
	"name": "compile_attempt_0",
	"ts": 1754336057556288.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "ed08aa4ec91b74e6dbd4428600f8b8fb"}
	{
	"name": "build_guards",
	"ts": 1754336057556752.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.604000 1142858 torch/_dynamo/guards.py:3264] {"dynamo_cpp_guards_str": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "e43f79e90e076e25c23fe0530956739a"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo/output_graph.py:643 in init_ambient_guards
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:631 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['fn'], accessed_by=FrameLocalsGuardAccessor(key='fn', framelocals_idx=2), type=<class 'method'>, tag_safe=(False, False)
	| | +- ID_MATCH: ___check_obj_id(L['fn'], 139646516664256)                   
	| | +- GuardManager: source=L['fn'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__), type=<class 'tuple'>, tag_safe=(False, False)
	| | | +- GuardManager: source=L['fn'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0), type=<class 'cell'>, tag_safe=(False, False)
	| | | | +- GuardManager: source=L['fn'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents), type=<class 'method'>, tag_safe=(False, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__closure__[0].cell_contents, 9738560)  # with ctx_factory():  # utils/_contextlib.py:119 in decorate_context
	| | | +- GuardManager: source=L['fn'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1), type=<class 'cell'>, tag_safe=(False, False)
	| | | | +- GuardManager: source=L['fn'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- GuardManager: source=L['fn'].__closure__[1].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__), type=<class 'code'>, tag_safe=(True, False)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['fn'].__closure__[1].cell_contents.__code__, 11214464)  # return func(*args, **kwargs)  # utils/_contextlib.py:120 in decorate_context
	| | +- GuardManager: source=L['fn'].__self__, accessed_by=GetAttrGuardAccessor(__self__), type=<class '__main__.MultiGraphRepro'>, tag_safe=(True, True)
	| | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__, 86065824)                
	| | | +- GuardManager: source=L['fn'].__self__.__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | +- GuardManager: source=L['fn'].__self__._modules, accessed_by=DictGetItemGuardAccessor('_modules'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules, 9676128)          # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1'], accessed_by=DictGetItemGuardAccessor('lin1'), type=<class 'torch.nn.modules.linear.Linear'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin1'], 87594704)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['lin1'].__dict__)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin1']._parameters, 9676128)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'NoneType'>, tag_safe=(True, False)
	| | | | | | | | | +- NONE_MATCH: L['fn'].__self__._modules['lin1']._parameters['bias'] is None  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['lin1']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2'], accessed_by=DictGetItemGuardAccessor('lin2'), type=<class 'torch.nn.modules.linear.Linear'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin2'], 87594704)  # h2 = self.lin2(h)  # test2.py:70 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['lin2'].__dict__)  # h2 = self.lin2(h)  # test2.py:70 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin2']._parameters, 9676128)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'NoneType'>, tag_safe=(True, False)
	| | | | | | | | | +- NONE_MATCH: L['fn'].__self__._modules['lin2']._parameters['bias'] is None  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['lin2']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'], accessed_by=DictGetItemGuardAccessor('norm'), type=<class 'torch.nn.modules.normalization.LayerNorm'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm'], 88494992)  # h = self.norm(h)  # test2.py:61 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['norm'].__dict__)  # h = self.norm(h)  # test2.py:61 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].eps, accessed_by=DictGetItemGuardAccessor('eps'), type=<class 'float'>, tag_safe=(True, False)
	| | | | | | | | +- EQUALS_MATCH: L['fn'].__self__._modules['norm'].eps == 1e-05                # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm']._parameters, 9676128)  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['norm']._parameters['bias'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024], stride=[1])  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['norm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024], stride=[1])  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].normalized_shape, accessed_by=DictGetItemGuardAccessor('normalized_shape'), type=<class 'tuple'>, tag_safe=(True, False)
	| | | | | | | | +- EQUALS_MATCH: L['fn'].__self__._modules['norm'].normalized_shape == (1024,)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm'].normalized_shape, 9650464)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | | +- LENGTH_CHECK: len(L['fn'].__self__._modules['norm'].normalized_shape) == 1  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | +- GuardManager: source=L['fn'].__self__._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._parameters, 9676128)       # h = self.lin1(x)  # test2.py:59 in graph_one
	| +- GuardManager: source=L['args'], accessed_by=FrameLocalsGuardAccessor(key='args', framelocals_idx=0), type=<class 'tuple'>, tag_safe=(True, False)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 9650464)                        
	| | +- LENGTH_CHECK: len(L['args']) == 3                                         
	| | +- GuardManager: source=L['args'][0], accessed_by=TupleGetItemGuardAccessor(0), type=<class 'torch.Tensor'>, tag_safe=(True, False)
	| | | +- TENSOR_MATCH: check_tensor(L['args'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=False, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- NO_HASATTR: hasattr(L['args'][0], '_dynamo_dynamic_indices') == False     # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['args'][0], L['args'][1])
	| | +- GuardManager: source=L['args'][1], accessed_by=TupleGetItemGuardAccessor(1), type=<class 'torch.Tensor'>, tag_safe=(True, False)
	| | | +- TENSOR_MATCH: check_tensor(L['args'][1], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=False, size=[2048, 1024], stride=[1024, 1])  # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | +- NO_HASATTR: hasattr(L['args'][1], '_dynamo_dynamic_indices') == False     # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | +- NO_TENSOR_ALIASING
	| | +- GuardManager: source=L['args'][2], accessed_by=TupleGetItemGuardAccessor(2), type=<class 'int'>, tag_safe=(True, False)
	| | | +- EQUALS_MATCH: L['args'][2] == 2                                             # torch.ops._c10d_functional.all_gather_into_tensor.default(  # test2.py:75 in graph_one
	| +- GuardManager: source=L['kwargs'], accessed_by=FrameLocalsGuardAccessor(key='kwargs', framelocals_idx=1), type=<class 'dict'>, tag_safe=(True, False)
	| | +- TYPE_MATCH: ___check_type_id(L['kwargs'], 9676128)                      
	| | +- DICT_LENGTH: not L['kwargs']                                             
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)
	| | +- GuardManager: source=G['__import___main__'], accessed_by=DictGetItemGuardAccessor('__import___main__'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import___main__'], 139648550378592)      # h = F.gelu(h)  # test2.py:60 in graph_one
	| | | +- GuardManager: source=G['__import___main__'].math, accessed_by=GetAttrGuardAccessor(math), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].math, 139648548565248)  # g = gathered * math.sqrt(0.5)  # test2.py:82 in graph_one
	| | | | +- GuardManager: source=G['__import___main__'].math.sqrt, accessed_by=GetAttrGuardAccessor(sqrt), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].math.sqrt, 139648548568848)  # g = gathered * math.sqrt(0.5)  # test2.py:82 in graph_one
	| | | +- GuardManager: source=G['__import___main__'].torch, accessed_by=GetAttrGuardAccessor(torch), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch, 139648548799248)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | +- GuardManager: source=G['__import___main__'].torch.ops, accessed_by=GetAttrGuardAccessor(ops), type=<class 'torch._ops._Ops'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops, 139646535729696)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional, accessed_by=GetAttrGuardAccessor(_c10d_functional), type=<class 'torch._ops._OpNamespace'>, tag_safe=(False, False)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional, 139645390308672)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.all_reduce, accessed_by=GetAttrGuardAccessor(all_reduce), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.all_reduce, 139645365491216)  # torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")  # test2.py:65 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.wait_tensor, accessed_by=GetAttrGuardAccessor(wait_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.wait_tensor, 139645391765136)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.reduce_scatter_tensor, accessed_by=GetAttrGuardAccessor(reduce_scatter_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.reduce_scatter_tensor, 139645365494432)  # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.all_gather_into_tensor, accessed_by=GetAttrGuardAccessor(all_gather_into_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.all_gather_into_tensor, 139645365493040)  # torch.ops._c10d_functional.all_gather_into_tensor.default(  # test2.py:75 in graph_one
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_linear'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 139646537542256)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F, 139646537542176)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.gelu, accessed_by=GetAttrGuardAccessor(gelu), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.gelu, 139647331694640)  # h = F.gelu(h)  # test2.py:60 in graph_one
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.relu, accessed_by=GetAttrGuardAccessor(relu), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.relu, 139646534605440)  # h2 = F.relu(h2)  # test2.py:71 in graph_one
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.linear, accessed_by=GetAttrGuardAccessor(linear), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.linear, 139647331695760)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.layer_norm, accessed_by=GetAttrGuardAccessor(layer_norm), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.layer_norm, 139646534610080)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_module'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 139646542524272)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_normalization'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_normalization'], 139646533665952)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	+- LAMBDA_GUARD: G['__import_torch_dot_nn_dot_modules_dot_linear'].F is G['__import___main__'].F  # h = F.gelu(h)  # test2.py:60 in graph_one
	+- LAMBDA_GUARD: G['__import_torch_dot_nn_dot_modules_dot_linear'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	
	Guard latency = 76.59 us
V0804 12:34:17.605000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "34c095b8287af9a8e0795bf443735bd9"}
	{
	"name": "build_guards",
	"ts": 1754336057604943.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.605000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "287c902d8f119efce4659e7156d907f4"}
	{
	"name": "gc",
	"ts": 1754336057605596.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.612000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "62e1991310911d573d0cd0d87742e3a8"}
	{
	"name": "gc",
	"ts": 1754336057612475.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.613000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "c9baed5bb949943a63c9444699a3230f"}
	{
	"name": "entire_frame_compile",
	"ts": 1754336057613317.0,
	"args": {
	"fn_name": "_compile.compile_inner",
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.616000 1142858 torch/_dynamo/utils.py:1626] {"compilation_metrics": {"compile_id": "0/1", "frame_key": "2", "co_name": "inner", "co_filename": "/home/skarjala/pytorch/torch/_dynamo/external_utils.py", "co_firstlineno": 66, "cache_size": 1, "accumulated_cache_size": 1, "guard_count": 74, "shape_env_guard_count": 0, "graph_op_count": 16, "graph_node_count": 23, "graph_input_count": 6, "start_time": 1754336056.314324, "entire_frame_compile_time_s": 1.298985, "backend_compile_time_s": 1.166478, "inductor_compile_time_s": 1.03941, "code_gen_time_s": 0.915887, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": ["_c10d_functional::all_gather_into_tensor", "_c10d_functional::reduce_scatter_tensor", "_c10d_functional::all_reduce", "_c10d_functional::wait_tensor"], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "remote_cache_time_saved_s": null, "structured_logging_overhead_s": 0.055596, "config_suppress_errors": false, "config_inline_inbuilt_nn_modules": true, "specialize_float": false, "dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}", "is_forward": true, "num_triton_bundles": null, "remote_fx_graph_cache_get_time_ms": null, "remote_fx_graph_cache_put_time_ms": null, "start_time_us": 1754336056314324, "duration_us": 1298985, "dynamo_cumulative_compile_time_us": 1298985, "aot_autograd_cumulative_compile_time_us": 1166478, "inductor_cumulative_compile_time_us": 1039410, "inductor_code_gen_cumulative_compile_time_us": 915887, "triton_compile_time_us": 720120, "runtime_cudagraphify_time_us": null, "runtime_triton_autotune_time_us": null, "dynamo_compile_time_before_restart_us": 0, "distributed_ephemeral_timeout_us": null, "structured_logging_overhead_us": 55596, "remote_fx_graph_cache_get_time_us": null, "remote_fx_graph_cache_put_time_us": null, "backward_cumulative_compile_time_us": null, "end_time_us": 1754336057613729, "pre_grad_pass_time_us": 1199, "post_grad_pass_time_us": 6732, "joint_graph_pass_time_us": 10172, "log_format_version": 3, "inductor_config": "{\"TYPE_CHECKING\": false, \"_cache_config_ignore_prefix\": [\"trace\", \"cuda.cutlass_dir\", \"worker_start_method\", \"compile_threads\", \"post_grad_custom_post_pass\", \"post_grad_custom_pre_pass\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\", \"always_complex_memory_overlap_TESTING_ONLY\", \"fx_graph_cache\", \"fx_graph_remote_cache\", \"autotune_local_cache\", \"autotune_remote_cache\"], \"_collective.auto_select\": false, \"_collective.one_shot_all_reduce_threshold_bytes\": 131072, \"_fuse_ddp_bucket_size\": 25, \"_fuse_ddp_communication\": false, \"_fuse_ddp_communication_passes\": [\"fuse_ddp_with_concat_op\", \"schedule_comm_wait\"], \"_micro_pipeline_tp\": false, \"_post_fusion_custom_pass\": null, \"_pre_fusion_custom_pass\": null, \"_profile_var\": \"\", \"_raise_error_for_testing\": false, \"_save_config_ignore\": [\"trace.upload_tar\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"pre_grad_custom_pass\", \"aot_inductor.repro_level\", \"aot_inductor.dump_aoti_minifier\", \"post_grad_custom_pre_pass\", \"post_grad_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\"], \"add_pre_grad_passes\": null, \"aggressive_fusion\": false, \"alignment_asserts\": true, \"allow_buffer_reuse\": true, \"always_complex_memory_overlap_TESTING_ONLY\": false, \"always_keep_tensor_constants\": false, \"annotate_training\": false, \"aot_inductor.allow_stack_allocation\": false, \"aot_inductor.compile_standalone\": false, \"aot_inductor.compile_wrapper_opt_level\": \"O1\", \"aot_inductor.custom_op_libs\": null, \"aot_inductor.custom_ops_to_c_shims\": {}, \"aot_inductor.debug_compile\": false, \"aot_inductor.debug_intermediate_value_printer\": \"0\", \"aot_inductor.dump_aoti_minifier\": false, \"aot_inductor.embed_kernel_binary\": false, \"aot_inductor.emit_multi_arch_kernel\": false, \"aot_inductor.enable_lto\": false, \"aot_inductor.filtered_kernel_names\": null, \"aot_inductor.force_mmap_weights\": false, \"aot_inductor.metadata\": {}, \"aot_inductor.model_name_for_generated_files\": null, \"aot_inductor.output_path\": \"\", \"aot_inductor.package\": false, \"aot_inductor.package_constants_in_so\": true, \"aot_inductor.package_constants_on_disk\": false, \"aot_inductor.package_cpp_only\": null, \"aot_inductor.precompile_headers\": true, \"aot_inductor.presets\": {}, \"aot_inductor.raise_error_on_ignored_optimization\": true, \"aot_inductor.repro_level\": 2, \"aot_inductor.serialized_in_spec\": \"\", \"aot_inductor.serialized_out_spec\": \"\", \"aot_inductor.use_consts_asm_build\": true, \"aot_inductor.use_minimal_arrayref_interface\": false, \"aot_inductor.use_runtime_constant_folding\": false, \"aot_inductor.weight_use_caching_allocator\": false, \"assert_indirect_indexing\": true, \"assume_aligned_inputs\": false, \"assume_unaligned_fallback_output\": false, \"autoheuristic_collect\": \"\", \"autoheuristic_log_path\": \"DEFAULT\", \"autoheuristic_use\": \"mixed_mm\", \"autotune_fallback_to_aten\": false, \"autotune_in_subproc\": false, \"autotune_local_cache\": true, \"autotune_lookup_table\": {}, \"autotune_multi_device\": false, \"autotune_num_choices_displayed\": 10, \"autotune_remote_cache\": null, \"b2b_gemm_pass\": false, \"batch_fusion\": true, \"benchmark_combo_kernel\": false, \"benchmark_epilogue_fusion\": true, \"benchmark_fusion\": false, \"benchmark_harness\": true, \"benchmark_kernel\": false, \"bfloat16_atomic_adds_enabled\": true, \"bucket_all_gathers_fx\": \"none\", \"bucket_all_gathers_fx_bucket_size_determinator\": null, \"bucket_reduce_scatters_fx\": \"none\", \"bucket_reduce_scatters_fx_bucket_size_determinator\": null, \"bundle_triton_into_fx_graph_cache\": true, \"bundled_autotune_remote_cache\": null, \"bw_outputs_user_visible\": true, \"can_inplace_pad_graph_input\": false, \"check_stack_no_cycles_TESTING_ONLY\": false, \"combo_kernel_allow_mixed_sizes\": 1, \"combo_kernel_foreach_dynamic_shapes\": true, \"combo_kernels\": false, \"combo_kernels_autotune\": 1, \"comment_origin\": false, \"compile_threads\": 32, \"comprehensive_padding\": true, \"compute_all_bounds\": false, \"constant_and_index_propagation\": true, \"conv_1x1_as_mm\": false, \"coordinate_descent_check_all_directions\": false, \"coordinate_descent_search_radius\": 1, \"coordinate_descent_tuning\": false, \"cpp.cxx\": [null, \"g++\"], \"cpp.descriptive_names\": \"original_aten\", \"cpp.dynamic_threads\": false, \"cpp.enable_concat_linear\": false, \"cpp.enable_floating_point_contract_flag\": \"off\", \"cpp.enable_grouped_gemm_template\": false, \"cpp.enable_kernel_profile\": false, \"cpp.enable_loop_tail_vec\": true, \"cpp.enable_tiling_heuristics\": true, \"cpp.enable_unsafe_math_opt_flag\": false, \"cpp.fallback_scatter_reduce_sum\": true, \"cpp.force_inline_kernel\": false, \"cpp.gemm_cache_blocking\": null, \"cpp.gemm_max_k_slices\": 1, \"cpp.gemm_thread_factors\": null, \"cpp.inject_log1p_bug_TESTING_ONLY\": null, \"cpp.inject_relu_bug_TESTING_ONLY\": null, \"cpp.max_horizontal_fusion_size\": 16, \"cpp.min_chunk_size\": 512, \"cpp.no_redundant_loops\": true, \"cpp.simdlen\": null, \"cpp.threads\": -1, \"cpp.use_decompose_tanh\": false, \"cpp.use_small_dequant_buffer\": false, \"cpp.vec_isa_ok\": null, \"cpp.weight_prepack\": true, \"cpp_cache_precompile_headers\": true, \"cpp_wrapper\": false, \"cpp_wrapper_build_separate\": false, \"cpu_backend\": \"cpp\", \"cuda.arch\": null, \"cuda.binary_remote_cache_force_write\": false, \"cuda.compile_opt_level\": \"-O1\", \"cuda.cuda_cxx\": null, \"cuda.cutlass_backend_min_gemm_size\": 1, \"cuda.cutlass_dir\": \"/home/skarjala/pytorch/third_party/cutlass\", \"cuda.cutlass_enabled_ops\": \"all\", \"cuda.cutlass_epilogue_fusion_enabled\": false, \"cuda.cutlass_hash_with_compile_cmd\": false, \"cuda.cutlass_instantiation_level\": \"0\", \"cuda.cutlass_max_profiling_configs\": null, \"cuda.cutlass_max_profiling_swizzle_options\": [1, 2, 4, 8], \"cuda.cutlass_op_allowlist_regex\": null, \"cuda.cutlass_op_denylist_regex\": null, \"cuda.cutlass_prescreening\": true, \"cuda.cutlass_presets\": null, \"cuda.cutlass_tma_only\": false, \"cuda.enable_caching_codegen\": true, \"cuda.enable_cuda_lto\": false, \"cuda.enable_debug_info\": false, \"cuda.enable_ptxas_info\": false, \"cuda.generate_test_runner\": false, \"cuda.upload_to_binary_remote_cache\": false, \"cuda.use_binary_remote_cache\": true, \"cuda.use_fast_math\": false, \"cuda.version\": null, \"cuda_backend\": \"triton\", \"dce\": false, \"debug\": false, \"debug_fusion\": false, \"debug_index_asserts\": false, \"debug_ir_traceback\": false, \"decompose_mem_bound_mm\": false, \"developer_warnings\": true, \"disable_cpp_codegen\": false, \"disable_padding_cpu\": true, \"disable_progress\": true, \"dynamic_scale_rblock\": true, \"efficient_conv_bn_eval_fx_passes\": false, \"emulate_precision_casts\": false, \"enable_auto_functionalized_v2\": true, \"enable_caching_generated_triton_templates\": true, \"enable_linear_binary_folding\": false, \"enabled_metric_tables\": \"\", \"epilogue_fusion\": true, \"epilogue_fusion_first\": false, \"estimate_op_runtime\": \"default\", \"external_matmul\": [], \"fallback_random\": false, \"force_fuse_int_mm_with_mul\": false, \"force_layout_optimization\": false, \"force_pointwise_cat\": false, \"force_same_precision\": false, \"force_shape_pad\": false, \"freezing\": false, \"freezing_discard_parameters\": false, \"fx_graph_cache\": true, \"fx_graph_remote_cache\": null, \"fx_passes_numeric_check\": {\"num_iterations\": 1, \"pre_grad\": false, \"precision\": 0.0001, \"requires_optimizer\": true}, \"generate_intermediate_hooks\": false, \"global_cache_dir\": null, \"graph_partition\": false, \"group_fusion\": false, \"halide.asserts\": false, \"halide.cpu_target\": \"host\", \"halide.debug\": false, \"halide.gpu_target\": \"host-cuda\", \"halide.scan_kernels\": false, \"halide.scheduler_cpu\": \"Adams2019\", \"halide.scheduler_cuda\": \"Anderson2021\", \"implicit_fallbacks\": true, \"inplace_buffers\": true, \"inplace_padding\": true, \"inter_node_bw\": 25, \"intra_node_bw\": 300, \"is_nightly_or_source\": true, \"is_predispatch\": false, \"joint_custom_post_pass\": null, \"joint_custom_pre_pass\": null, \"joint_graph_constant_folding\": true, \"keep_output_stride\": true, \"kernel_name_max_ops\": 10, \"layout_opt_default\": \"1\", \"layout_optimization\": true, \"loop_ordering_after_fusion\": false, \"max_autotune\": false, \"max_autotune_conv_backends\": \"ATEN,TRITON\", \"max_autotune_flex_search_space\": \"DEFAULT\", \"max_autotune_gemm\": false, \"max_autotune_gemm_backends\": \"ATEN,TRITON,CPP\", \"max_autotune_gemm_search_space\": \"DEFAULT\", \"max_autotune_pointwise\": false, \"max_autotune_report_choices_stats\": true, \"max_autotune_subproc_graceful_timeout_seconds\": 0.0, \"max_autotune_subproc_result_timeout_seconds\": 60.0, \"max_autotune_subproc_terminate_timeout_seconds\": 0.0, \"max_epilogue_benchmarked_choices\": 1, \"max_fusion_buffer_group_pairwise_attempts\": 64, \"max_fusion_size\": 64, \"max_pointwise_cat_inputs\": 8, \"memory_planning\": false, \"memory_pool\": \"intermediates\", \"min_num_split\": 0, \"mixed_mm_choice\": \"heuristic\", \"multi_kernel_hints\": [], \"nan_asserts\": false, \"non_blocking_remote_cache_write\": true, \"online_softmax\": true, \"optimize_scatter_upon_const_tensor\": true, \"pad_channels_last\": false, \"pad_outputs\": false, \"padding_alignment_bytes\": 128, \"padding_stride_threshold\": 1024, \"pattern_matcher\": true, \"permute_fusion\": false, \"pick_loop_orders\": true, \"post_grad_custom_post_pass\": null, \"post_grad_custom_pre_pass\": null, \"post_grad_fusion_options\": {}, \"pre_grad_custom_pass\": null, \"pre_grad_fusion_options\": {}, \"precompilation_timeout_seconds\": 3600, \"profile_bandwidth\": false, \"profile_bandwidth_output\": null, \"profile_bandwidth_regex\": \"\", \"profile_bandwidth_with_do_bench_using_profiling\": false, \"profiler_mark_wrapper_call\": false, \"prologue_fusion\": true, \"quiesce_async_compile_pool\": false, \"realize_acc_reads_size_threshold\": null, \"realize_acc_reads_threshold\": 8, \"realize_opcount_threshold\": 30, \"realize_reads_threshold\": 4, \"remove_pre_grad_passes\": null, \"reorder_for_compute_comm_overlap\": false, \"reorder_for_compute_comm_overlap_passes\": [\"reorder_compute_for_overlap\", \"sink_waits\", \"raise_comms\"], \"reorder_for_locality\": true, \"reorder_for_peak_memory\": true, \"reorder_prefetch_limit\": null, \"rocm.arch\": [], \"rocm.ck_dir\": null, \"rocm.ck_max_profiling_configs\": null, \"rocm.ck_supported_arch\": [\"gfx90a\", \"gfx942\", \"gfx950\"], \"rocm.ck_tile_max_profiling_configs\": null, \"rocm.compile_opt_level\": \"-O2\", \"rocm.flush_denormals\": true, \"rocm.generate_test_runner\": false, \"rocm.is_debug\": false, \"rocm.kBatch_sweep\": null, \"rocm.n_max_profiling_configs\": null, \"rocm.print_kernel_resource_usage\": false, \"rocm.rocm_home\": null, \"rocm.save_temps\": false, \"rocm.split_k_threshold\": 16, \"rocm.use_fast_math\": true, \"rocm.use_preselected_instances\": false, \"save_args\": false, \"scalar_asserts\": true, \"score_fusion_memory_threshold\": 10, \"search_autotune_cache\": false, \"shape_padding\": true, \"size_asserts\": true, \"sleep_sec_TESTING_ONLY\": null, \"split_cat_fx_passes\": true, \"split_reductions\": true, \"static_launch_user_defined_triton_kernels\": false, \"static_weight_shapes\": true, \"strict_static_cuda_launcher\": false, \"test_configs.autotune_choice_desc_regex\": null, \"test_configs.autotune_choice_name_regex\": null, \"test_configs.force_extern_kernel_in_multi_template\": false, \"test_configs.graphsafe_rng_func_ignores_fallback_random\": false, \"test_configs.max_mm_configs\": null, \"test_configs.runtime_triton_dtype_assert\": false, \"test_configs.static_cpp_dtype_assert\": false, \"trace.compile_profile\": false, \"trace.debug_dir\": null, \"trace.debug_log\": false, \"trace.dot_graph_shape\": null, \"trace.draw_orig_fx_graph\": false, \"trace.enabled\": true, \"trace.fx_graph\": true, \"trace.fx_graph_transformed\": true, \"trace.graph_diagram\": false, \"trace.info_log\": false, \"trace.ir_post_fusion\": true, \"trace.ir_pre_fusion\": true, \"trace.log_autotuning_results\": false, \"trace.log_url_for_graph_xform\": null, \"trace.output_code\": true, \"trace.provenance_tracking\": true, \"trace.save_real_tensors\": false, \"trace.upload_tar\": null, \"triton.autotune_at_compile_time\": null, \"triton.autotune_cublasLt\": true, \"triton.autotune_pointwise\": true, \"triton.autotune_with_sample_inputs\": false, \"triton.coalesce_tiling_analysis\": true, \"triton.codegen_upcast_to_fp32\": true, \"triton.cooperative_reductions\": false, \"triton.cudagraph_capture_sizes\": null, \"triton.cudagraph_dynamic_shape_warn_limit\": 50, \"triton.cudagraph_skip_dynamic_graphs\": false, \"triton.cudagraph_support_input_mutation\": true, \"triton.cudagraph_trees\": true, \"triton.cudagraph_trees_history_recording\": false, \"triton.cudagraph_unexpected_rerecord_limit\": 128, \"triton.cudagraphs\": false, \"triton.debug_sync_graph\": false, \"triton.debug_sync_kernel\": false, \"triton.decompose_k_threshold\": 32, \"triton.dense_indexing\": false, \"triton.descriptive_names\": \"original_aten\", \"triton.disallow_failing_autotune_kernels_TESTING_ONLY\": false, \"triton.divisible_by_16\": true, \"triton.enable_persistent_tma_matmul\": false, \"triton.fast_path_cudagraph_asserts\": false, \"triton.force_cooperative_reductions\": false, \"triton.force_cudagraph_sync\": false, \"triton.force_cudagraphs_warmup\": false, \"triton.inject_relu_bug_TESTING_ONLY\": null, \"triton.max_tiles\": null, \"triton.min_split_scan_rblock\": 256, \"triton.multi_kernel\": 0, \"triton.num_decompose_k_splits\": 10, \"triton.persistent_reductions\": true, \"triton.prefer_nd_tiling\": false, \"triton.skip_cudagraph_warmup\": false, \"triton.skip_l1_cache\": false, \"triton.slow_path_cudagraph_asserts\": true, \"triton.spill_threshold\": 16, \"triton.store_cubin\": false, \"triton.tile_reductions\": false, \"triton.tiling_prevents_pointwise_fusion\": true, \"triton.tiling_prevents_reduction_fusion\": true, \"triton.unique_kernel_names\": true, \"triton.unique_user_kernel_names\": false, \"triton.use_block_ptr\": false, \"triton.use_tensor_descriptor\": false, \"triton_kernel_default_layout_constraint\": \"needs_fixed_stride_order\", \"unbacked_symint_fallback\": 8192, \"unroll_reductions_threshold\": 8, \"unsafe_ignore_unsupported_triton_autotune_args\": false, \"unsafe_marked_cacheable_functions\": {}, \"unsafe_skip_cache_dynamic_shape_guards\": false, \"use_experimental_benchmarker\": true, \"use_fast_math\": false, \"use_mixed_mm\": true, \"use_static_cuda_launcher\": true, \"verbose_progress\": false, \"warn_mix_layout\": false, \"worker_start_method\": \"subprocess\", \"worker_suppress_logging\": true}", "remote_cache_version": null, "inductor_fx_remote_cache_hit_count": null, "inductor_fx_remote_cache_miss_count": null, "inductor_fx_remote_cache_backend_type": null, "inductor_fx_remote_cache_hit_keys": null, "inductor_fx_remote_cache_miss_keys": null, "cuda_version": "12.4", "triton_version": "3.4.0", "feature_usage": {"aot_autograd_remote_cache": false, "fx_cache": true, "parallel_compile_post_warmup": false, "static_cuda_launcher": true, "triton_bundling": true}, "compile_time_autotune_time_us": 3720, "is_runtime": false, "gc_time_us": 6878, "tensorify_float_attempt": null, "tensorify_float_success": null, "tensorify_float_failure": null, "guard_latency_us": 76, "recompile_reason": "0/0: ___check_obj_id(fn, 139645370122560)                   ", "num_graph_breaks": 0, "triton_kernel_compile_times_us": "[[\"triton_poi_fused_all_gather_into_tensor_relu_1\", 275030], [\"triton_poi_fused_add_mul_repeat_2\", 241968], [\"triton_per_fused_all_reduce_gelu_native_layer_norm_0\", 200965]]", "ir_count": 123, "cudagraph_skip_reason": null, "python_version": "3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]", "pgo_put_remote_code_state_time_us": null, "pgo_get_remote_code_state_time_us": null, "param_numel": 2099200, "param_bytes": 4198400, "param_count": 4, "recompile_user_contexts": null}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0}
V0804 12:34:17.616000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 1, "attempt": 0, "has_payload": "e5e170a8abbb6cfeb1f911f0268e54c7"}
	{
	"name": "dynamo",
	"ts": 1754336057616827.0,
	"args": {
	"compile_id": "0/1",
	"num_graph_breaks": 0,
	"guard_latency_us": 76,
	"frame_key": "2",
	"co_name": "inner",
	"co_filename": "/home/skarjala/pytorch/torch/_dynamo/external_utils.py",
	"co_firstlineno": 66,
	"cache_size": 1,
	"accumulated_cache_size": 1,
	"guard_count": 74,
	"shape_env_guard_count": 0,
	"graph_op_count": 16,
	"graph_node_count": 23,
	"graph_input_count": 6,
	"fail_type": null,
	"fail_reason": null,
	"fail_user_frame_filename": null,
	"fail_user_frame_lineno": null,
	"non_compliant_ops": [],
	"compliant_custom_ops": [
	"_c10d_functional::all_gather_into_tensor",
	"_c10d_functional::reduce_scatter_tensor",
	"_c10d_functional::all_reduce",
	"_c10d_functional::wait_tensor"
	],
	"restart_reasons": [],
	"dynamo_time_before_restart_s": 0.0,
	"has_guarded_code": true,
	"dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.618000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "d12146f7cea70f5bcbd201d87761d0c7"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057618449.5,
	"args": {
	"kernel_name": "triton_poi_fused_all_gather_into_tensor_relu_1",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.619000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "4010c9af9457d49754c6fd46b2fdf585"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057619328.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.650000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "65f713b9210df3d5d122cf6a56ff560b"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057650626.8,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.651000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "e1389d214d9a14fb65c01353f08d6a07"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057651446.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.664000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "9af83c401cd846ee17d03bc8bc4ee499"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057664746.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.665000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "5d874912142c9bfd726b1f86e19a0e74"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057665164.5,
	"args": {
	"kernel_name": "triton_poi_fused_all_gather_into_tensor_relu_1",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.666000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "b3cea9f7482bbd3f76dfcef4848e1501"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057666301.8,
	"args": {
	"kernel_name": "triton_poi_fused_add_mul_repeat_2",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.667000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "acb4dc136e497003711efcd4ffc16634"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057667075.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.676000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "ab15fe0f95c885a59701a1f202e2c376"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057676590.5,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.677000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "10061e3509b8d2b1b6bea2f8c0cd17f4"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057677333.8,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "1bbdb7e90d19a309656a9c38d86eac43"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057686403.5,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "f7e91746014d42c8f6f90be6d82ab3b7"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057686856.2,
	"args": {
	"kernel_name": "triton_poi_fused_add_mul_repeat_2",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.690000 1142858 torch/_dynamo/utils.py:1626] {"compilation_metrics_runtime": {"compile_id": "0/1", "frame_key": null, "co_name": null, "co_filename": null, "co_firstlineno": null, "cache_size": null, "accumulated_cache_size": null, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1754336057.665496, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": null, "compliant_custom_ops": null, "restart_reasons": null, "dynamo_time_before_restart_s": null, "has_guarded_code": null, "remote_cache_time_saved_s": null, "structured_logging_overhead_s": null, "config_suppress_errors": false, "config_inline_inbuilt_nn_modules": true, "specialize_float": null, "dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}", "is_forward": true, "num_triton_bundles": null, "remote_fx_graph_cache_get_time_ms": null, "remote_fx_graph_cache_put_time_ms": null, "start_time_us": 1754336057665496, "duration_us": 67268, "dynamo_cumulative_compile_time_us": null, "aot_autograd_cumulative_compile_time_us": null, "inductor_cumulative_compile_time_us": null, "inductor_code_gen_cumulative_compile_time_us": null, "triton_compile_time_us": null, "runtime_cudagraphify_time_us": null, "runtime_triton_autotune_time_us": 67268, "dynamo_compile_time_before_restart_us": null, "distributed_ephemeral_timeout_us": null, "structured_logging_overhead_us": null, "remote_fx_graph_cache_get_time_us": null, "remote_fx_graph_cache_put_time_us": null, "backward_cumulative_compile_time_us": null, "end_time_us": 1754336057687713, "pre_grad_pass_time_us": null, "post_grad_pass_time_us": null, "joint_graph_pass_time_us": null, "log_format_version": 3, "inductor_config": "{\"TYPE_CHECKING\": false, \"_cache_config_ignore_prefix\": [\"trace\", \"cuda.cutlass_dir\", \"worker_start_method\", \"compile_threads\", \"post_grad_custom_post_pass\", \"post_grad_custom_pre_pass\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\", \"always_complex_memory_overlap_TESTING_ONLY\", \"fx_graph_cache\", \"fx_graph_remote_cache\", \"autotune_local_cache\", \"autotune_remote_cache\"], \"_collective.auto_select\": false, \"_collective.one_shot_all_reduce_threshold_bytes\": 131072, \"_fuse_ddp_bucket_size\": 25, \"_fuse_ddp_communication\": false, \"_fuse_ddp_communication_passes\": [\"fuse_ddp_with_concat_op\", \"schedule_comm_wait\"], \"_micro_pipeline_tp\": false, \"_post_fusion_custom_pass\": null, \"_pre_fusion_custom_pass\": null, \"_profile_var\": \"\", \"_raise_error_for_testing\": false, \"_save_config_ignore\": [\"trace.upload_tar\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"pre_grad_custom_pass\", \"aot_inductor.repro_level\", \"aot_inductor.dump_aoti_minifier\", \"post_grad_custom_pre_pass\", \"post_grad_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\"], \"add_pre_grad_passes\": null, \"aggressive_fusion\": false, \"alignment_asserts\": true, \"allow_buffer_reuse\": true, \"always_complex_memory_overlap_TESTING_ONLY\": false, \"always_keep_tensor_constants\": false, \"annotate_training\": false, \"aot_inductor.allow_stack_allocation\": false, \"aot_inductor.compile_standalone\": false, \"aot_inductor.compile_wrapper_opt_level\": \"O1\", \"aot_inductor.custom_op_libs\": null, \"aot_inductor.custom_ops_to_c_shims\": {}, \"aot_inductor.debug_compile\": false, \"aot_inductor.debug_intermediate_value_printer\": \"0\", \"aot_inductor.dump_aoti_minifier\": false, \"aot_inductor.embed_kernel_binary\": false, \"aot_inductor.emit_multi_arch_kernel\": false, \"aot_inductor.enable_lto\": false, \"aot_inductor.filtered_kernel_names\": null, \"aot_inductor.force_mmap_weights\": false, \"aot_inductor.metadata\": {}, \"aot_inductor.model_name_for_generated_files\": null, \"aot_inductor.output_path\": \"\", \"aot_inductor.package\": false, \"aot_inductor.package_constants_in_so\": true, \"aot_inductor.package_constants_on_disk\": false, \"aot_inductor.package_cpp_only\": null, \"aot_inductor.precompile_headers\": true, \"aot_inductor.presets\": {}, \"aot_inductor.raise_error_on_ignored_optimization\": true, \"aot_inductor.repro_level\": 2, \"aot_inductor.serialized_in_spec\": \"\", \"aot_inductor.serialized_out_spec\": \"\", \"aot_inductor.use_consts_asm_build\": true, \"aot_inductor.use_minimal_arrayref_interface\": false, \"aot_inductor.use_runtime_constant_folding\": false, \"aot_inductor.weight_use_caching_allocator\": false, \"assert_indirect_indexing\": true, \"assume_aligned_inputs\": false, \"assume_unaligned_fallback_output\": false, \"autoheuristic_collect\": \"\", \"autoheuristic_log_path\": \"DEFAULT\", \"autoheuristic_use\": \"mixed_mm\", \"autotune_fallback_to_aten\": false, \"autotune_in_subproc\": false, \"autotune_local_cache\": true, \"autotune_lookup_table\": {}, \"autotune_multi_device\": false, \"autotune_num_choices_displayed\": 10, \"autotune_remote_cache\": null, \"b2b_gemm_pass\": false, \"batch_fusion\": true, \"benchmark_combo_kernel\": false, \"benchmark_epilogue_fusion\": true, \"benchmark_fusion\": false, \"benchmark_harness\": true, \"benchmark_kernel\": false, \"bfloat16_atomic_adds_enabled\": true, \"bucket_all_gathers_fx\": \"none\", \"bucket_all_gathers_fx_bucket_size_determinator\": null, \"bucket_reduce_scatters_fx\": \"none\", \"bucket_reduce_scatters_fx_bucket_size_determinator\": null, \"bundle_triton_into_fx_graph_cache\": true, \"bundled_autotune_remote_cache\": null, \"bw_outputs_user_visible\": true, \"can_inplace_pad_graph_input\": false, \"check_stack_no_cycles_TESTING_ONLY\": false, \"combo_kernel_allow_mixed_sizes\": 1, \"combo_kernel_foreach_dynamic_shapes\": true, \"combo_kernels\": false, \"combo_kernels_autotune\": 1, \"comment_origin\": false, \"compile_threads\": 32, \"comprehensive_padding\": true, \"compute_all_bounds\": false, \"constant_and_index_propagation\": true, \"conv_1x1_as_mm\": false, \"coordinate_descent_check_all_directions\": false, \"coordinate_descent_search_radius\": 1, \"coordinate_descent_tuning\": false, \"cpp.cxx\": [null, \"g++\"], \"cpp.descriptive_names\": \"original_aten\", \"cpp.dynamic_threads\": false, \"cpp.enable_concat_linear\": false, \"cpp.enable_floating_point_contract_flag\": \"off\", \"cpp.enable_grouped_gemm_template\": false, \"cpp.enable_kernel_profile\": false, \"cpp.enable_loop_tail_vec\": true, \"cpp.enable_tiling_heuristics\": true, \"cpp.enable_unsafe_math_opt_flag\": false, \"cpp.fallback_scatter_reduce_sum\": true, \"cpp.force_inline_kernel\": false, \"cpp.gemm_cache_blocking\": null, \"cpp.gemm_max_k_slices\": 1, \"cpp.gemm_thread_factors\": null, \"cpp.inject_log1p_bug_TESTING_ONLY\": null, \"cpp.inject_relu_bug_TESTING_ONLY\": null, \"cpp.max_horizontal_fusion_size\": 16, \"cpp.min_chunk_size\": 512, \"cpp.no_redundant_loops\": true, \"cpp.simdlen\": null, \"cpp.threads\": -1, \"cpp.use_decompose_tanh\": false, \"cpp.use_small_dequant_buffer\": false, \"cpp.vec_isa_ok\": null, \"cpp.weight_prepack\": true, \"cpp_cache_precompile_headers\": true, \"cpp_wrapper\": false, \"cpp_wrapper_build_separate\": false, \"cpu_backend\": \"cpp\", \"cuda.arch\": null, \"cuda.binary_remote_cache_force_write\": false, \"cuda.compile_opt_level\": \"-O1\", \"cuda.cuda_cxx\": null, \"cuda.cutlass_backend_min_gemm_size\": 1, \"cuda.cutlass_dir\": \"/home/skarjala/pytorch/third_party/cutlass\", \"cuda.cutlass_enabled_ops\": \"all\", \"cuda.cutlass_epilogue_fusion_enabled\": false, \"cuda.cutlass_hash_with_compile_cmd\": false, \"cuda.cutlass_instantiation_level\": \"0\", \"cuda.cutlass_max_profiling_configs\": null, \"cuda.cutlass_max_profiling_swizzle_options\": [1, 2, 4, 8], \"cuda.cutlass_op_allowlist_regex\": null, \"cuda.cutlass_op_denylist_regex\": null, \"cuda.cutlass_prescreening\": true, \"cuda.cutlass_presets\": null, \"cuda.cutlass_tma_only\": false, \"cuda.enable_caching_codegen\": true, \"cuda.enable_cuda_lto\": false, \"cuda.enable_debug_info\": false, \"cuda.enable_ptxas_info\": false, \"cuda.generate_test_runner\": false, \"cuda.upload_to_binary_remote_cache\": false, \"cuda.use_binary_remote_cache\": true, \"cuda.use_fast_math\": false, \"cuda.version\": null, \"cuda_backend\": \"triton\", \"dce\": false, \"debug\": false, \"debug_fusion\": false, \"debug_index_asserts\": false, \"debug_ir_traceback\": false, \"decompose_mem_bound_mm\": false, \"developer_warnings\": true, \"disable_cpp_codegen\": false, \"disable_padding_cpu\": true, \"disable_progress\": true, \"dynamic_scale_rblock\": true, \"efficient_conv_bn_eval_fx_passes\": false, \"emulate_precision_casts\": false, \"enable_auto_functionalized_v2\": true, \"enable_caching_generated_triton_templates\": true, \"enable_linear_binary_folding\": false, \"enabled_metric_tables\": \"\", \"epilogue_fusion\": true, \"epilogue_fusion_first\": false, \"estimate_op_runtime\": \"default\", \"external_matmul\": [], \"fallback_random\": false, \"force_fuse_int_mm_with_mul\": false, \"force_layout_optimization\": false, \"force_pointwise_cat\": false, \"force_same_precision\": false, \"force_shape_pad\": false, \"freezing\": false, \"freezing_discard_parameters\": false, \"fx_graph_cache\": true, \"fx_graph_remote_cache\": null, \"fx_passes_numeric_check\": {\"num_iterations\": 1, \"pre_grad\": false, \"precision\": 0.0001, \"requires_optimizer\": true}, \"generate_intermediate_hooks\": false, \"global_cache_dir\": null, \"graph_partition\": false, \"group_fusion\": false, \"halide.asserts\": false, \"halide.cpu_target\": \"host\", \"halide.debug\": false, \"halide.gpu_target\": \"host-cuda\", \"halide.scan_kernels\": false, \"halide.scheduler_cpu\": \"Adams2019\", \"halide.scheduler_cuda\": \"Anderson2021\", \"implicit_fallbacks\": true, \"inplace_buffers\": true, \"inplace_padding\": true, \"inter_node_bw\": 25, \"intra_node_bw\": 300, \"is_nightly_or_source\": true, \"is_predispatch\": false, \"joint_custom_post_pass\": null, \"joint_custom_pre_pass\": null, \"joint_graph_constant_folding\": true, \"keep_output_stride\": true, \"kernel_name_max_ops\": 10, \"layout_opt_default\": \"1\", \"layout_optimization\": true, \"loop_ordering_after_fusion\": false, \"max_autotune\": false, \"max_autotune_conv_backends\": \"ATEN,TRITON\", \"max_autotune_flex_search_space\": \"DEFAULT\", \"max_autotune_gemm\": false, \"max_autotune_gemm_backends\": \"ATEN,TRITON,CPP\", \"max_autotune_gemm_search_space\": \"DEFAULT\", \"max_autotune_pointwise\": false, \"max_autotune_report_choices_stats\": true, \"max_autotune_subproc_graceful_timeout_seconds\": 0.0, \"max_autotune_subproc_result_timeout_seconds\": 60.0, \"max_autotune_subproc_terminate_timeout_seconds\": 0.0, \"max_epilogue_benchmarked_choices\": 1, \"max_fusion_buffer_group_pairwise_attempts\": 64, \"max_fusion_size\": 64, \"max_pointwise_cat_inputs\": 8, \"memory_planning\": false, \"memory_pool\": \"intermediates\", \"min_num_split\": 0, \"mixed_mm_choice\": \"heuristic\", \"multi_kernel_hints\": [], \"nan_asserts\": false, \"non_blocking_remote_cache_write\": true, \"online_softmax\": true, \"optimize_scatter_upon_const_tensor\": true, \"pad_channels_last\": false, \"pad_outputs\": false, \"padding_alignment_bytes\": 128, \"padding_stride_threshold\": 1024, \"pattern_matcher\": true, \"permute_fusion\": false, \"pick_loop_orders\": true, \"post_grad_custom_post_pass\": null, \"post_grad_custom_pre_pass\": null, \"post_grad_fusion_options\": {}, \"pre_grad_custom_pass\": null, \"pre_grad_fusion_options\": {}, \"precompilation_timeout_seconds\": 3600, \"profile_bandwidth\": false, \"profile_bandwidth_output\": null, \"profile_bandwidth_regex\": \"\", \"profile_bandwidth_with_do_bench_using_profiling\": false, \"profiler_mark_wrapper_call\": false, \"prologue_fusion\": true, \"quiesce_async_compile_pool\": false, \"realize_acc_reads_size_threshold\": null, \"realize_acc_reads_threshold\": 8, \"realize_opcount_threshold\": 30, \"realize_reads_threshold\": 4, \"remove_pre_grad_passes\": null, \"reorder_for_compute_comm_overlap\": false, \"reorder_for_compute_comm_overlap_passes\": [\"reorder_compute_for_overlap\", \"sink_waits\", \"raise_comms\"], \"reorder_for_locality\": true, \"reorder_for_peak_memory\": true, \"reorder_prefetch_limit\": null, \"rocm.arch\": [], \"rocm.ck_dir\": null, \"rocm.ck_max_profiling_configs\": null, \"rocm.ck_supported_arch\": [\"gfx90a\", \"gfx942\", \"gfx950\"], \"rocm.ck_tile_max_profiling_configs\": null, \"rocm.compile_opt_level\": \"-O2\", \"rocm.flush_denormals\": true, \"rocm.generate_test_runner\": false, \"rocm.is_debug\": false, \"rocm.kBatch_sweep\": null, \"rocm.n_max_profiling_configs\": null, \"rocm.print_kernel_resource_usage\": false, \"rocm.rocm_home\": null, \"rocm.save_temps\": false, \"rocm.split_k_threshold\": 16, \"rocm.use_fast_math\": true, \"rocm.use_preselected_instances\": false, \"save_args\": false, \"scalar_asserts\": true, \"score_fusion_memory_threshold\": 10, \"search_autotune_cache\": false, \"shape_padding\": true, \"size_asserts\": true, \"sleep_sec_TESTING_ONLY\": null, \"split_cat_fx_passes\": true, \"split_reductions\": true, \"static_launch_user_defined_triton_kernels\": false, \"static_weight_shapes\": true, \"strict_static_cuda_launcher\": false, \"test_configs.autotune_choice_desc_regex\": null, \"test_configs.autotune_choice_name_regex\": null, \"test_configs.force_extern_kernel_in_multi_template\": false, \"test_configs.graphsafe_rng_func_ignores_fallback_random\": false, \"test_configs.max_mm_configs\": null, \"test_configs.runtime_triton_dtype_assert\": false, \"test_configs.static_cpp_dtype_assert\": false, \"trace.compile_profile\": false, \"trace.debug_dir\": null, \"trace.debug_log\": false, \"trace.dot_graph_shape\": null, \"trace.draw_orig_fx_graph\": false, \"trace.enabled\": true, \"trace.fx_graph\": true, \"trace.fx_graph_transformed\": true, \"trace.graph_diagram\": false, \"trace.info_log\": false, \"trace.ir_post_fusion\": true, \"trace.ir_pre_fusion\": true, \"trace.log_autotuning_results\": false, \"trace.log_url_for_graph_xform\": null, \"trace.output_code\": true, \"trace.provenance_tracking\": true, \"trace.save_real_tensors\": false, \"trace.upload_tar\": null, \"triton.autotune_at_compile_time\": null, \"triton.autotune_cublasLt\": true, \"triton.autotune_pointwise\": true, \"triton.autotune_with_sample_inputs\": false, \"triton.coalesce_tiling_analysis\": true, \"triton.codegen_upcast_to_fp32\": true, \"triton.cooperative_reductions\": false, \"triton.cudagraph_capture_sizes\": null, \"triton.cudagraph_dynamic_shape_warn_limit\": 50, \"triton.cudagraph_skip_dynamic_graphs\": false, \"triton.cudagraph_support_input_mutation\": true, \"triton.cudagraph_trees\": true, \"triton.cudagraph_trees_history_recording\": false, \"triton.cudagraph_unexpected_rerecord_limit\": 128, \"triton.cudagraphs\": false, \"triton.debug_sync_graph\": false, \"triton.debug_sync_kernel\": false, \"triton.decompose_k_threshold\": 32, \"triton.dense_indexing\": false, \"triton.descriptive_names\": \"original_aten\", \"triton.disallow_failing_autotune_kernels_TESTING_ONLY\": false, \"triton.divisible_by_16\": true, \"triton.enable_persistent_tma_matmul\": false, \"triton.fast_path_cudagraph_asserts\": false, \"triton.force_cooperative_reductions\": false, \"triton.force_cudagraph_sync\": false, \"triton.force_cudagraphs_warmup\": false, \"triton.inject_relu_bug_TESTING_ONLY\": null, \"triton.max_tiles\": null, \"triton.min_split_scan_rblock\": 256, \"triton.multi_kernel\": 0, \"triton.num_decompose_k_splits\": 10, \"triton.persistent_reductions\": true, \"triton.prefer_nd_tiling\": false, \"triton.skip_cudagraph_warmup\": false, \"triton.skip_l1_cache\": false, \"triton.slow_path_cudagraph_asserts\": true, \"triton.spill_threshold\": 16, \"triton.store_cubin\": false, \"triton.tile_reductions\": false, \"triton.tiling_prevents_pointwise_fusion\": true, \"triton.tiling_prevents_reduction_fusion\": true, \"triton.unique_kernel_names\": true, \"triton.unique_user_kernel_names\": false, \"triton.use_block_ptr\": false, \"triton.use_tensor_descriptor\": false, \"triton_kernel_default_layout_constraint\": \"needs_fixed_stride_order\", \"unbacked_symint_fallback\": 8192, \"unroll_reductions_threshold\": 8, \"unsafe_ignore_unsupported_triton_autotune_args\": false, \"unsafe_marked_cacheable_functions\": {}, \"unsafe_skip_cache_dynamic_shape_guards\": false, \"use_experimental_benchmarker\": true, \"use_fast_math\": false, \"use_mixed_mm\": true, \"use_static_cuda_launcher\": true, \"verbose_progress\": false, \"warn_mix_layout\": false, \"worker_start_method\": \"subprocess\", \"worker_suppress_logging\": true}", "remote_cache_version": null, "inductor_fx_remote_cache_hit_count": null, "inductor_fx_remote_cache_miss_count": null, "inductor_fx_remote_cache_backend_type": null, "inductor_fx_remote_cache_hit_keys": null, "inductor_fx_remote_cache_miss_keys": null, "cuda_version": "12.4", "triton_version": "3.4.0", "feature_usage": null, "compile_time_autotune_time_us": null, "is_runtime": true, "gc_time_us": null, "tensorify_float_attempt": null, "tensorify_float_success": null, "tensorify_float_failure": null, "guard_latency_us": null, "recompile_reason": null, "num_graph_breaks": null, "triton_kernel_compile_times_us": null, "ir_count": null, "cudagraph_skip_reason": null, "python_version": "3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]", "pgo_put_remote_code_state_time_us": null, "pgo_get_remote_code_state_time_us": null, "param_numel": null, "param_bytes": null, "param_count": null, "recompile_user_contexts": null}, "rank": 3, "frame_id": 0, "frame_compile_id": 1}
V0804 12:34:16.314000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "7c90a21f65537fe33bd4da7786393ffb"}
	{
	"name": "dynamo",
	"ts": 1754336056313939.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.314000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "47c40858947eb348e0dc5db36fb282e9"}
	{
	"name": "entire_frame_compile",
	"ts": 1754336056314332.0,
	"args": {
	"fn_name": "_compile.compile_inner",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.315000 1142858 torch/_dynamo/guards.py:3824] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "7dde321851e25222fcdf3cd24a328e08"}
	[
	"0/0: ___check_obj_id(fn, 139645370122560)                   "
	]
V0804 12:34:16.315000 1142858 torch/_dynamo/convert_frame.py:231] {"dynamo_start": {"stack": [{"line": 191, "name": "<module>", "filename": 1, "loc": "main()"}, {"line": 165, "name": "main", "filename": 1, "loc": "_ = compiled_graph_one(x, y, world_size)"}, {"line": 804, "name": "compile_wrapper", "filename": 2, "loc": "return fn(*args, **kwargs)"}, {"line": 66, "name": "inner", "filename": 3}]}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.315000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "d30538d5b5348faacbd331f749954da1"}
	{
	"name": "compile_attempt_0",
	"ts": 1754336056315927.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.317000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "d366bef3b9e6e50ef36d2283ae9dd85c"}
	{
	"name": "bytecode_tracing",
	"ts": 1754336056317708.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.325000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 0, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.326000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1024, 1], "storage": 0, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0275d78370>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.326000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 0, "source": "L['fn'].__self__._modules['lin1']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.328000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 1, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.329000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "stride": [1024, 1], "storage": 1, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Tensor object at 0x7f02578e68a0>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.329000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 1, "source": "L['args'][0]"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.337000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 2, "describer_id": 7, "size": 2048}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.338000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 2, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0276252c60>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.338000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 3, "source": "L['fn'].__self__._modules['norm']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.340000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 3, "describer_id": 7, "size": 2048}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.340000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 3, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f02762520d0>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.341000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 4, "source": "L['fn'].__self__._modules['norm']._parameters['bias']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.363000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 4, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.363000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 15, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1024, 1], "storage": 4, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0276250c80>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.364000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 15, "source": "L['fn'].__self__._modules['lin2']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.373000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 5, "describer_id": 7, "size": 4194304}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.373000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 19, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [2048, 1024], "is_leaf": true, "stride": [1024, 1], "storage": 5, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Tensor object at 0x7f0276250690>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.374000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 19, "source": "L['args'][1]"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:16.380000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5280f2dfd9df0aa55464b0bd925840f8"}
	{
	"name": "bytecode_tracing",
	"ts": 1754336056380758.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.385000 1142858 torch/_dynamo/output_graph.py:1686] {"dynamo_output_graph": {"sizes": {"l_fn_self_modules_lin1_parameters_weight_": [1024, 1024], "l_args_0_": [1024, 1024], "l_fn_self_modules_norm_parameters_weight_": [1024], "l_fn_self_modules_norm_parameters_bias_": [1024], "l_fn_self_modules_lin2_parameters_weight_": [1024, 1024], "l_args_1_": [2048, 1024], "h": [1024, 1024], "h_1": [1024, 1024], "h_2": [1024, 1024], "all_reduce_default": [1024, 1024], "h_3": [1024, 1024], "h2": [1024, 1024], "h2_1": [1024, 1024], "all_gather_into_tensor_default": [2048, 1024], "gathered": [2048, 1024], "g": [2048, 1024], "reduce_scatter_tensor_default": [1024, 1024], "rs": [1024, 1024], "rs_expanded": [2048, 1024], "out": [2048, 1024]}}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "a887576c59d8b651fcb075634b10ab10"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
V0804 12:34:16.386000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "2be60ddb9bc5333c2c380c178be9bbaa"}
	{
	"name": "backend_compile",
	"ts": 1754336056386431.8,
	"args": {
	"fn_name": "OutputGraph.call_user_compiler",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.388000 1142858 torch/_inductor/compile_fx.py:2185] {"artifact": {"name": "before_pre_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "9f30354df593b94d410ba0c8b868cf1d"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
	
	 # graph id: 139645242301984
V0804 12:34:16.388000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "9f6e9cb61b8237dce327a717ec937586"}
	{
	"name": "_recursive_pre_grad_passes",
	"ts": 1754336056388510.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.389000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "0d1b28d37d9e0bbbc36cc9e003a76368"}
	{
	"name": "_recursive_pre_grad_passes",
	"ts": 1754336056389709.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.391000 1142858 torch/_inductor/compile_fx.py:2216] {"artifact": {"name": "after_pre_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "9f30354df593b94d410ba0c8b868cf1d"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
	
	 # graph id: 139645242301984
V0804 12:34:16.406000 1142858 torch/_dynamo/utils.py:1970] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "9a6a23ab58ab474257f3a4e893130f53"}
	{
	"name": "autograd_cache_miss",
	"ts": 1754336056406148.5,
	"args": {
	"cache_status_detailed": "full_miss",
	"key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp",
	"cache_state": "miss",
	"components": [
	"[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False",
	"[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>",
	"[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])",
	"[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"compile_id": "0/1"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0804 12:34:16.407000 1142858 torch/_functorch/_aot_autograd/autograd_cache.py:1231] {"artifact": {"name": "aotautograd_cache_miss", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "788d107aba066052e238c3a6e11503b1"}
	{"cache_status_detailed": "full_miss", "key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp", "cache_state": "miss", "components": ["[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False", "[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>", "[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])", "[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ", "[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)", "[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>", "[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}", "[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}", "[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False", "[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10", "[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True", "[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']", "[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None", "[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op", "[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait", "[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"], "compile_id": "0/1"}
V0804 12:34:16.408000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "2672a8794196028615a8c5dc0cd4545d"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1754336056408019.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.411000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "37dbf44617e2cc9cf4cb8f87dcd2168b"}
	{
	"name": "aot_collect_metadata",
	"ts": 1754336056411498.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.430000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "b4dd7b13c294c54c6c350813d71e311f"}
	{
	"name": "aot_collect_metadata",
	"ts": 1754336056430062.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.489000 1142858 torch/_functorch/_aot_autograd/graph_capture.py:301] {"artifact": {"name": "aot_forward_graph_fw_metadata", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "083ebbd57ef41f8da24878484b104f67"}
	ViewAndMutationMeta(input_info=[InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=False,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=False,
	                                              keep_input_mutations=True)],
	                    output_info=[OutputAliasInfo(output_type=<OutputType.non_alias: 1>,
	                                                raw_type=<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,
	                                                base_idx=None,
	                                                dynamic_dims=set(),
	                                                requires_grad=False,
	                                                functional_tensor=None)],
	                    num_intermediate_bases=0,
	                    keep_input_mutations=True,
	                    traced_tangents=[],
	                    traced_tangents_descs=[],
	                    subclass_inp_meta=[PlainTensorMeta(unwrapped_idx=0,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=1,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=2,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=3,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=4,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=5,
	                                                      memory_format=None)],
	                    subclass_fw_graph_out_meta=[PlainTensorMeta(unwrapped_idx=0,
	                                                               memory_format=None)],
	                    subclass_tangent_meta=[],
	                    is_train=False,
	                    traced_tangent_metas=None,
	                    num_symints_saved_for_bw=None,
	                    grad_enabled_mutation=None,
	                    deterministic=False,
	                    static_input_indices=[0, 2, 3, 4],
	                    tokens={},
	                    indices_of_inputs_that_requires_grad_with_mutations_in_bw=[],
	                    bw_donated_idxs=None,
	                    num_backward_tokens=0,
	                    num_graphsafe_rng_states=0,
	                    graphsafe_rng_state_index=None)
V0804 12:34:16.491000 1142858 torch/_functorch/_aot_autograd/graph_capture.py:319] {"aot_inference_graph": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "11e47da400b78de48aca98e293efdee2"}
	class <lambda>(torch.nn.Module):
	    def forward(
	        self,
	        arg0_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=0)
	        arg1_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=1)
	        arg2_1: "f16[1024][1]cuda:1",  # PlainAOTInput(idx=2)
	        arg3_1: "f16[1024][1]cuda:1",  # PlainAOTInput(idx=3)
	        arg4_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=4)
	        arg5_1: "f16[2048, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=5)
	    ):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        convert_element_type_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul_2, torch.float16);  mul_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        convert_element_type_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(convert_element_type_3, torch.float32);  convert_element_type_3 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_4, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(convert_element_type_4, getitem_1);  convert_element_type_4 = getitem_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (
	            add_3,  # PlainAOTOutput(idx=0)
	        )
	        
V0804 12:34:16.494000 1142858 torch/_functorch/_aot_autograd/graph_compile.py:285] {"artifact": {"name": "torch._functorch.config", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "7b8fae87b220765c393a4321db77304b"}
	{
	"TYPE_CHECKING": false,
	"functionalize_rng_ops": false,
	"fake_tensor_allow_meta": true,
	"debug_assert": false,
	"debug_partitioner": true,
	"decompose_custom_triton_ops": true,
	"static_weight_shapes": true,
	"treat_parameters_as_free_to_save": true,
	"cse": true,
	"enable_autograd_cache": true,
	"autograd_cache_allow_custom_autograd_functions": false,
	"bundled_autograd_cache": false,
	"autograd_cache_normalize_inputs": true,
	"enable_remote_autograd_cache": null,
	"view_replay_for_aliased_outputs": true,
	"max_dist_from_bw": 1000,
	"ban_recompute_used_far_apart": true,
	"ban_recompute_long_fusible_chains": true,
	"ban_recompute_materialized_backward": true,
	"ban_recompute_not_in_allowlist": true,
	"ban_recompute_reductions": true,
	"recompute_views": false,
	"activation_memory_budget": 1.0,
	"activation_memory_budget_runtime_estimator": "flops",
	"activation_memory_budget_solver": "dp",
	"visualize_memory_budget_pareto": false,
	"memory_budget_pareto_dir": null,
	"aggressive_recomputation": false,
	"fake_tensor_allow_unsafe_data_ptr_access": true,
	"unlift_effect_tokens": true,
	"custom_op_default_layout_constraint": "needs_exact_strides",
	"fake_tensor_crossref": false,
	"fake_tensor_propagate_real_tensors": false,
	"backward_pass_autocast": "same_as_forward",
	"donated_buffer": true,
	"torch_compile_graph_format": "svg",
	"generate_fake_kernels_from_real_mismatches": false,
	"graphsafe_rng_functionalization": true,
	"strict_autograd_cache": false,
	"unsafe_allow_optimization_of_collectives": false,
	"disable_guess_zero_tangent_for_mutated_input_subclass": false,
	"guess_tangent_strides_as_outputs": false,
	"_sync_decision_cross_ranks": false,
	"saved_tensors_hooks_filtering_mode": "donated"
	}
V0804 12:34:16.494000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "90d6ee195e45d620693546d5a31f80d7"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1754336056494891.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.495000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "a745cad32948a652f398e9732e150a31"}
	{
	"name": "_recursive_joint_graph_passes",
	"ts": 1754336056495829.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.499000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "0375ea534b3c7296346d7d52154cb3e0"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056499276.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.499000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5ff2046b3b8de35076afe914b1ad0582"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056499864.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.500000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "a4c9e1e03b6b998c7524a61aa4d56d98"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056500562.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.501000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "78f3cf7069e6fafb287e6822cc6054be"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056501055.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.502000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "870b6872e1d05e7fc333bf822a90f062"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056502713.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.503000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "2162fddf032e66b24405540862f234d7"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056503290.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.504000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "623f6ee68cae3e526ccdccbe048ac375"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056503946.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.504000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "6c436b15a2c5c82cedf0ab24a18c5a94"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056504654.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.506000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "d524e3c70c61cd1422f2543f01744d21"}
	{
	"name": "_recursive_joint_graph_passes",
	"ts": 1754336056506002.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.506000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "aa3d7f9f3a5df299acc578e9c36d5736"}
	{
	"name": "inductor_compile",
	"ts": 1754336056506517.2,
	"args": {
	"fn_name": "compile_fx_inner",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.508000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "17532b2e7096e364ab2621f72faf8e2b"}
	{
	"name": "fx_codegen_and_compile",
	"ts": 1754336056508161.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.521000 1142858 torch/_inductor/compile_fx.py:1218] {"artifact": {"name": "fx_graph_runnable", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "c8dffcf090b13a05ef569d7c2e98e0ff"}
	
	import os
	os.environ['TORCH_TRACE'] = '1'
	os.environ['TORCHELASTIC_RESTART_COUNT'] = '0'
	os.environ['TORCHELASTIC_MAX_RESTARTS'] = '0'
	os.environ['TORCHELASTIC_RUN_ID'] = 'none'
	os.environ['TORCHELASTIC_USE_AGENT_STORE'] = 'True'
	os.environ['TORCH_NCCL_ASYNC_ERROR_HANDLING'] = '1'
	os.environ['TORCHELASTIC_ERROR_FILE'] = '/tmp/torchelastic_krot7efo/none_58jhr50i/attempt_0/1/error.json'
	os.environ['TORCH_COMPILE_DEBUG'] = '1'
	os.environ['TORCH_LOGS_FORMAT'] = '[%(filename)s:%(lineno)d %(levelname)s] %(message)s'
	os.environ['TORCH_LOGS_OUT'] = '/dev/stdout'
	os.environ['TORCHINDUCTOR_CACHE_DIR'] = '/tmp/torchinductor_cache'
	os.environ['TRITON_CACHE_DIR'] = '/tmp/torchinductor_cache/triton/1'
	
	import torch
	from torch import tensor, device
	import torch.fx as fx
	from torch._dynamo.testing import rand_strided
	from math import inf
	import torch._inductor.inductor_prims
	import torch.distributed as dist
	from torch.testing._internal.distributed.fake_pg import FakeStore
	
	import torch._dynamo.config
	import torch._inductor.config
	import torch._functorch.config
	import torch.fx.experimental._config
	
	torch._inductor.config.triton.store_cubin = False
	torch._inductor.config.trace.enabled = True
	torch._inductor.config.trace.save_real_tensors = False
	torch._functorch.config.functionalize_rng_ops = False
	torch._functorch.config.debug_partitioner = True
	torch._functorch.config.fake_tensor_allow_unsafe_data_ptr_access = True
	torch._functorch.config.unlift_effect_tokens = True
	
	
	
	isolate_fails_code_str = None
	
	
	
	
	# torch version: 2.9.0a0+git2249284
	# torch cuda version: 12.4
	# torch git version: 22492848b66f13637b01a4d8f98a16e3004940a9
	
	
	# CUDA Info: 
	# nvcc: NVIDIA (R) Cuda compiler driver 
	# Copyright (c) 2005-2024 NVIDIA Corporation 
	# Built on Thu_Mar_28_02:18:24_PDT_2024 
	# Cuda compilation tools, release 12.4, V12.4.131 
	# Build cuda_12.4.r12.4/compiler.34097967_0 
	
	# GPU Hardware Info: 
	# NVIDIA PG509-210 : 2 
	
	
	from torch.nn import *
	class Repro(torch.nn.Module):
	    def __init__(self) -> None:
	        super().__init__()
	
	    
	    
	    def forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):
	        permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)
	        getitem = var_mean[0]
	        getitem_1 = var_mean[1];  var_mean = None
	        add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None
	        mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
	def load_args(reader):
	    buf0 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf0, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg0_1
	    buf1 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf1, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg1_1
	    buf2 = reader.storage(None, 2048, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf2, (1024,), dtype=torch.float16, is_leaf=True)  # arg2_1
	    buf3 = reader.storage(None, 2048, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf3, (1024,), dtype=torch.float16, is_leaf=True)  # arg3_1
	    buf4 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf4, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg4_1
	    buf5 = reader.storage(None, 4194304, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf5, (2048, 1024), dtype=torch.float16, is_leaf=True)  # arg5_1
	load_args._version = 0
	mod = Repro()
	if __name__ == '__main__':
	    from torch._dynamo.repro.after_aot import run_repro
	    # Initialize FakeProcessGroup for distributed operations
	    store = FakeStore()
	    dist.init_process_group(
	        backend="fake",
	        rank=0,
	        world_size=2,
	        store=store
	    )
	    with torch.no_grad():
	        run_repro(mod, load_args, accuracy=False, command='run', save_dir=None, tracing_mode='real', check_str=None)
	        # To run it separately, do 
	        # mod, args = run_repro(mod, load_args, accuracy=False, command='get_args', save_dir=None, tracing_mode='real', check_str=None)
	        # mod(*args)
	    dist.destroy_process_group()
	
V0804 12:34:16.525000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "890cf167d834bdb0fd317483764155dd"}
	{
	"name": "additional_fake_tensor_prop",
	"ts": 1754336056525165.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.541000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "d5b6e6d2824fe175227f4f7635f712d4"}
	{
	"name": "additional_fake_tensor_prop",
	"ts": 1754336056541768.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.544000 1142858 torch/_inductor/compile_fx.py:1267] {"artifact": {"name": "before_post_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "97a46234dae257bf8fd40d911b84825f"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f16[1024, 1024][1024, 1]cuda:1", arg1_1: "f16[1024, 1024][1024, 1]cuda:1", arg2_1: "f16[1024][1]cuda:1", arg3_1: "f16[1024][1]cuda:1", arg4_1: "f16[1024, 1024][1024, 1]cuda:1", arg5_1: "f16[2048, 1024][1024, 1]cuda:1"):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        convert_element_type_default: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
V0804 12:34:16.544000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "138b38f013feea2c2810d94ad007029a"}
	{
	"name": "_recursive_post_grad_passes",
	"ts": 1754336056544536.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.551000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "831c49aa2f1d0d302e85378c26b2a1ba"}
	{
	"name": "_recursive_post_grad_passes",
	"ts": 1754336056551269.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.554000 1142858 torch/_inductor/compile_fx.py:1305] {"artifact": {"name": "after_post_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "ed435d7c02e74345e0a9c2504ca76b90"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f16[1024, 1024][1024, 1]cuda:1", arg1_1: "f16[1024, 1024][1024, 1]cuda:1", arg2_1: "f16[1024][1]cuda:1", arg3_1: "f16[1024][1]cuda:1", arg4_1: "f16[1024, 1024][1024, 1]cuda:1", arg5_1: "f16[2048, 1024][1024, 1]cuda:1"):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        var_mean = torch.ops.aten.var_mean.correction(mul_2, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(mul_2, getitem_1);  mul_2 = getitem_1 = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce_.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
V0804 12:34:16.555000 1142858 torch/_inductor/compile_fx.py:1317] {"artifact": {"name": "inductor_post_to_pre_grad_nodes", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5385faa7da9add5b8aed080ce40f0a99"}
	{"permute": [{"name": "h", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm": [{"name": "h", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_2": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "erf": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default", "target": "prims.convert_element_type.default", "graph_id": 139644951478880, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_4", "target": "prims.convert_element_type.default", "graph_id": 139644951478880, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}], "var_mean": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_1": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_3": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_4": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_5": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "all_reduce": [{"name": "all_reduce_default", "target": "_c10d_functional.all_reduce.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor": [{"name": "h_3", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_1": [{"name": "h2", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_1": [{"name": "h2", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "relu": [{"name": "h2_1", "target": "<function relu at 0x7f01fe16da80>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "all_gather_into_tensor": [{"name": "all_gather_into_tensor_default", "target": "_c10d_functional.all_gather_into_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "reduce_scatter_tensor": [{"name": "reduce_scatter_tensor_default", "target": "_c10d_functional.reduce_scatter_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor_1": [{"name": "gathered", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_5": [{"name": "g", "target": "<built-in function mul>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor_2": [{"name": "rs", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "repeat": [{"name": "rs_expanded", "target": "repeat", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3": [{"name": "out", "target": "<built-in function add>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}
V0804 12:34:16.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "f75821924e9c2353b4f3946eb6d366e4"}
	{
	"name": "GraphLowering.run",
	"ts": 1754336056556702.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.609000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5d5a2e0aa081fdb84e1a9f7dcc0b0de4"}
	{
	"name": "GraphLowering.run",
	"ts": 1754336056609207.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.609000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "707c9051d9f97b6d7cd849b21b3d3fc7"}
	{
	"name": "GraphLowering.compile_to_fn",
	"ts": 1754336056609873.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.610000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5da1bf862b530ce7c88172e7faecf15c"}
	{
	"name": "code_gen",
	"ts": 1754336056610300.5,
	"args": {
	"fn_name": "GraphLowering.compile_to_module",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.610000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "54f75962f2756f3767b9eca10b5d9572"}
	{
	"name": "GraphLowering.codegen",
	"ts": 1754336056610684.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.612000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "cac084576df4ba9a7be6fb75151dfe66"}
	{
	"name": "Scheduler.__init__",
	"ts": 1754336056611882.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "446e4d8da5f2286816636dc91a4f1bc4"}
	{
	"name": "Scheduler.fused_nodes",
	"ts": 1754336056685976.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.691000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "ebb17982755a3bdc3fcad80ac6e602d7"}
	{
	"name": "Scheduler.fused_nodes",
	"ts": 1754336056691301.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.709000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "a0caa68cff431e5beac07b0edf24a84d"}
	{
	"name": "Scheduler.__init__",
	"ts": 1754336056709536.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.710000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "313d0d26537e0a05ef7d76bb2de559a4"}
	{
	"name": "Scheduler.codegen",
	"ts": 1754336056709973.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.789000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "6fcfa50a2cd6a4efe8f8743fb05ecb52"}
	{
	"name": "Scheduler.codegen",
	"ts": 1754336056789863.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.790000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "f5204ac80a5d2e97475762d96f156661"}
	{
	"name": "PythonWrapperCodegen.generate",
	"ts": 1754336056790474.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.797000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "4f5733ae18760680d73c9df46e2033c5"}
	{
	"name": "PythonWrapperCodegen.generate",
	"ts": 1754336056797837.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.798000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "c533d8799308abcb9db51d192da55f1a"}
	{
	"name": "GraphLowering.codegen",
	"ts": 1754336056798311.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.799000 1142858 torch/_inductor/graph.py:2390] {"inductor_output_code": {"filename": "/tmp/torchinductor_cache/2o/c2o2b5knsvinu3iyv2ufo3zaumqmodn4ad2mi47uizpf6he7ropv.py"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "3e05e0147dcb3f5d92e520c435f93996"}
	# AOT ID: ['1_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from cmath import nanj
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	import triton
	import triton.language as tl
	from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
	from torch._C import _cuda_getCurrentRawStream as get_raw_stream
	from torch._C import _cuda_getCurrentRawStream as get_raw_stream
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	assert_alignment = torch._C._dynamo.guards.assert_alignment
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
	
	
	# kernel path: /tmp/torchinductor_cache/y5/cy5cpjsbzjqu5acybwozmucja7k3xuwvs6mwcifuppxwyfxv2xcf.py
	# Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	# Source node to ATen node mapping:
	#   all_reduce_default => all_reduce
	#   h_1 => add, convert_element_type_2, erf, mul, mul_1, mul_2
	#   h_2 => add_1, add_2, convert_element_type_5, mul_3, mul_4, rsqrt, sub, var_mean
	# Graph fragment:
	#   %mm : Tensor "f16[1024, 1024][1024, 1]cuda:1" = PlaceHolder[target=mm]
	#   %getitem_1 : Tensor "f32[1024, 1][1, 1024]cuda:1" = PlaceHolder[target=getitem_1]
	#   %buf2 : Tensor "f32[1024, 1][1, 1024]cuda:1" = PlaceHolder[target=buf2]
	#   %arg2_1 : Tensor "f16[1024][1]cuda:1" = PlaceHolder[target=arg2_1]
	#   %arg3_1 : Tensor "f16[1024][1]cuda:1" = PlaceHolder[target=arg3_1]
	#   %convert_element_type_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=2] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%mm, torch.float32), kwargs = {})
	#   %mul : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 0.5), kwargs = {})
	#   %mul_1 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 0.7071067811865476), kwargs = {})
	#   %erf : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_1,), kwargs = {})
	#   %add : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf, 1), kwargs = {})
	#   %mul_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul, %add), kwargs = {})
	#   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%mul_2, [1]), kwargs = {correction: 0, keepdim: True})
	#   %sub : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2, %getitem_1), kwargs = {})
	#   %add_1 : Tensor "f32[1024, 1][1, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem, 1e-05), kwargs = {})
	#   %rsqrt : Tensor "f32[1024, 1][1, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1,), kwargs = {})
	#   %mul_3 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, %rsqrt), kwargs = {})
	#   %mul_4 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3, %arg2_1), kwargs = {})
	#   %add_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_4, %arg3_1), kwargs = {})
	#   %convert_element_type_5 : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%add_2, torch.float16), kwargs = {})
	#   %all_reduce : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops._c10d_functional.all_reduce_.default](args = (%convert_element_type_5, sum, 0), kwargs = {})
	#   return %getitem_1,%buf2,%wait_tensor
	triton_per_fused_all_reduce_gelu_native_layer_norm_0 = async_compile.triton('triton_per_fused_all_reduce_gelu_native_layer_norm_0', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.persistent_reduction(
	    size_hints={'x': 1024, 'r0_': 1024},
	    reduction_hint=ReductionHint.INNER,
	    filename=__file__,
	    triton_meta={'signature': {'in_out_ptr0': '*fp16', 'in_ptr0': '*fp16', 'in_ptr1': '*fp16', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': True, 'num_load': 3, 'num_reduction': 4, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 0, 'r0_': 6295552}}
	)
	@triton.jit
	def triton_per_fused_all_reduce_gelu_native_layer_norm_0(in_out_ptr0, in_ptr0, in_ptr1, xnumel, r0_numel):
	    xnumel = 1024
	    XBLOCK: tl.constexpr = 1
	    r0_numel = 1024
	    R0_BLOCK: tl.constexpr = 1024
	    rnumel = r0_numel
	    RBLOCK: tl.constexpr = R0_BLOCK
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = tl.full([1], xoffset, tl.int32)
	    xmask = tl.full([R0_BLOCK], True, tl.int1)
	    r0_index = tl.arange(0, R0_BLOCK)[:]
	    r0_offset = 0
	    r0_mask = tl.full([R0_BLOCK], True, tl.int1)
	    roffset = r0_offset
	    rindex = r0_index
	    r0_1 = r0_index
	    x0 = xindex
	    tmp0 = tl.load(in_out_ptr0 + (r0_1 + 1024*x0), None).to(tl.float32)
	    tmp30 = tl.load(in_ptr0 + (r0_1), None, eviction_policy='evict_last').to(tl.float32)
	    tmp33 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last').to(tl.float32)
	    tmp1 = tmp0.to(tl.float32)
	    tmp2 = 0.5
	    tmp3 = tmp1 * tmp2
	    tmp4 = 0.7071067811865476
	    tmp5 = tmp1 * tmp4
	    tmp6 = libdevice.erf(tmp5)
	    tmp7 = 1.0
	    tmp8 = tmp6 + tmp7
	    tmp9 = tmp3 * tmp8
	    tmp10 = tl.broadcast_to(tmp9, [R0_BLOCK])
	    tmp12 = tl.broadcast_to(tmp10, [R0_BLOCK])
	    tmp14 = triton_helpers.promote_to_tensor(tl.sum(tmp12, 0))
	    tmp15 = tl.full([1], 1024, tl.int32)
	    tmp16 = tmp15.to(tl.float32)
	    tmp17 = (tmp14 / tmp16)
	    tmp18 = tmp10 - tmp17
	    tmp19 = tmp18 * tmp18
	    tmp20 = tl.broadcast_to(tmp19, [R0_BLOCK])
	    tmp22 = triton_helpers.promote_to_tensor(tl.sum(tmp20, 0))
	    tmp23 = tmp9 - tmp17
	    tmp24 = 1024.0
	    tmp25 = (tmp22 / tmp24)
	    tmp26 = 1e-05
	    tmp27 = tmp25 + tmp26
	    tmp28 = libdevice.rsqrt(tmp27)
	    tmp29 = tmp23 * tmp28
	    tmp31 = tmp30.to(tl.float32)
	    tmp32 = tmp29 * tmp31
	    tmp34 = tmp33.to(tl.float32)
	    tmp35 = tmp32 + tmp34
	    tmp36 = tmp35.to(tl.float32)
	    tl.store(in_out_ptr0 + (r0_1 + 1024*x0), tmp36, None)
	''', device_str='cuda')
	
	
	# kernel path: /tmp/torchinductor_cache/au/caue5kfnaqefl7zlwh5ro3lh64raqnztcacwv7es3k55dzeyjtqa.py
	# Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	# Source node to ATen node mapping:
	#   all_gather_into_tensor_default => all_gather_into_tensor
	#   h2_1 => relu
	# Graph fragment:
	#   %mm_1 : Tensor "f16[1024, 1024][1024, 1]cuda:1" = PlaceHolder[target=mm_1]
	#   %relu : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%mm_1,), kwargs = {})
	#   %all_gather_into_tensor : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%relu, 2, 0), kwargs = {})
	#   return %buf10
	triton_poi_fused_all_gather_into_tensor_relu_1 = async_compile.triton('triton_poi_fused_all_gather_into_tensor_relu_1', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.pointwise(
	    size_hints={'x': 1048576}, 
	    filename=__file__,
	    triton_meta={'signature': {'in_out_ptr0': '*fp16', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_all_gather_into_tensor_relu_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 6291456}},
	    min_elem_per_thread=0
	)
	@triton.jit
	def triton_poi_fused_all_gather_into_tensor_relu_1(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
	    xnumel = 1048576
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = xoffset + tl.arange(0, XBLOCK)[:]
	    xmask = tl.full([XBLOCK], True, tl.int1)
	    x0 = xindex
	    tmp0 = tl.load(in_out_ptr0 + (x0), None).to(tl.float32)
	    tmp1 = tl.full([1], 0, tl.int32)
	    tmp2 = triton_helpers.maximum(tmp1, tmp0)
	    tl.store(in_out_ptr0 + (x0), tmp2, None)
	''', device_str='cuda')
	
	
	# kernel path: /tmp/torchinductor_cache/wv/cwv6cxclgtrt3hams2kloxex2znci73vsksvlyvcuj7liuhc6676.py
	# Topologically Sorted Source Nodes: [g, rs_expanded, out], Original ATen: [aten.mul, aten.repeat, aten.add]
	# Source node to ATen node mapping:
	#   g => mul_5
	#   out => add_3
	#   rs_expanded => repeat
	# Graph fragment:
	#   %buf14 : Tensor  = PlaceHolder[target=buf14]
	#   %buf16 : Tensor  = PlaceHolder[target=buf16]
	#   %mul_5 : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%wait_tensor_1, 0.7071067811865476), kwargs = {})
	#   %repeat : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.repeat.default](args = (%wait_tensor_2, [2, 1]), kwargs = {})
	#   %add_3 : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_5, %repeat), kwargs = {})
	#   return %add_3
	triton_poi_fused_add_mul_repeat_2 = async_compile.triton('triton_poi_fused_add_mul_repeat_2', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.pointwise(
	    size_hints={'x': 2097152}, 
	    filename=__file__,
	    triton_meta={'signature': {'in_ptr0': '*fp16', 'in_ptr1': '*fp16', 'out_ptr0': '*fp16', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_mul_repeat_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 8388608}},
	    min_elem_per_thread=0
	)
	@triton.jit
	def triton_poi_fused_add_mul_repeat_2(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
	    xnumel = 2097152
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = xoffset + tl.arange(0, XBLOCK)[:]
	    xmask = tl.full([XBLOCK], True, tl.int1)
	    x2 = xindex
	    x0 = (xindex % 1024)
	    x1 = xindex // 1024
	    tmp0 = tl.load(in_ptr0 + (x2), None).to(tl.float32)
	    tmp3 = tl.load(in_ptr1 + (x0 + 1024*((x1 % 1024))), None).to(tl.float32)
	    tmp1 = 0.7071067811865476
	    tmp2 = tmp0 * tmp1
	    tmp4 = tmp2 + tmp3
	    tl.store(out_ptr0 + (x2), tmp4, None)
	''', device_str='cuda')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg2_1, (1024, ), (1, ))
	    assert_size_stride(arg3_1, (1024, ), (1, ))
	    assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg5_1, (2048, 1024), (1024, 1))
	    with torch.cuda._DeviceGuard(1):
	        torch.cuda.set_device(1)
	        buf0 = empty_strided_cuda((1024, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [h], Original ATen: [aten.mm]
	        extern_kernels.mm(arg1_1, reinterpret_tensor(arg0_1, (1024, 1024), (1, 1024), 0), out=buf0)
	        del arg0_1
	        del arg1_1
	        buf4 = buf0; del buf0  # reuse
	        # Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	        stream1 = get_raw_stream(1)
	        triton_per_fused_all_reduce_gelu_native_layer_norm_0.run(buf4, arg2_1, arg3_1, 1024, 1024, stream=stream1)
	        del arg2_1
	        del arg3_1
	        # Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	        torch.ops._c10d_functional.all_reduce_.default(buf4, 'sum', '0')
	        # Topologically Sorted Source Nodes: [h_3], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf4)
	        buf9 = empty_strided_cuda((1024, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [h2], Original ATen: [aten.mm]
	        extern_kernels.mm(buf4, reinterpret_tensor(arg4_1, (1024, 1024), (1, 1024), 0), out=buf9)
	        del arg4_1
	        buf10 = buf9; del buf9  # reuse
	        # Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	        stream1 = get_raw_stream(1)
	        triton_poi_fused_all_gather_into_tensor_relu_1.run(buf10, 1048576, stream=stream1)
	        # Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	        buf11 = torch.ops._c10d_functional.all_gather_into_tensor.default(buf10, 2, '0')
	        assert_size_stride(buf11, (2048, 1024), (1024, 1), 'torch.ops._c10d_functional.all_gather_into_tensor.default')
	        assert_alignment(buf11, 16, 'torch.ops._c10d_functional.all_gather_into_tensor.default')
	        del buf4
	        # Topologically Sorted Source Nodes: [reduce_scatter_tensor_default], Original ATen: [_c10d_functional.reduce_scatter_tensor]
	        buf12 = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0')
	        assert_size_stride(buf12, (1024, 1024), (1024, 1), 'torch.ops._c10d_functional.reduce_scatter_tensor.default')
	        assert_alignment(buf12, 16, 'torch.ops._c10d_functional.reduce_scatter_tensor.default')
	        # Topologically Sorted Source Nodes: [gathered], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf11)
	        del buf10
	        # Topologically Sorted Source Nodes: [rs], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf12)
	        del arg5_1
	        buf17 = empty_strided_cuda((2048, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [g, rs_expanded, out], Original ATen: [aten.mul, aten.repeat, aten.add]
	        stream1 = get_raw_stream(1)
	        triton_poi_fused_add_mul_repeat_2.run(buf11, buf12, buf17, 2097152, stream=stream1)
	        del buf11
	        del buf12
	    return (buf17, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg1_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg2_1 = rand_strided((1024, ), (1, ), device='cuda:1', dtype=torch.float16)
	    arg3_1 = rand_strided((1024, ), (1, ), device='cuda:1', dtype=torch.float16)
	    arg4_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg5_1 = rand_strided((2048, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0804 12:34:16.799000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "80236dd3153279aef925f754b0c47b70"}
	{
	"name": "PyCodeCache.load_by_key_path",
	"ts": 1754336056799696.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.802000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "12ad482937cfff8aece2cbc039844561"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336056802091.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.001000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "4d64653ef1d8d8c32ab4de360b189449"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057001688.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.002000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "80f978ac4c35bb3c9cb156c4c9c7212b"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057002558.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.003000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "3c142d9837ec0dfbc99fecfab8653418"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057003600.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.004000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5777ab745f33880ba17d9f6a14a0f70c"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057004106.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.277000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "4e663a4bec69ea28d39d17c2f748072b"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057277526.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.278000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "4f1a3e38895dbbdf80c453694838a888"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057278400.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.279000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "df182e15284e055cf323e429492b08af"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057279661.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.280000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "894894af91c31053d3d1aa05047df5ad"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057280180.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.520000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5cf06f1b29da2c07e13fdebaaaee8d77"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057520536.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.521000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "7ed1e0e9f925f1a7c72242bb070be0f4"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057521421.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.522000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "e02e32b9c735425ff82cb524f6118aa4"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057522678.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.523000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "94801603d69e385f61d2cdf0a7f3542f"}
	{
	"name": "async_compile.wait",
	"ts": 1754336057523139.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.523000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "9ad23fc92a8e4f2a15ffaedb2bf2a062"}
	{
	"name": "async_compile.wait",
	"ts": 1754336057523699.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.524000 1142858 torch/_inductor/async_compile.py:116] {"artifact": {"name": "triton_kernel_info", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "911ae427d653658a7be1def130de511a"}
	{"triton_per_fused_all_reduce_gelu_native_layer_norm_0": {"autotune_cache_state": "only 1 config", "only_config": [["XBLOCK", 1], ["num_warps", 8], ["num_stages", 1]], "compile_time_us": 200965}, "triton_poi_fused_add_mul_repeat_2": {"autotune_cache_state": "miss", "num_configs": 2, "compile_time_us": 241968}, "triton_poi_fused_all_gather_into_tensor_relu_1": {"autotune_cache_state": "miss", "num_configs": 2, "compile_time_us": 275030}}
V0804 12:34:17.524000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "bee9239babd4825a4636a5bbc00edc0a"}
	{
	"name": "PyCodeCache.load_by_key_path",
	"ts": 1754336057524497.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.526000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5d61db82333d22acbcf73f9db933c20c"}
	{
	"name": "code_gen",
	"ts": 1754336057526188.5,
	"args": {
	"fn_name": "GraphLowering.compile_to_module",
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.528000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "c96d85c4e6d3a3185d3045f553d66b16"}
	{
	"name": "GraphLowering.compile_to_fn",
	"ts": 1754336057528082.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.528000 1142858 torch/_inductor/debug.py:700] {"artifact": {"name": "inductor_collective_schedule", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "e255b7f099207a3c7478df9c470be5fb"}
	[
	"torch.ops._c10d_functional.all_reduce_.default",
	"torch.ops._c10d_functional.wait_tensor.default",
	"torch.ops._c10d_functional.all_gather_into_tensor.default",
	"torch.ops._c10d_functional.reduce_scatter_tensor.default",
	"torch.ops._c10d_functional.wait_tensor.default",
	"torch.ops._c10d_functional.wait_tensor.default"
	]
V0804 12:34:17.536000 1142858 torch/_inductor/debug.py:734] {"artifact": {"name": "inductor_runtime_and_tensor_meta", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "5bdf44b46ade21759085f713237b436d"}
	{
	"ops": [
	{
	"name": "extern_kernels.mm",
	"type": "compute",
	"estimated_runtime_ns": 7918718.150774888,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "op1_op2_op4",
	"type": "compute",
	"estimated_runtime_ns": 2494.708994708994,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.all_reduce_.default",
	"type": "collective",
	"estimated_runtime_ns": 34581.10319270239,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "extern_kernels.mm",
	"type": "compute",
	"estimated_runtime_ns": 7918718.150774888,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "op8",
	"type": "compute",
	"estimated_runtime_ns": 2492.275132275132,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.all_gather_into_tensor.default",
	"type": "collective",
	"estimated_runtime_ns": 21085.55159635119,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.reduce_scatter_tensor.default",
	"type": "collective",
	"estimated_runtime_ns": 33891.10319270239,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "op13",
	"type": "compute",
	"estimated_runtime_ns": 6230.68783068783,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	}
	]
	}
V0804 12:34:17.537000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "ca8ccf8344ba48c785e79204ca585441"}
	{
	"name": "TritonBundler.collect",
	"ts": 1754336057536993.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.538000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "ef094d43c568c6c3ba97e4ecc345ebd5"}
	{
	"name": "TritonBundler.collect",
	"ts": 1754336057538643.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.542000 1142858 torch/_dynamo/utils.py:1970] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "15cbcc011ff940cc5afe9aba4d908989"}
	{
	"name": "fx_graph_cache_miss",
	"ts": 1754336056508661.2,
	"args": {
	"cache_status_detailed": "full_miss",
	"key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia",
	"components": [
	"[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1",
	"[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_event_time": 1754336056519882928,
	"cache_state": "miss",
	"triton_bundler_meta": "TritonBundlerMetadata(cached_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2', 'triton_poi_fused_add_mul_repeat_2'], statically_launched_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2'])",
	"time_taken_ns": 1028276620,
	"compile_id": "0/1"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0804 12:34:17.543000 1142858 torch/_inductor/compile_fx.py:1046] {"artifact": {"name": "fx_graph_cache_miss", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "e6fdbc08f0c63f46936e51c6e9971b97"}
	{"cache_status_detailed": "full_miss", "key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia", "components": ["[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ", "[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1", "[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)", "[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>", "[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}", "[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}", "[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False", "[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10", "[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True", "[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']", "[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None", "[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op", "[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait", "[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"], "cache_event_time": 1754336056519882928, "cache_state": "miss", "triton_bundler_meta": "TritonBundlerMetadata(cached_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2', 'triton_poi_fused_add_mul_repeat_2'], statically_launched_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2'])", "time_taken_ns": 1028276620, "compile_id": "0/1"}
V0804 12:34:17.544000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "14540daa5eed5d60e04d8d90d1acad9b"}
	{
	"name": "fx_codegen_and_compile",
	"ts": 1754336057544033.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.545000 1142858 torch/_inductor/compile_fx.py:1063] {"artifact": {"name": "inductor_provenance_tracking_node_mappings", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "76d2422b3e3af0e2c6da07ed7be908de"}
	{"preToPost": {"h": ["permute", "mm"], "h_1": ["convert_element_type_2", "mul", "mul_1", "erf", "add", "mul_2"], "h_2": ["mul_2", "var_mean", "getitem", "getitem_1", "sub", "add_1", "rsqrt", "mul_3", "mul_4", "add_2", "convert_element_type_5"], "all_reduce_default": ["all_reduce"], "h_3": ["wait_tensor"], "h2": ["permute_1", "mm_1"], "h2_1": ["relu"], "all_gather_into_tensor_default": ["all_gather_into_tensor"], "reduce_scatter_tensor_default": ["reduce_scatter_tensor"], "gathered": ["wait_tensor_1"], "g": ["mul_5"], "rs": ["wait_tensor_2"], "rs_expanded": ["repeat"], "out": ["add_3"]}, "postToPre": {"permute": ["h"], "mm": ["h"], "convert_element_type_2": ["h_1"], "mul": ["h_1"], "mul_1": ["h_1"], "erf": ["h_1"], "add": ["h_1"], "mul_2": ["h_1", "h_2"], "var_mean": ["h_2"], "getitem": ["h_2"], "getitem_1": ["h_2"], "sub": ["h_2"], "add_1": ["h_2"], "rsqrt": ["h_2"], "mul_3": ["h_2"], "mul_4": ["h_2"], "add_2": ["h_2"], "convert_element_type_5": ["h_2"], "all_reduce": ["all_reduce_default"], "wait_tensor": ["h_3"], "permute_1": ["h2"], "mm_1": ["h2"], "relu": ["h2_1"], "all_gather_into_tensor": ["all_gather_into_tensor_default"], "reduce_scatter_tensor": ["reduce_scatter_tensor_default"], "wait_tensor_1": ["gathered"], "mul_5": ["g"], "wait_tensor_2": ["rs"], "repeat": ["rs_expanded"], "add_3": ["out"]}, "cppCodeToPost": {"triton_per_fused_all_reduce_gelu_native_layer_norm_0": ["var_mean", "mul_2", "mul", "convert_element_type_2", "add", "erf", "mul_1", "all_reduce", "convert_element_type_5", "add_2", "mul_4", "mul_3", "sub", "rsqrt", "add_1"], "triton_poi_fused_all_gather_into_tensor_relu_1": ["all_gather_into_tensor", "relu"], "triton_poi_fused_add_mul_repeat_2": ["add_3", "mul_5", "repeat"], "extern_kernels.mm": ["mm", "mm_1"]}, "postToCppCode": {"var_mean": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "convert_element_type_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "erf": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_1": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "all_reduce": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "convert_element_type_5": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_4": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_3": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "sub": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "rsqrt": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add_1": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "all_gather_into_tensor": ["triton_poi_fused_all_gather_into_tensor_relu_1"], "relu": ["triton_poi_fused_all_gather_into_tensor_relu_1"], "add_3": ["triton_poi_fused_add_mul_repeat_2"], "mul_5": ["triton_poi_fused_add_mul_repeat_2"], "repeat": ["triton_poi_fused_add_mul_repeat_2"], "mm": ["extern_kernels.mm"], "mm_1": ["extern_kernels.mm"]}}
V0804 12:34:17.546000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "aa82c2077ddbafd7cce2517078b3da43"}
	{
	"name": "inductor_compile",
	"ts": 1754336057545927.5,
	"args": {
	"fn_name": "compile_fx_inner",
	"compile_id": "0/1",
	"is_backward": false,
	"cache_state": "miss",
	"cache_event_time": 1754336056508661133,
	"key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia",
	"components": [
	"[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1",
	"[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_bypass_reason": null,
	"remote_cache_enabled": false,
	"local_cache_enabled": true
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.547000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "575fb830502bd4aef41be843d415bd81"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1754336057547051.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.551000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "c93ee0f5660e1303f99b3bb6658dba22"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1754336057551887.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.553000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "29b59e021e5c79f63433f5cc4dd58004"}
	{
	"name": "backend_compile",
	"ts": 1754336057552910.0,
	"args": {
	"fn_name": "OutputGraph.call_user_compiler",
	"compile_id": "0/1",
	"cache_state": "miss",
	"cache_event_time": 1754336056406148383,
	"key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp",
	"components": [
	"[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False",
	"[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>",
	"[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])",
	"[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_bypass_reason": null,
	"remote_cache_enabled": false,
	"local_cache_enabled": true,
	"requires_subclass_dispatch": false,
	"dispatch_mode": "inference"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "993d974dfe8f1e85e9bfd2447147f6a8"}
	{
	"name": "compile_attempt_0",
	"ts": 1754336057556288.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "ed08aa4ec91b74e6dbd4428600f8b8fb"}
	{
	"name": "build_guards",
	"ts": 1754336057556752.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.604000 1142858 torch/_dynamo/guards.py:3264] {"dynamo_cpp_guards_str": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "e43f79e90e076e25c23fe0530956739a"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo/output_graph.py:643 in init_ambient_guards
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:631 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['fn'], accessed_by=FrameLocalsGuardAccessor(key='fn', framelocals_idx=2), type=<class 'method'>, tag_safe=(False, False)
	| | +- ID_MATCH: ___check_obj_id(L['fn'], 139646516664256)                   
	| | +- GuardManager: source=L['fn'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__), type=<class 'tuple'>, tag_safe=(False, False)
	| | | +- GuardManager: source=L['fn'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0), type=<class 'cell'>, tag_safe=(False, False)
	| | | | +- GuardManager: source=L['fn'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents), type=<class 'method'>, tag_safe=(False, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__closure__[0].cell_contents, 9738560)  # with ctx_factory():  # utils/_contextlib.py:119 in decorate_context
	| | | +- GuardManager: source=L['fn'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1), type=<class 'cell'>, tag_safe=(False, False)
	| | | | +- GuardManager: source=L['fn'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- GuardManager: source=L['fn'].__closure__[1].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__), type=<class 'code'>, tag_safe=(True, False)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['fn'].__closure__[1].cell_contents.__code__, 11214464)  # return func(*args, **kwargs)  # utils/_contextlib.py:120 in decorate_context
	| | +- GuardManager: source=L['fn'].__self__, accessed_by=GetAttrGuardAccessor(__self__), type=<class '__main__.MultiGraphRepro'>, tag_safe=(True, True)
	| | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__, 86065824)                
	| | | +- GuardManager: source=L['fn'].__self__.__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | +- GuardManager: source=L['fn'].__self__._modules, accessed_by=DictGetItemGuardAccessor('_modules'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules, 9676128)          # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1'], accessed_by=DictGetItemGuardAccessor('lin1'), type=<class 'torch.nn.modules.linear.Linear'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin1'], 87594704)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['lin1'].__dict__)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin1']._parameters, 9676128)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'NoneType'>, tag_safe=(True, False)
	| | | | | | | | | +- NONE_MATCH: L['fn'].__self__._modules['lin1']._parameters['bias'] is None  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['lin1']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2'], accessed_by=DictGetItemGuardAccessor('lin2'), type=<class 'torch.nn.modules.linear.Linear'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin2'], 87594704)  # h2 = self.lin2(h)  # test2.py:70 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['lin2'].__dict__)  # h2 = self.lin2(h)  # test2.py:70 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin2']._parameters, 9676128)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'NoneType'>, tag_safe=(True, False)
	| | | | | | | | | +- NONE_MATCH: L['fn'].__self__._modules['lin2']._parameters['bias'] is None  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['lin2']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'], accessed_by=DictGetItemGuardAccessor('norm'), type=<class 'torch.nn.modules.normalization.LayerNorm'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm'], 88494992)  # h = self.norm(h)  # test2.py:61 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['norm'].__dict__)  # h = self.norm(h)  # test2.py:61 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].eps, accessed_by=DictGetItemGuardAccessor('eps'), type=<class 'float'>, tag_safe=(True, False)
	| | | | | | | | +- EQUALS_MATCH: L['fn'].__self__._modules['norm'].eps == 1e-05                # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm']._parameters, 9676128)  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['norm']._parameters['bias'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024], stride=[1])  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['norm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024], stride=[1])  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].normalized_shape, accessed_by=DictGetItemGuardAccessor('normalized_shape'), type=<class 'tuple'>, tag_safe=(True, False)
	| | | | | | | | +- EQUALS_MATCH: L['fn'].__self__._modules['norm'].normalized_shape == (1024,)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm'].normalized_shape, 9650464)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | | +- LENGTH_CHECK: len(L['fn'].__self__._modules['norm'].normalized_shape) == 1  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | +- GuardManager: source=L['fn'].__self__._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._parameters, 9676128)       # h = self.lin1(x)  # test2.py:59 in graph_one
	| +- GuardManager: source=L['args'], accessed_by=FrameLocalsGuardAccessor(key='args', framelocals_idx=0), type=<class 'tuple'>, tag_safe=(True, False)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 9650464)                        
	| | +- LENGTH_CHECK: len(L['args']) == 3                                         
	| | +- GuardManager: source=L['args'][0], accessed_by=TupleGetItemGuardAccessor(0), type=<class 'torch.Tensor'>, tag_safe=(True, False)
	| | | +- TENSOR_MATCH: check_tensor(L['args'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=False, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- NO_HASATTR: hasattr(L['args'][0], '_dynamo_dynamic_indices') == False     # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['args'][0], L['args'][1])
	| | +- GuardManager: source=L['args'][1], accessed_by=TupleGetItemGuardAccessor(1), type=<class 'torch.Tensor'>, tag_safe=(True, False)
	| | | +- TENSOR_MATCH: check_tensor(L['args'][1], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=False, size=[2048, 1024], stride=[1024, 1])  # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | +- NO_HASATTR: hasattr(L['args'][1], '_dynamo_dynamic_indices') == False     # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | +- NO_TENSOR_ALIASING
	| | +- GuardManager: source=L['args'][2], accessed_by=TupleGetItemGuardAccessor(2), type=<class 'int'>, tag_safe=(True, False)
	| | | +- EQUALS_MATCH: L['args'][2] == 2                                             # torch.ops._c10d_functional.all_gather_into_tensor.default(  # test2.py:75 in graph_one
	| +- GuardManager: source=L['kwargs'], accessed_by=FrameLocalsGuardAccessor(key='kwargs', framelocals_idx=1), type=<class 'dict'>, tag_safe=(True, False)
	| | +- TYPE_MATCH: ___check_type_id(L['kwargs'], 9676128)                      
	| | +- DICT_LENGTH: not L['kwargs']                                             
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)
	| | +- GuardManager: source=G['__import___main__'], accessed_by=DictGetItemGuardAccessor('__import___main__'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import___main__'], 139648550378592)      # h = F.gelu(h)  # test2.py:60 in graph_one
	| | | +- GuardManager: source=G['__import___main__'].math, accessed_by=GetAttrGuardAccessor(math), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].math, 139648548565248)  # g = gathered * math.sqrt(0.5)  # test2.py:82 in graph_one
	| | | | +- GuardManager: source=G['__import___main__'].math.sqrt, accessed_by=GetAttrGuardAccessor(sqrt), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].math.sqrt, 139648548568848)  # g = gathered * math.sqrt(0.5)  # test2.py:82 in graph_one
	| | | +- GuardManager: source=G['__import___main__'].torch, accessed_by=GetAttrGuardAccessor(torch), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch, 139648548799248)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | +- GuardManager: source=G['__import___main__'].torch.ops, accessed_by=GetAttrGuardAccessor(ops), type=<class 'torch._ops._Ops'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops, 139646535729696)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional, accessed_by=GetAttrGuardAccessor(_c10d_functional), type=<class 'torch._ops._OpNamespace'>, tag_safe=(False, False)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional, 139645390308672)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.all_reduce, accessed_by=GetAttrGuardAccessor(all_reduce), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.all_reduce, 139645365491216)  # torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")  # test2.py:65 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.wait_tensor, accessed_by=GetAttrGuardAccessor(wait_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.wait_tensor, 139645391765136)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.reduce_scatter_tensor, accessed_by=GetAttrGuardAccessor(reduce_scatter_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.reduce_scatter_tensor, 139645365494432)  # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.all_gather_into_tensor, accessed_by=GetAttrGuardAccessor(all_gather_into_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.all_gather_into_tensor, 139645365493040)  # torch.ops._c10d_functional.all_gather_into_tensor.default(  # test2.py:75 in graph_one
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_linear'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 139646537542256)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F, 139646537542176)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.gelu, accessed_by=GetAttrGuardAccessor(gelu), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.gelu, 139647331694640)  # h = F.gelu(h)  # test2.py:60 in graph_one
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.relu, accessed_by=GetAttrGuardAccessor(relu), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.relu, 139646534605440)  # h2 = F.relu(h2)  # test2.py:71 in graph_one
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.linear, accessed_by=GetAttrGuardAccessor(linear), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.linear, 139647331695760)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.layer_norm, accessed_by=GetAttrGuardAccessor(layer_norm), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.layer_norm, 139646534610080)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_module'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 139646542524272)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_normalization'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_normalization'], 139646533665952)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	+- LAMBDA_GUARD: G['__import_torch_dot_nn_dot_modules_dot_linear'].F is G['__import___main__'].F  # h = F.gelu(h)  # test2.py:60 in graph_one
	+- LAMBDA_GUARD: G['__import_torch_dot_nn_dot_modules_dot_linear'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	
	Guard latency = 76.59 us
V0804 12:34:17.605000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "34c095b8287af9a8e0795bf443735bd9"}
	{
	"name": "build_guards",
	"ts": 1754336057604943.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.605000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "287c902d8f119efce4659e7156d907f4"}
	{
	"name": "gc",
	"ts": 1754336057605596.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.612000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "62e1991310911d573d0cd0d87742e3a8"}
	{
	"name": "gc",
	"ts": 1754336057612475.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.613000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "c9baed5bb949943a63c9444699a3230f"}
	{
	"name": "entire_frame_compile",
	"ts": 1754336057613317.0,
	"args": {
	"fn_name": "_compile.compile_inner",
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.616000 1142858 torch/_dynamo/utils.py:1626] {"compilation_metrics": {"compile_id": "0/1", "frame_key": "2", "co_name": "inner", "co_filename": "/home/skarjala/pytorch/torch/_dynamo/external_utils.py", "co_firstlineno": 66, "cache_size": 1, "accumulated_cache_size": 1, "guard_count": 74, "shape_env_guard_count": 0, "graph_op_count": 16, "graph_node_count": 23, "graph_input_count": 6, "start_time": 1754336056.314324, "entire_frame_compile_time_s": 1.298985, "backend_compile_time_s": 1.166478, "inductor_compile_time_s": 1.03941, "code_gen_time_s": 0.915887, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": ["_c10d_functional::all_gather_into_tensor", "_c10d_functional::reduce_scatter_tensor", "_c10d_functional::all_reduce", "_c10d_functional::wait_tensor"], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "remote_cache_time_saved_s": null, "structured_logging_overhead_s": 0.055596, "config_suppress_errors": false, "config_inline_inbuilt_nn_modules": true, "specialize_float": false, "dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}", "is_forward": true, "num_triton_bundles": null, "remote_fx_graph_cache_get_time_ms": null, "remote_fx_graph_cache_put_time_ms": null, "start_time_us": 1754336056314324, "duration_us": 1298985, "dynamo_cumulative_compile_time_us": 1298985, "aot_autograd_cumulative_compile_time_us": 1166478, "inductor_cumulative_compile_time_us": 1039410, "inductor_code_gen_cumulative_compile_time_us": 915887, "triton_compile_time_us": 720120, "runtime_cudagraphify_time_us": null, "runtime_triton_autotune_time_us": null, "dynamo_compile_time_before_restart_us": 0, "distributed_ephemeral_timeout_us": null, "structured_logging_overhead_us": 55596, "remote_fx_graph_cache_get_time_us": null, "remote_fx_graph_cache_put_time_us": null, "backward_cumulative_compile_time_us": null, "end_time_us": 1754336057613729, "pre_grad_pass_time_us": 1199, "post_grad_pass_time_us": 6732, "joint_graph_pass_time_us": 10172, "log_format_version": 3, "inductor_config": "{\"TYPE_CHECKING\": false, \"_cache_config_ignore_prefix\": [\"trace\", \"cuda.cutlass_dir\", \"worker_start_method\", \"compile_threads\", \"post_grad_custom_post_pass\", \"post_grad_custom_pre_pass\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\", \"always_complex_memory_overlap_TESTING_ONLY\", \"fx_graph_cache\", \"fx_graph_remote_cache\", \"autotune_local_cache\", \"autotune_remote_cache\"], \"_collective.auto_select\": false, \"_collective.one_shot_all_reduce_threshold_bytes\": 131072, \"_fuse_ddp_bucket_size\": 25, \"_fuse_ddp_communication\": false, \"_fuse_ddp_communication_passes\": [\"fuse_ddp_with_concat_op\", \"schedule_comm_wait\"], \"_micro_pipeline_tp\": false, \"_post_fusion_custom_pass\": null, \"_pre_fusion_custom_pass\": null, \"_profile_var\": \"\", \"_raise_error_for_testing\": false, \"_save_config_ignore\": [\"trace.upload_tar\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"pre_grad_custom_pass\", \"aot_inductor.repro_level\", \"aot_inductor.dump_aoti_minifier\", \"post_grad_custom_pre_pass\", \"post_grad_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\"], \"add_pre_grad_passes\": null, \"aggressive_fusion\": false, \"alignment_asserts\": true, \"allow_buffer_reuse\": true, \"always_complex_memory_overlap_TESTING_ONLY\": false, \"always_keep_tensor_constants\": false, \"annotate_training\": false, \"aot_inductor.allow_stack_allocation\": false, \"aot_inductor.compile_standalone\": false, \"aot_inductor.compile_wrapper_opt_level\": \"O1\", \"aot_inductor.custom_op_libs\": null, \"aot_inductor.custom_ops_to_c_shims\": {}, \"aot_inductor.debug_compile\": false, \"aot_inductor.debug_intermediate_value_printer\": \"0\", \"aot_inductor.dump_aoti_minifier\": false, \"aot_inductor.embed_kernel_binary\": false, \"aot_inductor.emit_multi_arch_kernel\": false, \"aot_inductor.enable_lto\": false, \"aot_inductor.filtered_kernel_names\": null, \"aot_inductor.force_mmap_weights\": false, \"aot_inductor.metadata\": {}, \"aot_inductor.model_name_for_generated_files\": null, \"aot_inductor.output_path\": \"\", \"aot_inductor.package\": false, \"aot_inductor.package_constants_in_so\": true, \"aot_inductor.package_constants_on_disk\": false, \"aot_inductor.package_cpp_only\": null, \"aot_inductor.precompile_headers\": true, \"aot_inductor.presets\": {}, \"aot_inductor.raise_error_on_ignored_optimization\": true, \"aot_inductor.repro_level\": 2, \"aot_inductor.serialized_in_spec\": \"\", \"aot_inductor.serialized_out_spec\": \"\", \"aot_inductor.use_consts_asm_build\": true, \"aot_inductor.use_minimal_arrayref_interface\": false, \"aot_inductor.use_runtime_constant_folding\": false, \"aot_inductor.weight_use_caching_allocator\": false, \"assert_indirect_indexing\": true, \"assume_aligned_inputs\": false, \"assume_unaligned_fallback_output\": false, \"autoheuristic_collect\": \"\", \"autoheuristic_log_path\": \"DEFAULT\", \"autoheuristic_use\": \"mixed_mm\", \"autotune_fallback_to_aten\": false, \"autotune_in_subproc\": false, \"autotune_local_cache\": true, \"autotune_lookup_table\": {}, \"autotune_multi_device\": false, \"autotune_num_choices_displayed\": 10, \"autotune_remote_cache\": null, \"b2b_gemm_pass\": false, \"batch_fusion\": true, \"benchmark_combo_kernel\": false, \"benchmark_epilogue_fusion\": true, \"benchmark_fusion\": false, \"benchmark_harness\": true, \"benchmark_kernel\": false, \"bfloat16_atomic_adds_enabled\": true, \"bucket_all_gathers_fx\": \"none\", \"bucket_all_gathers_fx_bucket_size_determinator\": null, \"bucket_reduce_scatters_fx\": \"none\", \"bucket_reduce_scatters_fx_bucket_size_determinator\": null, \"bundle_triton_into_fx_graph_cache\": true, \"bundled_autotune_remote_cache\": null, \"bw_outputs_user_visible\": true, \"can_inplace_pad_graph_input\": false, \"check_stack_no_cycles_TESTING_ONLY\": false, \"combo_kernel_allow_mixed_sizes\": 1, \"combo_kernel_foreach_dynamic_shapes\": true, \"combo_kernels\": false, \"combo_kernels_autotune\": 1, \"comment_origin\": false, \"compile_threads\": 32, \"comprehensive_padding\": true, \"compute_all_bounds\": false, \"constant_and_index_propagation\": true, \"conv_1x1_as_mm\": false, \"coordinate_descent_check_all_directions\": false, \"coordinate_descent_search_radius\": 1, \"coordinate_descent_tuning\": false, \"cpp.cxx\": [null, \"g++\"], \"cpp.descriptive_names\": \"original_aten\", \"cpp.dynamic_threads\": false, \"cpp.enable_concat_linear\": false, \"cpp.enable_floating_point_contract_flag\": \"off\", \"cpp.enable_grouped_gemm_template\": false, \"cpp.enable_kernel_profile\": false, \"cpp.enable_loop_tail_vec\": true, \"cpp.enable_tiling_heuristics\": true, \"cpp.enable_unsafe_math_opt_flag\": false, \"cpp.fallback_scatter_reduce_sum\": true, \"cpp.force_inline_kernel\": false, \"cpp.gemm_cache_blocking\": null, \"cpp.gemm_max_k_slices\": 1, \"cpp.gemm_thread_factors\": null, \"cpp.inject_log1p_bug_TESTING_ONLY\": null, \"cpp.inject_relu_bug_TESTING_ONLY\": null, \"cpp.max_horizontal_fusion_size\": 16, \"cpp.min_chunk_size\": 512, \"cpp.no_redundant_loops\": true, \"cpp.simdlen\": null, \"cpp.threads\": -1, \"cpp.use_decompose_tanh\": false, \"cpp.use_small_dequant_buffer\": false, \"cpp.vec_isa_ok\": null, \"cpp.weight_prepack\": true, \"cpp_cache_precompile_headers\": true, \"cpp_wrapper\": false, \"cpp_wrapper_build_separate\": false, \"cpu_backend\": \"cpp\", \"cuda.arch\": null, \"cuda.binary_remote_cache_force_write\": false, \"cuda.compile_opt_level\": \"-O1\", \"cuda.cuda_cxx\": null, \"cuda.cutlass_backend_min_gemm_size\": 1, \"cuda.cutlass_dir\": \"/home/skarjala/pytorch/third_party/cutlass\", \"cuda.cutlass_enabled_ops\": \"all\", \"cuda.cutlass_epilogue_fusion_enabled\": false, \"cuda.cutlass_hash_with_compile_cmd\": false, \"cuda.cutlass_instantiation_level\": \"0\", \"cuda.cutlass_max_profiling_configs\": null, \"cuda.cutlass_max_profiling_swizzle_options\": [1, 2, 4, 8], \"cuda.cutlass_op_allowlist_regex\": null, \"cuda.cutlass_op_denylist_regex\": null, \"cuda.cutlass_prescreening\": true, \"cuda.cutlass_presets\": null, \"cuda.cutlass_tma_only\": false, \"cuda.enable_caching_codegen\": true, \"cuda.enable_cuda_lto\": false, \"cuda.enable_debug_info\": false, \"cuda.enable_ptxas_info\": false, \"cuda.generate_test_runner\": false, \"cuda.upload_to_binary_remote_cache\": false, \"cuda.use_binary_remote_cache\": true, \"cuda.use_fast_math\": false, \"cuda.version\": null, \"cuda_backend\": \"triton\", \"dce\": false, \"debug\": false, \"debug_fusion\": false, \"debug_index_asserts\": false, \"debug_ir_traceback\": false, \"decompose_mem_bound_mm\": false, \"developer_warnings\": true, \"disable_cpp_codegen\": false, \"disable_padding_cpu\": true, \"disable_progress\": true, \"dynamic_scale_rblock\": true, \"efficient_conv_bn_eval_fx_passes\": false, \"emulate_precision_casts\": false, \"enable_auto_functionalized_v2\": true, \"enable_caching_generated_triton_templates\": true, \"enable_linear_binary_folding\": false, \"enabled_metric_tables\": \"\", \"epilogue_fusion\": true, \"epilogue_fusion_first\": false, \"estimate_op_runtime\": \"default\", \"external_matmul\": [], \"fallback_random\": false, \"force_fuse_int_mm_with_mul\": false, \"force_layout_optimization\": false, \"force_pointwise_cat\": false, \"force_same_precision\": false, \"force_shape_pad\": false, \"freezing\": false, \"freezing_discard_parameters\": false, \"fx_graph_cache\": true, \"fx_graph_remote_cache\": null, \"fx_passes_numeric_check\": {\"num_iterations\": 1, \"pre_grad\": false, \"precision\": 0.0001, \"requires_optimizer\": true}, \"generate_intermediate_hooks\": false, \"global_cache_dir\": null, \"graph_partition\": false, \"group_fusion\": false, \"halide.asserts\": false, \"halide.cpu_target\": \"host\", \"halide.debug\": false, \"halide.gpu_target\": \"host-cuda\", \"halide.scan_kernels\": false, \"halide.scheduler_cpu\": \"Adams2019\", \"halide.scheduler_cuda\": \"Anderson2021\", \"implicit_fallbacks\": true, \"inplace_buffers\": true, \"inplace_padding\": true, \"inter_node_bw\": 25, \"intra_node_bw\": 300, \"is_nightly_or_source\": true, \"is_predispatch\": false, \"joint_custom_post_pass\": null, \"joint_custom_pre_pass\": null, \"joint_graph_constant_folding\": true, \"keep_output_stride\": true, \"kernel_name_max_ops\": 10, \"layout_opt_default\": \"1\", \"layout_optimization\": true, \"loop_ordering_after_fusion\": false, \"max_autotune\": false, \"max_autotune_conv_backends\": \"ATEN,TRITON\", \"max_autotune_flex_search_space\": \"DEFAULT\", \"max_autotune_gemm\": false, \"max_autotune_gemm_backends\": \"ATEN,TRITON,CPP\", \"max_autotune_gemm_search_space\": \"DEFAULT\", \"max_autotune_pointwise\": false, \"max_autotune_report_choices_stats\": true, \"max_autotune_subproc_graceful_timeout_seconds\": 0.0, \"max_autotune_subproc_result_timeout_seconds\": 60.0, \"max_autotune_subproc_terminate_timeout_seconds\": 0.0, \"max_epilogue_benchmarked_choices\": 1, \"max_fusion_buffer_group_pairwise_attempts\": 64, \"max_fusion_size\": 64, \"max_pointwise_cat_inputs\": 8, \"memory_planning\": false, \"memory_pool\": \"intermediates\", \"min_num_split\": 0, \"mixed_mm_choice\": \"heuristic\", \"multi_kernel_hints\": [], \"nan_asserts\": false, \"non_blocking_remote_cache_write\": true, \"online_softmax\": true, \"optimize_scatter_upon_const_tensor\": true, \"pad_channels_last\": false, \"pad_outputs\": false, \"padding_alignment_bytes\": 128, \"padding_stride_threshold\": 1024, \"pattern_matcher\": true, \"permute_fusion\": false, \"pick_loop_orders\": true, \"post_grad_custom_post_pass\": null, \"post_grad_custom_pre_pass\": null, \"post_grad_fusion_options\": {}, \"pre_grad_custom_pass\": null, \"pre_grad_fusion_options\": {}, \"precompilation_timeout_seconds\": 3600, \"profile_bandwidth\": false, \"profile_bandwidth_output\": null, \"profile_bandwidth_regex\": \"\", \"profile_bandwidth_with_do_bench_using_profiling\": false, \"profiler_mark_wrapper_call\": false, \"prologue_fusion\": true, \"quiesce_async_compile_pool\": false, \"realize_acc_reads_size_threshold\": null, \"realize_acc_reads_threshold\": 8, \"realize_opcount_threshold\": 30, \"realize_reads_threshold\": 4, \"remove_pre_grad_passes\": null, \"reorder_for_compute_comm_overlap\": false, \"reorder_for_compute_comm_overlap_passes\": [\"reorder_compute_for_overlap\", \"sink_waits\", \"raise_comms\"], \"reorder_for_locality\": true, \"reorder_for_peak_memory\": true, \"reorder_prefetch_limit\": null, \"rocm.arch\": [], \"rocm.ck_dir\": null, \"rocm.ck_max_profiling_configs\": null, \"rocm.ck_supported_arch\": [\"gfx90a\", \"gfx942\", \"gfx950\"], \"rocm.ck_tile_max_profiling_configs\": null, \"rocm.compile_opt_level\": \"-O2\", \"rocm.flush_denormals\": true, \"rocm.generate_test_runner\": false, \"rocm.is_debug\": false, \"rocm.kBatch_sweep\": null, \"rocm.n_max_profiling_configs\": null, \"rocm.print_kernel_resource_usage\": false, \"rocm.rocm_home\": null, \"rocm.save_temps\": false, \"rocm.split_k_threshold\": 16, \"rocm.use_fast_math\": true, \"rocm.use_preselected_instances\": false, \"save_args\": false, \"scalar_asserts\": true, \"score_fusion_memory_threshold\": 10, \"search_autotune_cache\": false, \"shape_padding\": true, \"size_asserts\": true, \"sleep_sec_TESTING_ONLY\": null, \"split_cat_fx_passes\": true, \"split_reductions\": true, \"static_launch_user_defined_triton_kernels\": false, \"static_weight_shapes\": true, \"strict_static_cuda_launcher\": false, \"test_configs.autotune_choice_desc_regex\": null, \"test_configs.autotune_choice_name_regex\": null, \"test_configs.force_extern_kernel_in_multi_template\": false, \"test_configs.graphsafe_rng_func_ignores_fallback_random\": false, \"test_configs.max_mm_configs\": null, \"test_configs.runtime_triton_dtype_assert\": false, \"test_configs.static_cpp_dtype_assert\": false, \"trace.compile_profile\": false, \"trace.debug_dir\": null, \"trace.debug_log\": false, \"trace.dot_graph_shape\": null, \"trace.draw_orig_fx_graph\": false, \"trace.enabled\": true, \"trace.fx_graph\": true, \"trace.fx_graph_transformed\": true, \"trace.graph_diagram\": false, \"trace.info_log\": false, \"trace.ir_post_fusion\": true, \"trace.ir_pre_fusion\": true, \"trace.log_autotuning_results\": false, \"trace.log_url_for_graph_xform\": null, \"trace.output_code\": true, \"trace.provenance_tracking\": true, \"trace.save_real_tensors\": false, \"trace.upload_tar\": null, \"triton.autotune_at_compile_time\": null, \"triton.autotune_cublasLt\": true, \"triton.autotune_pointwise\": true, \"triton.autotune_with_sample_inputs\": false, \"triton.coalesce_tiling_analysis\": true, \"triton.codegen_upcast_to_fp32\": true, \"triton.cooperative_reductions\": false, \"triton.cudagraph_capture_sizes\": null, \"triton.cudagraph_dynamic_shape_warn_limit\": 50, \"triton.cudagraph_skip_dynamic_graphs\": false, \"triton.cudagraph_support_input_mutation\": true, \"triton.cudagraph_trees\": true, \"triton.cudagraph_trees_history_recording\": false, \"triton.cudagraph_unexpected_rerecord_limit\": 128, \"triton.cudagraphs\": false, \"triton.debug_sync_graph\": false, \"triton.debug_sync_kernel\": false, \"triton.decompose_k_threshold\": 32, \"triton.dense_indexing\": false, \"triton.descriptive_names\": \"original_aten\", \"triton.disallow_failing_autotune_kernels_TESTING_ONLY\": false, \"triton.divisible_by_16\": true, \"triton.enable_persistent_tma_matmul\": false, \"triton.fast_path_cudagraph_asserts\": false, \"triton.force_cooperative_reductions\": false, \"triton.force_cudagraph_sync\": false, \"triton.force_cudagraphs_warmup\": false, \"triton.inject_relu_bug_TESTING_ONLY\": null, \"triton.max_tiles\": null, \"triton.min_split_scan_rblock\": 256, \"triton.multi_kernel\": 0, \"triton.num_decompose_k_splits\": 10, \"triton.persistent_reductions\": true, \"triton.prefer_nd_tiling\": false, \"triton.skip_cudagraph_warmup\": false, \"triton.skip_l1_cache\": false, \"triton.slow_path_cudagraph_asserts\": true, \"triton.spill_threshold\": 16, \"triton.store_cubin\": false, \"triton.tile_reductions\": false, \"triton.tiling_prevents_pointwise_fusion\": true, \"triton.tiling_prevents_reduction_fusion\": true, \"triton.unique_kernel_names\": true, \"triton.unique_user_kernel_names\": false, \"triton.use_block_ptr\": false, \"triton.use_tensor_descriptor\": false, \"triton_kernel_default_layout_constraint\": \"needs_fixed_stride_order\", \"unbacked_symint_fallback\": 8192, \"unroll_reductions_threshold\": 8, \"unsafe_ignore_unsupported_triton_autotune_args\": false, \"unsafe_marked_cacheable_functions\": {}, \"unsafe_skip_cache_dynamic_shape_guards\": false, \"use_experimental_benchmarker\": true, \"use_fast_math\": false, \"use_mixed_mm\": true, \"use_static_cuda_launcher\": true, \"verbose_progress\": false, \"warn_mix_layout\": false, \"worker_start_method\": \"subprocess\", \"worker_suppress_logging\": true}", "remote_cache_version": null, "inductor_fx_remote_cache_hit_count": null, "inductor_fx_remote_cache_miss_count": null, "inductor_fx_remote_cache_backend_type": null, "inductor_fx_remote_cache_hit_keys": null, "inductor_fx_remote_cache_miss_keys": null, "cuda_version": "12.4", "triton_version": "3.4.0", "feature_usage": {"aot_autograd_remote_cache": false, "fx_cache": true, "parallel_compile_post_warmup": false, "static_cuda_launcher": true, "triton_bundling": true}, "compile_time_autotune_time_us": 3720, "is_runtime": false, "gc_time_us": 6878, "tensorify_float_attempt": null, "tensorify_float_success": null, "tensorify_float_failure": null, "guard_latency_us": 76, "recompile_reason": "0/0: ___check_obj_id(fn, 139645370122560)                   ", "num_graph_breaks": 0, "triton_kernel_compile_times_us": "[[\"triton_poi_fused_all_gather_into_tensor_relu_1\", 275030], [\"triton_poi_fused_add_mul_repeat_2\", 241968], [\"triton_per_fused_all_reduce_gelu_native_layer_norm_0\", 200965]]", "ir_count": 123, "cudagraph_skip_reason": null, "python_version": "3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]", "pgo_put_remote_code_state_time_us": null, "pgo_get_remote_code_state_time_us": null, "param_numel": 2099200, "param_bytes": 4198400, "param_count": 4, "recompile_user_contexts": null}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0}
V0804 12:34:17.616000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 2, "attempt": 0, "has_payload": "e5e170a8abbb6cfeb1f911f0268e54c7"}
	{
	"name": "dynamo",
	"ts": 1754336057616827.0,
	"args": {
	"compile_id": "0/1",
	"num_graph_breaks": 0,
	"guard_latency_us": 76,
	"frame_key": "2",
	"co_name": "inner",
	"co_filename": "/home/skarjala/pytorch/torch/_dynamo/external_utils.py",
	"co_firstlineno": 66,
	"cache_size": 1,
	"accumulated_cache_size": 1,
	"guard_count": 74,
	"shape_env_guard_count": 0,
	"graph_op_count": 16,
	"graph_node_count": 23,
	"graph_input_count": 6,
	"fail_type": null,
	"fail_reason": null,
	"fail_user_frame_filename": null,
	"fail_user_frame_lineno": null,
	"non_compliant_ops": [],
	"compliant_custom_ops": [
	"_c10d_functional::all_gather_into_tensor",
	"_c10d_functional::reduce_scatter_tensor",
	"_c10d_functional::all_reduce",
	"_c10d_functional::wait_tensor"
	],
	"restart_reasons": [],
	"dynamo_time_before_restart_s": 0.0,
	"has_guarded_code": true,
	"dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.618000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "d12146f7cea70f5bcbd201d87761d0c7"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057618449.5,
	"args": {
	"kernel_name": "triton_poi_fused_all_gather_into_tensor_relu_1",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.619000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "4010c9af9457d49754c6fd46b2fdf585"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057619328.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.650000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "65f713b9210df3d5d122cf6a56ff560b"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057650626.8,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.651000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "e1389d214d9a14fb65c01353f08d6a07"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057651446.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.664000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "9af83c401cd846ee17d03bc8bc4ee499"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057664746.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.665000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "5d874912142c9bfd726b1f86e19a0e74"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057665164.5,
	"args": {
	"kernel_name": "triton_poi_fused_all_gather_into_tensor_relu_1",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.666000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "b3cea9f7482bbd3f76dfcef4848e1501"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057666301.8,
	"args": {
	"kernel_name": "triton_poi_fused_add_mul_repeat_2",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.667000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "acb4dc136e497003711efcd4ffc16634"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057667075.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.676000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "ab15fe0f95c885a59701a1f202e2c376"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057676590.5,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.677000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "10061e3509b8d2b1b6bea2f8c0cd17f4"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057677333.8,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "1bbdb7e90d19a309656a9c38d86eac43"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057686403.5,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "f7e91746014d42c8f6f90be6d82ab3b7"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057686856.2,
	"args": {
	"kernel_name": "triton_poi_fused_add_mul_repeat_2",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.690000 1142858 torch/_dynamo/utils.py:1626] {"compilation_metrics_runtime": {"compile_id": "0/1", "frame_key": null, "co_name": null, "co_filename": null, "co_firstlineno": null, "cache_size": null, "accumulated_cache_size": null, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1754336057.665496, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": null, "compliant_custom_ops": null, "restart_reasons": null, "dynamo_time_before_restart_s": null, "has_guarded_code": null, "remote_cache_time_saved_s": null, "structured_logging_overhead_s": null, "config_suppress_errors": false, "config_inline_inbuilt_nn_modules": true, "specialize_float": null, "dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}", "is_forward": true, "num_triton_bundles": null, "remote_fx_graph_cache_get_time_ms": null, "remote_fx_graph_cache_put_time_ms": null, "start_time_us": 1754336057665496, "duration_us": 67268, "dynamo_cumulative_compile_time_us": null, "aot_autograd_cumulative_compile_time_us": null, "inductor_cumulative_compile_time_us": null, "inductor_code_gen_cumulative_compile_time_us": null, "triton_compile_time_us": null, "runtime_cudagraphify_time_us": null, "runtime_triton_autotune_time_us": 67268, "dynamo_compile_time_before_restart_us": null, "distributed_ephemeral_timeout_us": null, "structured_logging_overhead_us": null, "remote_fx_graph_cache_get_time_us": null, "remote_fx_graph_cache_put_time_us": null, "backward_cumulative_compile_time_us": null, "end_time_us": 1754336057687713, "pre_grad_pass_time_us": null, "post_grad_pass_time_us": null, "joint_graph_pass_time_us": null, "log_format_version": 3, "inductor_config": "{\"TYPE_CHECKING\": false, \"_cache_config_ignore_prefix\": [\"trace\", \"cuda.cutlass_dir\", \"worker_start_method\", \"compile_threads\", \"post_grad_custom_post_pass\", \"post_grad_custom_pre_pass\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\", \"always_complex_memory_overlap_TESTING_ONLY\", \"fx_graph_cache\", \"fx_graph_remote_cache\", \"autotune_local_cache\", \"autotune_remote_cache\"], \"_collective.auto_select\": false, \"_collective.one_shot_all_reduce_threshold_bytes\": 131072, \"_fuse_ddp_bucket_size\": 25, \"_fuse_ddp_communication\": false, \"_fuse_ddp_communication_passes\": [\"fuse_ddp_with_concat_op\", \"schedule_comm_wait\"], \"_micro_pipeline_tp\": false, \"_post_fusion_custom_pass\": null, \"_pre_fusion_custom_pass\": null, \"_profile_var\": \"\", \"_raise_error_for_testing\": false, \"_save_config_ignore\": [\"trace.upload_tar\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"pre_grad_custom_pass\", \"aot_inductor.repro_level\", \"aot_inductor.dump_aoti_minifier\", \"post_grad_custom_pre_pass\", \"post_grad_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\"], \"add_pre_grad_passes\": null, \"aggressive_fusion\": false, \"alignment_asserts\": true, \"allow_buffer_reuse\": true, \"always_complex_memory_overlap_TESTING_ONLY\": false, \"always_keep_tensor_constants\": false, \"annotate_training\": false, \"aot_inductor.allow_stack_allocation\": false, \"aot_inductor.compile_standalone\": false, \"aot_inductor.compile_wrapper_opt_level\": \"O1\", \"aot_inductor.custom_op_libs\": null, \"aot_inductor.custom_ops_to_c_shims\": {}, \"aot_inductor.debug_compile\": false, \"aot_inductor.debug_intermediate_value_printer\": \"0\", \"aot_inductor.dump_aoti_minifier\": false, \"aot_inductor.embed_kernel_binary\": false, \"aot_inductor.emit_multi_arch_kernel\": false, \"aot_inductor.enable_lto\": false, \"aot_inductor.filtered_kernel_names\": null, \"aot_inductor.force_mmap_weights\": false, \"aot_inductor.metadata\": {}, \"aot_inductor.model_name_for_generated_files\": null, \"aot_inductor.output_path\": \"\", \"aot_inductor.package\": false, \"aot_inductor.package_constants_in_so\": true, \"aot_inductor.package_constants_on_disk\": false, \"aot_inductor.package_cpp_only\": null, \"aot_inductor.precompile_headers\": true, \"aot_inductor.presets\": {}, \"aot_inductor.raise_error_on_ignored_optimization\": true, \"aot_inductor.repro_level\": 2, \"aot_inductor.serialized_in_spec\": \"\", \"aot_inductor.serialized_out_spec\": \"\", \"aot_inductor.use_consts_asm_build\": true, \"aot_inductor.use_minimal_arrayref_interface\": false, \"aot_inductor.use_runtime_constant_folding\": false, \"aot_inductor.weight_use_caching_allocator\": false, \"assert_indirect_indexing\": true, \"assume_aligned_inputs\": false, \"assume_unaligned_fallback_output\": false, \"autoheuristic_collect\": \"\", \"autoheuristic_log_path\": \"DEFAULT\", \"autoheuristic_use\": \"mixed_mm\", \"autotune_fallback_to_aten\": false, \"autotune_in_subproc\": false, \"autotune_local_cache\": true, \"autotune_lookup_table\": {}, \"autotune_multi_device\": false, \"autotune_num_choices_displayed\": 10, \"autotune_remote_cache\": null, \"b2b_gemm_pass\": false, \"batch_fusion\": true, \"benchmark_combo_kernel\": false, \"benchmark_epilogue_fusion\": true, \"benchmark_fusion\": false, \"benchmark_harness\": true, \"benchmark_kernel\": false, \"bfloat16_atomic_adds_enabled\": true, \"bucket_all_gathers_fx\": \"none\", \"bucket_all_gathers_fx_bucket_size_determinator\": null, \"bucket_reduce_scatters_fx\": \"none\", \"bucket_reduce_scatters_fx_bucket_size_determinator\": null, \"bundle_triton_into_fx_graph_cache\": true, \"bundled_autotune_remote_cache\": null, \"bw_outputs_user_visible\": true, \"can_inplace_pad_graph_input\": false, \"check_stack_no_cycles_TESTING_ONLY\": false, \"combo_kernel_allow_mixed_sizes\": 1, \"combo_kernel_foreach_dynamic_shapes\": true, \"combo_kernels\": false, \"combo_kernels_autotune\": 1, \"comment_origin\": false, \"compile_threads\": 32, \"comprehensive_padding\": true, \"compute_all_bounds\": false, \"constant_and_index_propagation\": true, \"conv_1x1_as_mm\": false, \"coordinate_descent_check_all_directions\": false, \"coordinate_descent_search_radius\": 1, \"coordinate_descent_tuning\": false, \"cpp.cxx\": [null, \"g++\"], \"cpp.descriptive_names\": \"original_aten\", \"cpp.dynamic_threads\": false, \"cpp.enable_concat_linear\": false, \"cpp.enable_floating_point_contract_flag\": \"off\", \"cpp.enable_grouped_gemm_template\": false, \"cpp.enable_kernel_profile\": false, \"cpp.enable_loop_tail_vec\": true, \"cpp.enable_tiling_heuristics\": true, \"cpp.enable_unsafe_math_opt_flag\": false, \"cpp.fallback_scatter_reduce_sum\": true, \"cpp.force_inline_kernel\": false, \"cpp.gemm_cache_blocking\": null, \"cpp.gemm_max_k_slices\": 1, \"cpp.gemm_thread_factors\": null, \"cpp.inject_log1p_bug_TESTING_ONLY\": null, \"cpp.inject_relu_bug_TESTING_ONLY\": null, \"cpp.max_horizontal_fusion_size\": 16, \"cpp.min_chunk_size\": 512, \"cpp.no_redundant_loops\": true, \"cpp.simdlen\": null, \"cpp.threads\": -1, \"cpp.use_decompose_tanh\": false, \"cpp.use_small_dequant_buffer\": false, \"cpp.vec_isa_ok\": null, \"cpp.weight_prepack\": true, \"cpp_cache_precompile_headers\": true, \"cpp_wrapper\": false, \"cpp_wrapper_build_separate\": false, \"cpu_backend\": \"cpp\", \"cuda.arch\": null, \"cuda.binary_remote_cache_force_write\": false, \"cuda.compile_opt_level\": \"-O1\", \"cuda.cuda_cxx\": null, \"cuda.cutlass_backend_min_gemm_size\": 1, \"cuda.cutlass_dir\": \"/home/skarjala/pytorch/third_party/cutlass\", \"cuda.cutlass_enabled_ops\": \"all\", \"cuda.cutlass_epilogue_fusion_enabled\": false, \"cuda.cutlass_hash_with_compile_cmd\": false, \"cuda.cutlass_instantiation_level\": \"0\", \"cuda.cutlass_max_profiling_configs\": null, \"cuda.cutlass_max_profiling_swizzle_options\": [1, 2, 4, 8], \"cuda.cutlass_op_allowlist_regex\": null, \"cuda.cutlass_op_denylist_regex\": null, \"cuda.cutlass_prescreening\": true, \"cuda.cutlass_presets\": null, \"cuda.cutlass_tma_only\": false, \"cuda.enable_caching_codegen\": true, \"cuda.enable_cuda_lto\": false, \"cuda.enable_debug_info\": false, \"cuda.enable_ptxas_info\": false, \"cuda.generate_test_runner\": false, \"cuda.upload_to_binary_remote_cache\": false, \"cuda.use_binary_remote_cache\": true, \"cuda.use_fast_math\": false, \"cuda.version\": null, \"cuda_backend\": \"triton\", \"dce\": false, \"debug\": false, \"debug_fusion\": false, \"debug_index_asserts\": false, \"debug_ir_traceback\": false, \"decompose_mem_bound_mm\": false, \"developer_warnings\": true, \"disable_cpp_codegen\": false, \"disable_padding_cpu\": true, \"disable_progress\": true, \"dynamic_scale_rblock\": true, \"efficient_conv_bn_eval_fx_passes\": false, \"emulate_precision_casts\": false, \"enable_auto_functionalized_v2\": true, \"enable_caching_generated_triton_templates\": true, \"enable_linear_binary_folding\": false, \"enabled_metric_tables\": \"\", \"epilogue_fusion\": true, \"epilogue_fusion_first\": false, \"estimate_op_runtime\": \"default\", \"external_matmul\": [], \"fallback_random\": false, \"force_fuse_int_mm_with_mul\": false, \"force_layout_optimization\": false, \"force_pointwise_cat\": false, \"force_same_precision\": false, \"force_shape_pad\": false, \"freezing\": false, \"freezing_discard_parameters\": false, \"fx_graph_cache\": true, \"fx_graph_remote_cache\": null, \"fx_passes_numeric_check\": {\"num_iterations\": 1, \"pre_grad\": false, \"precision\": 0.0001, \"requires_optimizer\": true}, \"generate_intermediate_hooks\": false, \"global_cache_dir\": null, \"graph_partition\": false, \"group_fusion\": false, \"halide.asserts\": false, \"halide.cpu_target\": \"host\", \"halide.debug\": false, \"halide.gpu_target\": \"host-cuda\", \"halide.scan_kernels\": false, \"halide.scheduler_cpu\": \"Adams2019\", \"halide.scheduler_cuda\": \"Anderson2021\", \"implicit_fallbacks\": true, \"inplace_buffers\": true, \"inplace_padding\": true, \"inter_node_bw\": 25, \"intra_node_bw\": 300, \"is_nightly_or_source\": true, \"is_predispatch\": false, \"joint_custom_post_pass\": null, \"joint_custom_pre_pass\": null, \"joint_graph_constant_folding\": true, \"keep_output_stride\": true, \"kernel_name_max_ops\": 10, \"layout_opt_default\": \"1\", \"layout_optimization\": true, \"loop_ordering_after_fusion\": false, \"max_autotune\": false, \"max_autotune_conv_backends\": \"ATEN,TRITON\", \"max_autotune_flex_search_space\": \"DEFAULT\", \"max_autotune_gemm\": false, \"max_autotune_gemm_backends\": \"ATEN,TRITON,CPP\", \"max_autotune_gemm_search_space\": \"DEFAULT\", \"max_autotune_pointwise\": false, \"max_autotune_report_choices_stats\": true, \"max_autotune_subproc_graceful_timeout_seconds\": 0.0, \"max_autotune_subproc_result_timeout_seconds\": 60.0, \"max_autotune_subproc_terminate_timeout_seconds\": 0.0, \"max_epilogue_benchmarked_choices\": 1, \"max_fusion_buffer_group_pairwise_attempts\": 64, \"max_fusion_size\": 64, \"max_pointwise_cat_inputs\": 8, \"memory_planning\": false, \"memory_pool\": \"intermediates\", \"min_num_split\": 0, \"mixed_mm_choice\": \"heuristic\", \"multi_kernel_hints\": [], \"nan_asserts\": false, \"non_blocking_remote_cache_write\": true, \"online_softmax\": true, \"optimize_scatter_upon_const_tensor\": true, \"pad_channels_last\": false, \"pad_outputs\": false, \"padding_alignment_bytes\": 128, \"padding_stride_threshold\": 1024, \"pattern_matcher\": true, \"permute_fusion\": false, \"pick_loop_orders\": true, \"post_grad_custom_post_pass\": null, \"post_grad_custom_pre_pass\": null, \"post_grad_fusion_options\": {}, \"pre_grad_custom_pass\": null, \"pre_grad_fusion_options\": {}, \"precompilation_timeout_seconds\": 3600, \"profile_bandwidth\": false, \"profile_bandwidth_output\": null, \"profile_bandwidth_regex\": \"\", \"profile_bandwidth_with_do_bench_using_profiling\": false, \"profiler_mark_wrapper_call\": false, \"prologue_fusion\": true, \"quiesce_async_compile_pool\": false, \"realize_acc_reads_size_threshold\": null, \"realize_acc_reads_threshold\": 8, \"realize_opcount_threshold\": 30, \"realize_reads_threshold\": 4, \"remove_pre_grad_passes\": null, \"reorder_for_compute_comm_overlap\": false, \"reorder_for_compute_comm_overlap_passes\": [\"reorder_compute_for_overlap\", \"sink_waits\", \"raise_comms\"], \"reorder_for_locality\": true, \"reorder_for_peak_memory\": true, \"reorder_prefetch_limit\": null, \"rocm.arch\": [], \"rocm.ck_dir\": null, \"rocm.ck_max_profiling_configs\": null, \"rocm.ck_supported_arch\": [\"gfx90a\", \"gfx942\", \"gfx950\"], \"rocm.ck_tile_max_profiling_configs\": null, \"rocm.compile_opt_level\": \"-O2\", \"rocm.flush_denormals\": true, \"rocm.generate_test_runner\": false, \"rocm.is_debug\": false, \"rocm.kBatch_sweep\": null, \"rocm.n_max_profiling_configs\": null, \"rocm.print_kernel_resource_usage\": false, \"rocm.rocm_home\": null, \"rocm.save_temps\": false, \"rocm.split_k_threshold\": 16, \"rocm.use_fast_math\": true, \"rocm.use_preselected_instances\": false, \"save_args\": false, \"scalar_asserts\": true, \"score_fusion_memory_threshold\": 10, \"search_autotune_cache\": false, \"shape_padding\": true, \"size_asserts\": true, \"sleep_sec_TESTING_ONLY\": null, \"split_cat_fx_passes\": true, \"split_reductions\": true, \"static_launch_user_defined_triton_kernels\": false, \"static_weight_shapes\": true, \"strict_static_cuda_launcher\": false, \"test_configs.autotune_choice_desc_regex\": null, \"test_configs.autotune_choice_name_regex\": null, \"test_configs.force_extern_kernel_in_multi_template\": false, \"test_configs.graphsafe_rng_func_ignores_fallback_random\": false, \"test_configs.max_mm_configs\": null, \"test_configs.runtime_triton_dtype_assert\": false, \"test_configs.static_cpp_dtype_assert\": false, \"trace.compile_profile\": false, \"trace.debug_dir\": null, \"trace.debug_log\": false, \"trace.dot_graph_shape\": null, \"trace.draw_orig_fx_graph\": false, \"trace.enabled\": true, \"trace.fx_graph\": true, \"trace.fx_graph_transformed\": true, \"trace.graph_diagram\": false, \"trace.info_log\": false, \"trace.ir_post_fusion\": true, \"trace.ir_pre_fusion\": true, \"trace.log_autotuning_results\": false, \"trace.log_url_for_graph_xform\": null, \"trace.output_code\": true, \"trace.provenance_tracking\": true, \"trace.save_real_tensors\": false, \"trace.upload_tar\": null, \"triton.autotune_at_compile_time\": null, \"triton.autotune_cublasLt\": true, \"triton.autotune_pointwise\": true, \"triton.autotune_with_sample_inputs\": false, \"triton.coalesce_tiling_analysis\": true, \"triton.codegen_upcast_to_fp32\": true, \"triton.cooperative_reductions\": false, \"triton.cudagraph_capture_sizes\": null, \"triton.cudagraph_dynamic_shape_warn_limit\": 50, \"triton.cudagraph_skip_dynamic_graphs\": false, \"triton.cudagraph_support_input_mutation\": true, \"triton.cudagraph_trees\": true, \"triton.cudagraph_trees_history_recording\": false, \"triton.cudagraph_unexpected_rerecord_limit\": 128, \"triton.cudagraphs\": false, \"triton.debug_sync_graph\": false, \"triton.debug_sync_kernel\": false, \"triton.decompose_k_threshold\": 32, \"triton.dense_indexing\": false, \"triton.descriptive_names\": \"original_aten\", \"triton.disallow_failing_autotune_kernels_TESTING_ONLY\": false, \"triton.divisible_by_16\": true, \"triton.enable_persistent_tma_matmul\": false, \"triton.fast_path_cudagraph_asserts\": false, \"triton.force_cooperative_reductions\": false, \"triton.force_cudagraph_sync\": false, \"triton.force_cudagraphs_warmup\": false, \"triton.inject_relu_bug_TESTING_ONLY\": null, \"triton.max_tiles\": null, \"triton.min_split_scan_rblock\": 256, \"triton.multi_kernel\": 0, \"triton.num_decompose_k_splits\": 10, \"triton.persistent_reductions\": true, \"triton.prefer_nd_tiling\": false, \"triton.skip_cudagraph_warmup\": false, \"triton.skip_l1_cache\": false, \"triton.slow_path_cudagraph_asserts\": true, \"triton.spill_threshold\": 16, \"triton.store_cubin\": false, \"triton.tile_reductions\": false, \"triton.tiling_prevents_pointwise_fusion\": true, \"triton.tiling_prevents_reduction_fusion\": true, \"triton.unique_kernel_names\": true, \"triton.unique_user_kernel_names\": false, \"triton.use_block_ptr\": false, \"triton.use_tensor_descriptor\": false, \"triton_kernel_default_layout_constraint\": \"needs_fixed_stride_order\", \"unbacked_symint_fallback\": 8192, \"unroll_reductions_threshold\": 8, \"unsafe_ignore_unsupported_triton_autotune_args\": false, \"unsafe_marked_cacheable_functions\": {}, \"unsafe_skip_cache_dynamic_shape_guards\": false, \"use_experimental_benchmarker\": true, \"use_fast_math\": false, \"use_mixed_mm\": true, \"use_static_cuda_launcher\": true, \"verbose_progress\": false, \"warn_mix_layout\": false, \"worker_start_method\": \"subprocess\", \"worker_suppress_logging\": true}", "remote_cache_version": null, "inductor_fx_remote_cache_hit_count": null, "inductor_fx_remote_cache_miss_count": null, "inductor_fx_remote_cache_backend_type": null, "inductor_fx_remote_cache_hit_keys": null, "inductor_fx_remote_cache_miss_keys": null, "cuda_version": "12.4", "triton_version": "3.4.0", "feature_usage": null, "compile_time_autotune_time_us": null, "is_runtime": true, "gc_time_us": null, "tensorify_float_attempt": null, "tensorify_float_success": null, "tensorify_float_failure": null, "guard_latency_us": null, "recompile_reason": null, "num_graph_breaks": null, "triton_kernel_compile_times_us": null, "ir_count": null, "cudagraph_skip_reason": null, "python_version": "3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]", "pgo_put_remote_code_state_time_us": null, "pgo_get_remote_code_state_time_us": null, "param_numel": null, "param_bytes": null, "param_count": null, "recompile_user_contexts": null}, "rank": 3, "frame_id": 0, "frame_compile_id": 2}
V0804 12:34:16.314000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "7c90a21f65537fe33bd4da7786393ffb"}
	{
	"name": "dynamo",
	"ts": 1754336056313939.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.314000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "47c40858947eb348e0dc5db36fb282e9"}
	{
	"name": "entire_frame_compile",
	"ts": 1754336056314332.0,
	"args": {
	"fn_name": "_compile.compile_inner",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.315000 1142858 torch/_dynamo/guards.py:3824] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "7dde321851e25222fcdf3cd24a328e08"}
	[
	"0/0: ___check_obj_id(fn, 139645370122560)                   "
	]
V0804 12:34:16.315000 1142858 torch/_dynamo/convert_frame.py:231] {"dynamo_start": {"stack": [{"line": 191, "name": "<module>", "filename": 1, "loc": "main()"}, {"line": 165, "name": "main", "filename": 1, "loc": "_ = compiled_graph_one(x, y, world_size)"}, {"line": 804, "name": "compile_wrapper", "filename": 2, "loc": "return fn(*args, **kwargs)"}, {"line": 66, "name": "inner", "filename": 3}]}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.315000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "d30538d5b5348faacbd331f749954da1"}
	{
	"name": "compile_attempt_0",
	"ts": 1754336056315927.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.317000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "d366bef3b9e6e50ef36d2283ae9dd85c"}
	{
	"name": "bytecode_tracing",
	"ts": 1754336056317708.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.325000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 0, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.326000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1024, 1], "storage": 0, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0275d78370>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.326000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 0, "source": "L['fn'].__self__._modules['lin1']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.328000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 1, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.329000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "stride": [1024, 1], "storage": 1, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Tensor object at 0x7f02578e68a0>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.329000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 1, "source": "L['args'][0]"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.337000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 2, "describer_id": 7, "size": 2048}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.338000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 2, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0276252c60>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.338000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 3, "source": "L['fn'].__self__._modules['norm']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.340000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 3, "describer_id": 7, "size": 2048}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.340000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 3, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f02762520d0>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.341000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 4, "source": "L['fn'].__self__._modules['norm']._parameters['bias']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.363000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 4, "describer_id": 7, "size": 2097152}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.363000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 15, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [1024, 1024], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1024, 1], "storage": 4, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Parameter object at 0x7f0276250c80>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.364000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 15, "source": "L['fn'].__self__._modules['lin2']._parameters['weight']"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.373000 1142858 torch/_subclasses/meta_utils.py:270] {"describe_storage": {"id": 5, "describer_id": 7, "size": 4194304}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.373000 1142858 torch/_subclasses/meta_utils.py:487] {"describe_tensor": {"id": 19, "ndim": 2, "dtype": "torch.float16", "device": "device(type='cuda', index=1)", "size": [2048, 1024], "is_leaf": true, "stride": [1024, 1], "storage": 5, "view_func": "_CustomViewFunc(func=<built-in method _view_func_unsafe of Tensor object at 0x7f0276250690>)", "describer_id": 7}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.374000 1142858 torch/_subclasses/meta_utils.py:1899] {"describe_source": {"describer_id": 7, "id": 19, "source": "L['args'][1]"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:16.380000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5280f2dfd9df0aa55464b0bd925840f8"}
	{
	"name": "bytecode_tracing",
	"ts": 1754336056380758.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.385000 1142858 torch/_dynamo/output_graph.py:1686] {"dynamo_output_graph": {"sizes": {"l_fn_self_modules_lin1_parameters_weight_": [1024, 1024], "l_args_0_": [1024, 1024], "l_fn_self_modules_norm_parameters_weight_": [1024], "l_fn_self_modules_norm_parameters_bias_": [1024], "l_fn_self_modules_lin2_parameters_weight_": [1024, 1024], "l_args_1_": [2048, 1024], "h": [1024, 1024], "h_1": [1024, 1024], "h_2": [1024, 1024], "all_reduce_default": [1024, 1024], "h_3": [1024, 1024], "h2": [1024, 1024], "h2_1": [1024, 1024], "all_gather_into_tensor_default": [2048, 1024], "gathered": [2048, 1024], "g": [2048, 1024], "reduce_scatter_tensor_default": [1024, 1024], "rs": [1024, 1024], "rs_expanded": [2048, 1024], "out": [2048, 1024]}}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "a887576c59d8b651fcb075634b10ab10"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
V0804 12:34:16.386000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "2be60ddb9bc5333c2c380c178be9bbaa"}
	{
	"name": "backend_compile",
	"ts": 1754336056386431.8,
	"args": {
	"fn_name": "OutputGraph.call_user_compiler",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.388000 1142858 torch/_inductor/compile_fx.py:2185] {"artifact": {"name": "before_pre_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "9f30354df593b94d410ba0c8b868cf1d"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
	
	 # graph id: 139645242301984
V0804 12:34:16.388000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "9f6e9cb61b8237dce327a717ec937586"}
	{
	"name": "_recursive_pre_grad_passes",
	"ts": 1754336056388510.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.389000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "0d1b28d37d9e0bbbc36cc9e003a76368"}
	{
	"name": "_recursive_pre_grad_passes",
	"ts": 1754336056389709.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.391000 1142858 torch/_inductor/compile_fx.py:2216] {"artifact": {"name": "after_pre_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "9f30354df593b94d410ba0c8b868cf1d"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_fn_self_modules_lin1_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_0_: "f16[1024, 1024][1024, 1]cuda:1", L_fn_self_modules_norm_parameters_weight_: "f16[1024][1]cuda:1", L_fn_self_modules_norm_parameters_bias_: "f16[1024][1]cuda:1", L_fn_self_modules_lin2_parameters_weight_: "f16[1024, 1024][1024, 1]cuda:1", L_args_1_: "f16[2048, 1024][1024, 1]cuda:1"):
	        l_fn_self_modules_lin1_parameters_weight_ = L_fn_self_modules_lin1_parameters_weight_
	        l_args_0_ = L_args_0_
	        l_fn_self_modules_norm_parameters_weight_ = L_fn_self_modules_norm_parameters_weight_
	        l_fn_self_modules_norm_parameters_bias_ = L_fn_self_modules_norm_parameters_bias_
	        l_fn_self_modules_lin2_parameters_weight_ = L_fn_self_modules_lin2_parameters_weight_
	        l_args_1_ = L_args_1_
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None
	        
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        h: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(l_args_0_, l_fn_self_modules_lin1_parameters_weight_, None);  l_args_0_ = l_fn_self_modules_lin1_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        h_1: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.gelu(h);  h = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        h_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.layer_norm(h_1, (1024,), l_fn_self_modules_norm_parameters_weight_, l_fn_self_modules_norm_parameters_bias_, 1e-05);  h_1 = l_fn_self_modules_norm_parameters_weight_ = l_fn_self_modules_norm_parameters_bias_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        h_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        h2: "f16[1024, 1024][1024, 1]cuda:1" = torch._C._nn.linear(h_3, l_fn_self_modules_lin2_parameters_weight_, None);  h_3 = l_fn_self_modules_lin2_parameters_weight_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        h2_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.nn.functional.relu(h2);  h2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor_default: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        gathered: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        g: "f16[2048, 1024][1024, 1]cuda:1" = gathered * 0.7071067811865476;  gathered = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor_default: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(l_args_1_, 'sum', 2, '0');  l_args_1_ = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        rs: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        rs_expanded: "f16[2048, 1024][1024, 1]cuda:1" = rs.repeat(2, 1);  rs = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        out: "f16[2048, 1024][1024, 1]cuda:1" = g + rs_expanded;  g = rs_expanded = None
	        
	        # No stacktrace found for following nodes
	        _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None
	        return (out,)
	        
	
	 # graph id: 139645242301984
V0804 12:34:16.406000 1142858 torch/_dynamo/utils.py:1970] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "9a6a23ab58ab474257f3a4e893130f53"}
	{
	"name": "autograd_cache_miss",
	"ts": 1754336056406148.5,
	"args": {
	"cache_status_detailed": "full_miss",
	"key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp",
	"cache_state": "miss",
	"components": [
	"[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False",
	"[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>",
	"[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])",
	"[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"compile_id": "0/1"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0804 12:34:16.407000 1142858 torch/_functorch/_aot_autograd/autograd_cache.py:1231] {"artifact": {"name": "aotautograd_cache_miss", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "788d107aba066052e238c3a6e11503b1"}
	{"cache_status_detailed": "full_miss", "key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp", "cache_state": "miss", "components": ["[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False", "[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>", "[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])", "[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ", "[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)", "[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>", "[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}", "[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}", "[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False", "[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10", "[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True", "[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']", "[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None", "[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op", "[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait", "[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"], "compile_id": "0/1"}
V0804 12:34:16.408000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "2672a8794196028615a8c5dc0cd4545d"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1754336056408019.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.411000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "37dbf44617e2cc9cf4cb8f87dcd2168b"}
	{
	"name": "aot_collect_metadata",
	"ts": 1754336056411498.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.430000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "b4dd7b13c294c54c6c350813d71e311f"}
	{
	"name": "aot_collect_metadata",
	"ts": 1754336056430062.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.489000 1142858 torch/_functorch/_aot_autograd/graph_capture.py:301] {"artifact": {"name": "aot_forward_graph_fw_metadata", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "083ebbd57ef41f8da24878484b104f67"}
	ViewAndMutationMeta(input_info=[InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=False,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=True,
	                                              keep_input_mutations=True),
	                               InputAliasInfo(is_leaf=True,
	                                              mutates_data=False,
	                                              mutates_metadata=False,
	                                              mutations_hidden_from_autograd=True,
	                                              mutations_under_no_grad_or_inference_mode=False,
	                                              mutation_inductor_storage_resize=False,
	                                              mutates_storage_metadata=False,
	                                              requires_grad=False,
	                                              keep_input_mutations=True)],
	                    output_info=[OutputAliasInfo(output_type=<OutputType.non_alias: 1>,
	                                                raw_type=<class 'torch._subclasses.functional_tensor.FunctionalTensor'>,
	                                                base_idx=None,
	                                                dynamic_dims=set(),
	                                                requires_grad=False,
	                                                functional_tensor=None)],
	                    num_intermediate_bases=0,
	                    keep_input_mutations=True,
	                    traced_tangents=[],
	                    traced_tangents_descs=[],
	                    subclass_inp_meta=[PlainTensorMeta(unwrapped_idx=0,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=1,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=2,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=3,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=4,
	                                                      memory_format=None),
	                                      PlainTensorMeta(unwrapped_idx=5,
	                                                      memory_format=None)],
	                    subclass_fw_graph_out_meta=[PlainTensorMeta(unwrapped_idx=0,
	                                                               memory_format=None)],
	                    subclass_tangent_meta=[],
	                    is_train=False,
	                    traced_tangent_metas=None,
	                    num_symints_saved_for_bw=None,
	                    grad_enabled_mutation=None,
	                    deterministic=False,
	                    static_input_indices=[0, 2, 3, 4],
	                    tokens={},
	                    indices_of_inputs_that_requires_grad_with_mutations_in_bw=[],
	                    bw_donated_idxs=None,
	                    num_backward_tokens=0,
	                    num_graphsafe_rng_states=0,
	                    graphsafe_rng_state_index=None)
V0804 12:34:16.491000 1142858 torch/_functorch/_aot_autograd/graph_capture.py:319] {"aot_inference_graph": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "11e47da400b78de48aca98e293efdee2"}
	class <lambda>(torch.nn.Module):
	    def forward(
	        self,
	        arg0_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=0)
	        arg1_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=1)
	        arg2_1: "f16[1024][1]cuda:1",  # PlainAOTInput(idx=2)
	        arg3_1: "f16[1024][1]cuda:1",  # PlainAOTInput(idx=3)
	        arg4_1: "f16[1024, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=4)
	        arg5_1: "f16[2048, 1024][1024, 1]cuda:1",  # PlainAOTInput(idx=5)
	    ):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        convert_element_type_3: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul_2, torch.float16);  mul_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        convert_element_type_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(convert_element_type_3, torch.float32);  convert_element_type_3 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_4, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(convert_element_type_4, getitem_1);  convert_element_type_4 = getitem_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (
	            add_3,  # PlainAOTOutput(idx=0)
	        )
	        
V0804 12:34:16.494000 1142858 torch/_functorch/_aot_autograd/graph_compile.py:285] {"artifact": {"name": "torch._functorch.config", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "7b8fae87b220765c393a4321db77304b"}
	{
	"TYPE_CHECKING": false,
	"functionalize_rng_ops": false,
	"fake_tensor_allow_meta": true,
	"debug_assert": false,
	"debug_partitioner": true,
	"decompose_custom_triton_ops": true,
	"static_weight_shapes": true,
	"treat_parameters_as_free_to_save": true,
	"cse": true,
	"enable_autograd_cache": true,
	"autograd_cache_allow_custom_autograd_functions": false,
	"bundled_autograd_cache": false,
	"autograd_cache_normalize_inputs": true,
	"enable_remote_autograd_cache": null,
	"view_replay_for_aliased_outputs": true,
	"max_dist_from_bw": 1000,
	"ban_recompute_used_far_apart": true,
	"ban_recompute_long_fusible_chains": true,
	"ban_recompute_materialized_backward": true,
	"ban_recompute_not_in_allowlist": true,
	"ban_recompute_reductions": true,
	"recompute_views": false,
	"activation_memory_budget": 1.0,
	"activation_memory_budget_runtime_estimator": "flops",
	"activation_memory_budget_solver": "dp",
	"visualize_memory_budget_pareto": false,
	"memory_budget_pareto_dir": null,
	"aggressive_recomputation": false,
	"fake_tensor_allow_unsafe_data_ptr_access": true,
	"unlift_effect_tokens": true,
	"custom_op_default_layout_constraint": "needs_exact_strides",
	"fake_tensor_crossref": false,
	"fake_tensor_propagate_real_tensors": false,
	"backward_pass_autocast": "same_as_forward",
	"donated_buffer": true,
	"torch_compile_graph_format": "svg",
	"generate_fake_kernels_from_real_mismatches": false,
	"graphsafe_rng_functionalization": true,
	"strict_autograd_cache": false,
	"unsafe_allow_optimization_of_collectives": false,
	"disable_guess_zero_tangent_for_mutated_input_subclass": false,
	"guess_tangent_strides_as_outputs": false,
	"_sync_decision_cross_ranks": false,
	"saved_tensors_hooks_filtering_mode": "donated"
	}
V0804 12:34:16.494000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "90d6ee195e45d620693546d5a31f80d7"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1754336056494891.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.495000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "a745cad32948a652f398e9732e150a31"}
	{
	"name": "_recursive_joint_graph_passes",
	"ts": 1754336056495829.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.499000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "0375ea534b3c7296346d7d52154cb3e0"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056499276.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.499000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5ff2046b3b8de35076afe914b1ad0582"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056499864.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.500000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "a4c9e1e03b6b998c7524a61aa4d56d98"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056500562.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.501000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "78f3cf7069e6fafb287e6822cc6054be"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056501055.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.502000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "870b6872e1d05e7fc333bf822a90f062"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056502713.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.503000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "2162fddf032e66b24405540862f234d7"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056503290.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.504000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "623f6ee68cae3e526ccdccbe048ac375"}
	{
	"name": "pad_mm_benchmark_get_do_bench",
	"ts": 1754336056503946.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.504000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "6c436b15a2c5c82cedf0ab24a18c5a94"}
	{
	"name": "pad_mm_benchmark",
	"ts": 1754336056504654.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.506000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "d524e3c70c61cd1422f2543f01744d21"}
	{
	"name": "_recursive_joint_graph_passes",
	"ts": 1754336056506002.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.506000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "aa3d7f9f3a5df299acc578e9c36d5736"}
	{
	"name": "inductor_compile",
	"ts": 1754336056506517.2,
	"args": {
	"fn_name": "compile_fx_inner",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.508000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "17532b2e7096e364ab2621f72faf8e2b"}
	{
	"name": "fx_codegen_and_compile",
	"ts": 1754336056508161.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.521000 1142858 torch/_inductor/compile_fx.py:1218] {"artifact": {"name": "fx_graph_runnable", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "c8dffcf090b13a05ef569d7c2e98e0ff"}
	
	import os
	os.environ['TORCH_TRACE'] = '1'
	os.environ['TORCHELASTIC_RESTART_COUNT'] = '0'
	os.environ['TORCHELASTIC_MAX_RESTARTS'] = '0'
	os.environ['TORCHELASTIC_RUN_ID'] = 'none'
	os.environ['TORCHELASTIC_USE_AGENT_STORE'] = 'True'
	os.environ['TORCH_NCCL_ASYNC_ERROR_HANDLING'] = '1'
	os.environ['TORCHELASTIC_ERROR_FILE'] = '/tmp/torchelastic_krot7efo/none_58jhr50i/attempt_0/1/error.json'
	os.environ['TORCH_COMPILE_DEBUG'] = '1'
	os.environ['TORCH_LOGS_FORMAT'] = '[%(filename)s:%(lineno)d %(levelname)s] %(message)s'
	os.environ['TORCH_LOGS_OUT'] = '/dev/stdout'
	os.environ['TORCHINDUCTOR_CACHE_DIR'] = '/tmp/torchinductor_cache'
	os.environ['TRITON_CACHE_DIR'] = '/tmp/torchinductor_cache/triton/1'
	
	import torch
	from torch import tensor, device
	import torch.fx as fx
	from torch._dynamo.testing import rand_strided
	from math import inf
	import torch._inductor.inductor_prims
	import torch.distributed as dist
	from torch.testing._internal.distributed.fake_pg import FakeStore
	
	import torch._dynamo.config
	import torch._inductor.config
	import torch._functorch.config
	import torch.fx.experimental._config
	
	torch._inductor.config.triton.store_cubin = False
	torch._inductor.config.trace.enabled = True
	torch._inductor.config.trace.save_real_tensors = False
	torch._functorch.config.functionalize_rng_ops = False
	torch._functorch.config.debug_partitioner = True
	torch._functorch.config.fake_tensor_allow_unsafe_data_ptr_access = True
	torch._functorch.config.unlift_effect_tokens = True
	
	
	
	isolate_fails_code_str = None
	
	
	
	
	# torch version: 2.9.0a0+git2249284
	# torch cuda version: 12.4
	# torch git version: 22492848b66f13637b01a4d8f98a16e3004940a9
	
	
	# CUDA Info: 
	# nvcc: NVIDIA (R) Cuda compiler driver 
	# Copyright (c) 2005-2024 NVIDIA Corporation 
	# Built on Thu_Mar_28_02:18:24_PDT_2024 
	# Cuda compilation tools, release 12.4, V12.4.131 
	# Build cuda_12.4.r12.4/compiler.34097967_0 
	
	# GPU Hardware Info: 
	# NVIDIA PG509-210 : 2 
	
	
	from torch.nn import *
	class Repro(torch.nn.Module):
	    def __init__(self) -> None:
	        super().__init__()
	
	    
	    
	    def forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):
	        permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)
	        getitem = var_mean[0]
	        getitem_1 = var_mean[1];  var_mean = None
	        add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None
	        mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
	def load_args(reader):
	    buf0 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf0, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg0_1
	    buf1 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf1, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg1_1
	    buf2 = reader.storage(None, 2048, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf2, (1024,), dtype=torch.float16, is_leaf=True)  # arg2_1
	    buf3 = reader.storage(None, 2048, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf3, (1024,), dtype=torch.float16, is_leaf=True)  # arg3_1
	    buf4 = reader.storage(None, 2097152, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf4, (1024, 1024), dtype=torch.float16, is_leaf=True)  # arg4_1
	    buf5 = reader.storage(None, 4194304, device=device(type='cuda', index=1), dtype_hint=torch.float16)
	    reader.tensor(buf5, (2048, 1024), dtype=torch.float16, is_leaf=True)  # arg5_1
	load_args._version = 0
	mod = Repro()
	if __name__ == '__main__':
	    from torch._dynamo.repro.after_aot import run_repro
	    # Initialize FakeProcessGroup for distributed operations
	    store = FakeStore()
	    dist.init_process_group(
	        backend="fake",
	        rank=0,
	        world_size=2,
	        store=store
	    )
	    with torch.no_grad():
	        run_repro(mod, load_args, accuracy=False, command='run', save_dir=None, tracing_mode='real', check_str=None)
	        # To run it separately, do 
	        # mod, args = run_repro(mod, load_args, accuracy=False, command='get_args', save_dir=None, tracing_mode='real', check_str=None)
	        # mod(*args)
	    dist.destroy_process_group()
	
V0804 12:34:16.525000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "890cf167d834bdb0fd317483764155dd"}
	{
	"name": "additional_fake_tensor_prop",
	"ts": 1754336056525165.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.541000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "d5b6e6d2824fe175227f4f7635f712d4"}
	{
	"name": "additional_fake_tensor_prop",
	"ts": 1754336056541768.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.544000 1142858 torch/_inductor/compile_fx.py:1267] {"artifact": {"name": "before_post_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "97a46234dae257bf8fd40d911b84825f"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f16[1024, 1024][1024, 1]cuda:1", arg1_1: "f16[1024, 1024][1024, 1]cuda:1", arg2_1: "f16[1024][1]cuda:1", arg3_1: "f16[1024][1]cuda:1", arg4_1: "f16[1024, 1024][1024, 1]cuda:1", arg5_1: "f16[2048, 1024][1024, 1]cuda:1"):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        convert_element_type_default: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None
	        var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
V0804 12:34:16.544000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "138b38f013feea2c2810d94ad007029a"}
	{
	"name": "_recursive_post_grad_passes",
	"ts": 1754336056544536.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.551000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "831c49aa2f1d0d302e85378c26b2a1ba"}
	{
	"name": "_recursive_post_grad_passes",
	"ts": 1754336056551269.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.554000 1142858 torch/_inductor/compile_fx.py:1305] {"artifact": {"name": "after_post_grad_graph", "encoding": "string"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "ed435d7c02e74345e0a9c2504ca76b90"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f16[1024, 1024][1024, 1]cuda:1", arg1_1: "f16[1024, 1024][1024, 1]cuda:1", arg2_1: "f16[1024][1]cuda:1", arg3_1: "f16[1024][1]cuda:1", arg4_1: "f16[1024, 1024][1024, 1]cuda:1", arg5_1: "f16[2048, 1024][1024, 1]cuda:1"):
	         # File: /home/skarjala/pytorch/test2.py:59 in graph_one, code: h = self.lin1(x)
	        permute: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None
	        mm: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None
	        
	         # File: /home/skarjala/pytorch/test2.py:60 in graph_one, code: h = F.gelu(h)
	        convert_element_type_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None
	        mul: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)
	        mul_1: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None
	        erf: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.erf.default(mul_1);  mul_1 = None
	        add: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None
	        
	         # File: /home/skarjala/pytorch/test2.py:61 in graph_one, code: h = self.norm(h)
	        var_mean = torch.ops.aten.var_mean.correction(mul_2, [1], correction = 0, keepdim = True)
	        getitem: "f32[1024, 1][1, 1]cuda:1" = var_mean[0]
	        getitem_1: "f32[1024, 1][1, 1]cuda:1" = var_mean[1];  var_mean = None
	        sub: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.sub.Tensor(mul_2, getitem_1);  mul_2 = getitem_1 = None
	        add_1: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None
	        rsqrt: "f32[1024, 1][1, 1]cuda:1" = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
	        mul_3: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None
	        mul_4: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None
	        add_2: "f32[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None
	        convert_element_type_5: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:65 in graph_one, code: torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")
	        all_reduce: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_reduce_.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:64 in graph_one, code: h = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None
	        
	         # File: /home/skarjala/pytorch/test2.py:70 in graph_one, code: h2 = self.lin2(h)
	        permute_1: "f16[1024, 1024][1, 1024]cuda:1" = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None
	        mm_1: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:71 in graph_one, code: h2 = F.relu(h2)
	        relu: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops.aten.relu.default(mm_1);  mm_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:75 in graph_one, code: torch.ops._c10d_functional.all_gather_into_tensor.default(
	        all_gather_into_tensor: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None
	        
	         # File: /home/skarjala/pytorch/test2.py:86 in graph_one, code: torch.ops._c10d_functional.reduce_scatter_tensor.default(
	        reduce_scatter_tensor: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:74 in graph_one, code: gathered = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_1: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:82 in graph_one, code: g = gathered * math.sqrt(0.5)
	        mul_5: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:85 in graph_one, code: rs = torch.ops._c10d_functional.wait_tensor.default(
	        wait_tensor_2: "f16[1024, 1024][1024, 1]cuda:1" = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
	        
	         # File: /home/skarjala/pytorch/test2.py:93 in graph_one, code: rs_expanded = rs.repeat(world_size, 1)  # [world_size*N, D]
	        repeat: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None
	        
	         # File: /home/skarjala/pytorch/test2.py:94 in graph_one, code: out = g + rs_expanded
	        add_3: "f16[2048, 1024][1024, 1]cuda:1" = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None
	        return (add_3,)
	        
V0804 12:34:16.555000 1142858 torch/_inductor/compile_fx.py:1317] {"artifact": {"name": "inductor_post_to_pre_grad_nodes", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5385faa7da9add5b8aed080ce40f0a99"}
	{"permute": [{"name": "h", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm": [{"name": "h", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_2": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_1": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "erf": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_2": [{"name": "h_1", "target": "<built-in function gelu>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_default", "target": "prims.convert_element_type.default", "graph_id": 139644951478880, "pass_name": "remove_noop_ops", "action": "replace", "from_node": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}, {"name": "convert_element_type_4", "target": "prims.convert_element_type.default", "graph_id": 139644951478880, "pass_name": "pass_pattern_0", "action": "replace+create", "from_node": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}]}], "var_mean": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "getitem_1": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "sub": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_1": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "rsqrt": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_3": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_4": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_2": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "convert_element_type_5": [{"name": "h_2", "target": "<function layer_norm at 0x7f01fe16eca0>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "all_reduce": [{"name": "all_reduce_default", "target": "_c10d_functional.all_reduce.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor": [{"name": "h_3", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "permute_1": [{"name": "h2", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mm_1": [{"name": "h2", "target": "<built-in function linear>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "relu": [{"name": "h2_1", "target": "<function relu at 0x7f01fe16da80>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "all_gather_into_tensor": [{"name": "all_gather_into_tensor_default", "target": "_c10d_functional.all_gather_into_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "reduce_scatter_tensor": [{"name": "reduce_scatter_tensor_default", "target": "_c10d_functional.reduce_scatter_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor_1": [{"name": "gathered", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "mul_5": [{"name": "g", "target": "<built-in function mul>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "wait_tensor_2": [{"name": "rs", "target": "_c10d_functional.wait_tensor.default", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "repeat": [{"name": "rs_expanded", "target": "repeat", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}], "add_3": [{"name": "out", "target": "<built-in function add>", "graph_id": 139645242301984, "pass_name": "Interpreter_PropagateUnbackedSymInts", "action": "create", "from_node": []}]}
V0804 12:34:16.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "f75821924e9c2353b4f3946eb6d366e4"}
	{
	"name": "GraphLowering.run",
	"ts": 1754336056556702.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.609000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5d5a2e0aa081fdb84e1a9f7dcc0b0de4"}
	{
	"name": "GraphLowering.run",
	"ts": 1754336056609207.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.609000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "707c9051d9f97b6d7cd849b21b3d3fc7"}
	{
	"name": "GraphLowering.compile_to_fn",
	"ts": 1754336056609873.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.610000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5da1bf862b530ce7c88172e7faecf15c"}
	{
	"name": "code_gen",
	"ts": 1754336056610300.5,
	"args": {
	"fn_name": "GraphLowering.compile_to_module",
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.610000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "54f75962f2756f3767b9eca10b5d9572"}
	{
	"name": "GraphLowering.codegen",
	"ts": 1754336056610684.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.612000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "cac084576df4ba9a7be6fb75151dfe66"}
	{
	"name": "Scheduler.__init__",
	"ts": 1754336056611882.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "446e4d8da5f2286816636dc91a4f1bc4"}
	{
	"name": "Scheduler.fused_nodes",
	"ts": 1754336056685976.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.691000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "ebb17982755a3bdc3fcad80ac6e602d7"}
	{
	"name": "Scheduler.fused_nodes",
	"ts": 1754336056691301.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.709000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "a0caa68cff431e5beac07b0edf24a84d"}
	{
	"name": "Scheduler.__init__",
	"ts": 1754336056709536.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.710000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "313d0d26537e0a05ef7d76bb2de559a4"}
	{
	"name": "Scheduler.codegen",
	"ts": 1754336056709973.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.789000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "6fcfa50a2cd6a4efe8f8743fb05ecb52"}
	{
	"name": "Scheduler.codegen",
	"ts": 1754336056789863.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.790000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "f5204ac80a5d2e97475762d96f156661"}
	{
	"name": "PythonWrapperCodegen.generate",
	"ts": 1754336056790474.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.797000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "4f5733ae18760680d73c9df46e2033c5"}
	{
	"name": "PythonWrapperCodegen.generate",
	"ts": 1754336056797837.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.798000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "c533d8799308abcb9db51d192da55f1a"}
	{
	"name": "GraphLowering.codegen",
	"ts": 1754336056798311.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.799000 1142858 torch/_inductor/graph.py:2390] {"inductor_output_code": {"filename": "/tmp/torchinductor_cache/2o/c2o2b5knsvinu3iyv2ufo3zaumqmodn4ad2mi47uizpf6he7ropv.py"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "3e05e0147dcb3f5d92e520c435f93996"}
	# AOT ID: ['1_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from cmath import nanj
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	import triton
	import triton.language as tl
	from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
	from torch._C import _cuda_getCurrentRawStream as get_raw_stream
	from torch._C import _cuda_getCurrentRawStream as get_raw_stream
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	assert_alignment = torch._C._dynamo.guards.assert_alignment
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
	
	
	# kernel path: /tmp/torchinductor_cache/y5/cy5cpjsbzjqu5acybwozmucja7k3xuwvs6mwcifuppxwyfxv2xcf.py
	# Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	# Source node to ATen node mapping:
	#   all_reduce_default => all_reduce
	#   h_1 => add, convert_element_type_2, erf, mul, mul_1, mul_2
	#   h_2 => add_1, add_2, convert_element_type_5, mul_3, mul_4, rsqrt, sub, var_mean
	# Graph fragment:
	#   %mm : Tensor "f16[1024, 1024][1024, 1]cuda:1" = PlaceHolder[target=mm]
	#   %getitem_1 : Tensor "f32[1024, 1][1, 1024]cuda:1" = PlaceHolder[target=getitem_1]
	#   %buf2 : Tensor "f32[1024, 1][1, 1024]cuda:1" = PlaceHolder[target=buf2]
	#   %arg2_1 : Tensor "f16[1024][1]cuda:1" = PlaceHolder[target=arg2_1]
	#   %arg3_1 : Tensor "f16[1024][1]cuda:1" = PlaceHolder[target=arg3_1]
	#   %convert_element_type_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=2] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%mm, torch.float32), kwargs = {})
	#   %mul : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 0.5), kwargs = {})
	#   %mul_1 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convert_element_type_2, 0.7071067811865476), kwargs = {})
	#   %erf : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.erf.default](args = (%mul_1,), kwargs = {})
	#   %add : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%erf, 1), kwargs = {})
	#   %mul_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=2] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul, %add), kwargs = {})
	#   %var_mean : [num_users=2] = call_function[target=torch.ops.aten.var_mean.correction](args = (%mul_2, [1]), kwargs = {correction: 0, keepdim: True})
	#   %sub : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2, %getitem_1), kwargs = {})
	#   %add_1 : Tensor "f32[1024, 1][1, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%getitem, 1e-05), kwargs = {})
	#   %rsqrt : Tensor "f32[1024, 1][1, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.rsqrt.default](args = (%add_1,), kwargs = {})
	#   %mul_3 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%sub, %rsqrt), kwargs = {})
	#   %mul_4 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%mul_3, %arg2_1), kwargs = {})
	#   %add_2 : Tensor "f32[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_4, %arg3_1), kwargs = {})
	#   %convert_element_type_5 : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.prims.convert_element_type.default](args = (%add_2, torch.float16), kwargs = {})
	#   %all_reduce : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops._c10d_functional.all_reduce_.default](args = (%convert_element_type_5, sum, 0), kwargs = {})
	#   return %getitem_1,%buf2,%wait_tensor
	triton_per_fused_all_reduce_gelu_native_layer_norm_0 = async_compile.triton('triton_per_fused_all_reduce_gelu_native_layer_norm_0', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.persistent_reduction(
	    size_hints={'x': 1024, 'r0_': 1024},
	    reduction_hint=ReductionHint.INNER,
	    filename=__file__,
	    triton_meta={'signature': {'in_out_ptr0': '*fp16', 'in_ptr0': '*fp16', 'in_ptr1': '*fp16', 'xnumel': 'i32', 'r0_numel': 'i32'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': True, 'num_load': 3, 'num_reduction': 4, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 0, 'r0_': 6295552}}
	)
	@triton.jit
	def triton_per_fused_all_reduce_gelu_native_layer_norm_0(in_out_ptr0, in_ptr0, in_ptr1, xnumel, r0_numel):
	    xnumel = 1024
	    XBLOCK: tl.constexpr = 1
	    r0_numel = 1024
	    R0_BLOCK: tl.constexpr = 1024
	    rnumel = r0_numel
	    RBLOCK: tl.constexpr = R0_BLOCK
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = tl.full([1], xoffset, tl.int32)
	    xmask = tl.full([R0_BLOCK], True, tl.int1)
	    r0_index = tl.arange(0, R0_BLOCK)[:]
	    r0_offset = 0
	    r0_mask = tl.full([R0_BLOCK], True, tl.int1)
	    roffset = r0_offset
	    rindex = r0_index
	    r0_1 = r0_index
	    x0 = xindex
	    tmp0 = tl.load(in_out_ptr0 + (r0_1 + 1024*x0), None).to(tl.float32)
	    tmp30 = tl.load(in_ptr0 + (r0_1), None, eviction_policy='evict_last').to(tl.float32)
	    tmp33 = tl.load(in_ptr1 + (r0_1), None, eviction_policy='evict_last').to(tl.float32)
	    tmp1 = tmp0.to(tl.float32)
	    tmp2 = 0.5
	    tmp3 = tmp1 * tmp2
	    tmp4 = 0.7071067811865476
	    tmp5 = tmp1 * tmp4
	    tmp6 = libdevice.erf(tmp5)
	    tmp7 = 1.0
	    tmp8 = tmp6 + tmp7
	    tmp9 = tmp3 * tmp8
	    tmp10 = tl.broadcast_to(tmp9, [R0_BLOCK])
	    tmp12 = tl.broadcast_to(tmp10, [R0_BLOCK])
	    tmp14 = triton_helpers.promote_to_tensor(tl.sum(tmp12, 0))
	    tmp15 = tl.full([1], 1024, tl.int32)
	    tmp16 = tmp15.to(tl.float32)
	    tmp17 = (tmp14 / tmp16)
	    tmp18 = tmp10 - tmp17
	    tmp19 = tmp18 * tmp18
	    tmp20 = tl.broadcast_to(tmp19, [R0_BLOCK])
	    tmp22 = triton_helpers.promote_to_tensor(tl.sum(tmp20, 0))
	    tmp23 = tmp9 - tmp17
	    tmp24 = 1024.0
	    tmp25 = (tmp22 / tmp24)
	    tmp26 = 1e-05
	    tmp27 = tmp25 + tmp26
	    tmp28 = libdevice.rsqrt(tmp27)
	    tmp29 = tmp23 * tmp28
	    tmp31 = tmp30.to(tl.float32)
	    tmp32 = tmp29 * tmp31
	    tmp34 = tmp33.to(tl.float32)
	    tmp35 = tmp32 + tmp34
	    tmp36 = tmp35.to(tl.float32)
	    tl.store(in_out_ptr0 + (r0_1 + 1024*x0), tmp36, None)
	''', device_str='cuda')
	
	
	# kernel path: /tmp/torchinductor_cache/au/caue5kfnaqefl7zlwh5ro3lh64raqnztcacwv7es3k55dzeyjtqa.py
	# Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	# Source node to ATen node mapping:
	#   all_gather_into_tensor_default => all_gather_into_tensor
	#   h2_1 => relu
	# Graph fragment:
	#   %mm_1 : Tensor "f16[1024, 1024][1024, 1]cuda:1" = PlaceHolder[target=mm_1]
	#   %relu : Tensor "f16[1024, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.relu.default](args = (%mm_1,), kwargs = {})
	#   %all_gather_into_tensor : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops._c10d_functional.all_gather_into_tensor.default](args = (%relu, 2, 0), kwargs = {})
	#   return %buf10
	triton_poi_fused_all_gather_into_tensor_relu_1 = async_compile.triton('triton_poi_fused_all_gather_into_tensor_relu_1', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.pointwise(
	    size_hints={'x': 1048576}, 
	    filename=__file__,
	    triton_meta={'signature': {'in_out_ptr0': '*fp16', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_all_gather_into_tensor_relu_1', 'mutated_arg_names': ['in_out_ptr0'], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 6291456}},
	    min_elem_per_thread=0
	)
	@triton.jit
	def triton_poi_fused_all_gather_into_tensor_relu_1(in_out_ptr0, xnumel, XBLOCK : tl.constexpr):
	    xnumel = 1048576
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = xoffset + tl.arange(0, XBLOCK)[:]
	    xmask = tl.full([XBLOCK], True, tl.int1)
	    x0 = xindex
	    tmp0 = tl.load(in_out_ptr0 + (x0), None).to(tl.float32)
	    tmp1 = tl.full([1], 0, tl.int32)
	    tmp2 = triton_helpers.maximum(tmp1, tmp0)
	    tl.store(in_out_ptr0 + (x0), tmp2, None)
	''', device_str='cuda')
	
	
	# kernel path: /tmp/torchinductor_cache/wv/cwv6cxclgtrt3hams2kloxex2znci73vsksvlyvcuj7liuhc6676.py
	# Topologically Sorted Source Nodes: [g, rs_expanded, out], Original ATen: [aten.mul, aten.repeat, aten.add]
	# Source node to ATen node mapping:
	#   g => mul_5
	#   out => add_3
	#   rs_expanded => repeat
	# Graph fragment:
	#   %buf14 : Tensor  = PlaceHolder[target=buf14]
	#   %buf16 : Tensor  = PlaceHolder[target=buf16]
	#   %mul_5 : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%wait_tensor_1, 0.7071067811865476), kwargs = {})
	#   %repeat : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.repeat.default](args = (%wait_tensor_2, [2, 1]), kwargs = {})
	#   %add_3 : Tensor "f16[2048, 1024][1024, 1]cuda:1"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%mul_5, %repeat), kwargs = {})
	#   return %add_3
	triton_poi_fused_add_mul_repeat_2 = async_compile.triton('triton_poi_fused_add_mul_repeat_2', '''
	import triton
	import triton.language as tl
	
	from torch._inductor.runtime import triton_helpers, triton_heuristics
	from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
	from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
	triton_helpers.set_driver_to_gpu()
	
	@triton_heuristics.pointwise(
	    size_hints={'x': 2097152}, 
	    filename=__file__,
	    triton_meta={'signature': {'in_ptr0': '*fp16', 'in_ptr1': '*fp16', 'out_ptr0': '*fp16', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=1, multi_processor_count=108, cc=80, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, warp_size=32), 'constants': {}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]]}]},
	    inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_mul_repeat_2', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'num_load': 2, 'num_reduction': 0, 'backend_hash': '47293E737FB461650F87749C5DACA1F6B144A22EE5CE7CD8757A23E028E91841', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'tiling_scores': {'x': 8388608}},
	    min_elem_per_thread=0
	)
	@triton.jit
	def triton_poi_fused_add_mul_repeat_2(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
	    xnumel = 2097152
	    xoffset = tl.program_id(0) * XBLOCK
	    xindex = xoffset + tl.arange(0, XBLOCK)[:]
	    xmask = tl.full([XBLOCK], True, tl.int1)
	    x2 = xindex
	    x0 = (xindex % 1024)
	    x1 = xindex // 1024
	    tmp0 = tl.load(in_ptr0 + (x2), None).to(tl.float32)
	    tmp3 = tl.load(in_ptr1 + (x0 + 1024*((x1 % 1024))), None).to(tl.float32)
	    tmp1 = 0.7071067811865476
	    tmp2 = tmp0 * tmp1
	    tmp4 = tmp2 + tmp3
	    tl.store(out_ptr0 + (x2), tmp4, None)
	''', device_str='cuda')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg2_1, (1024, ), (1, ))
	    assert_size_stride(arg3_1, (1024, ), (1, ))
	    assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
	    assert_size_stride(arg5_1, (2048, 1024), (1024, 1))
	    with torch.cuda._DeviceGuard(1):
	        torch.cuda.set_device(1)
	        buf0 = empty_strided_cuda((1024, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [h], Original ATen: [aten.mm]
	        extern_kernels.mm(arg1_1, reinterpret_tensor(arg0_1, (1024, 1024), (1, 1024), 0), out=buf0)
	        del arg0_1
	        del arg1_1
	        buf4 = buf0; del buf0  # reuse
	        # Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	        stream1 = get_raw_stream(1)
	        triton_per_fused_all_reduce_gelu_native_layer_norm_0.run(buf4, arg2_1, arg3_1, 1024, 1024, stream=stream1)
	        del arg2_1
	        del arg3_1
	        # Topologically Sorted Source Nodes: [h_1, h_2, all_reduce_default], Original ATen: [aten.gelu, aten.native_layer_norm, _c10d_functional.all_reduce]
	        torch.ops._c10d_functional.all_reduce_.default(buf4, 'sum', '0')
	        # Topologically Sorted Source Nodes: [h_3], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf4)
	        buf9 = empty_strided_cuda((1024, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [h2], Original ATen: [aten.mm]
	        extern_kernels.mm(buf4, reinterpret_tensor(arg4_1, (1024, 1024), (1, 1024), 0), out=buf9)
	        del arg4_1
	        buf10 = buf9; del buf9  # reuse
	        # Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	        stream1 = get_raw_stream(1)
	        triton_poi_fused_all_gather_into_tensor_relu_1.run(buf10, 1048576, stream=stream1)
	        # Topologically Sorted Source Nodes: [h2_1, all_gather_into_tensor_default], Original ATen: [aten.relu, _c10d_functional.all_gather_into_tensor]
	        buf11 = torch.ops._c10d_functional.all_gather_into_tensor.default(buf10, 2, '0')
	        assert_size_stride(buf11, (2048, 1024), (1024, 1), 'torch.ops._c10d_functional.all_gather_into_tensor.default')
	        assert_alignment(buf11, 16, 'torch.ops._c10d_functional.all_gather_into_tensor.default')
	        del buf4
	        # Topologically Sorted Source Nodes: [reduce_scatter_tensor_default], Original ATen: [_c10d_functional.reduce_scatter_tensor]
	        buf12 = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0')
	        assert_size_stride(buf12, (1024, 1024), (1024, 1), 'torch.ops._c10d_functional.reduce_scatter_tensor.default')
	        assert_alignment(buf12, 16, 'torch.ops._c10d_functional.reduce_scatter_tensor.default')
	        # Topologically Sorted Source Nodes: [gathered], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf11)
	        del buf10
	        # Topologically Sorted Source Nodes: [rs], Original ATen: [_c10d_functional.wait_tensor]
	        torch.ops._c10d_functional.wait_tensor.default(buf12)
	        del arg5_1
	        buf17 = empty_strided_cuda((2048, 1024), (1024, 1), torch.float16)
	        # Topologically Sorted Source Nodes: [g, rs_expanded, out], Original ATen: [aten.mul, aten.repeat, aten.add]
	        stream1 = get_raw_stream(1)
	        triton_poi_fused_add_mul_repeat_2.run(buf11, buf12, buf17, 2097152, stream=stream1)
	        del buf11
	        del buf12
	    return (buf17, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg1_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg2_1 = rand_strided((1024, ), (1, ), device='cuda:1', dtype=torch.float16)
	    arg3_1 = rand_strided((1024, ), (1, ), device='cuda:1', dtype=torch.float16)
	    arg4_1 = rand_strided((1024, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    arg5_1 = rand_strided((2048, 1024), (1024, 1), device='cuda:1', dtype=torch.float16)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0804 12:34:16.799000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "80236dd3153279aef925f754b0c47b70"}
	{
	"name": "PyCodeCache.load_by_key_path",
	"ts": 1754336056799696.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:16.802000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "12ad482937cfff8aece2cbc039844561"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336056802091.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.001000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "4d64653ef1d8d8c32ab4de360b189449"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057001688.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.002000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "80f978ac4c35bb3c9cb156c4c9c7212b"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057002558.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.003000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "3c142d9837ec0dfbc99fecfab8653418"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057003600.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.004000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5777ab745f33880ba17d9f6a14a0f70c"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057004106.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.277000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "4e663a4bec69ea28d39d17c2f748072b"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057277526.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.278000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "4f1a3e38895dbbdf80c453694838a888"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057278400.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.279000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "df182e15284e055cf323e429492b08af"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057279661.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.280000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "894894af91c31053d3d1aa05047df5ad"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057280180.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.520000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5cf06f1b29da2c07e13fdebaaaee8d77"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057520536.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.521000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "7ed1e0e9f925f1a7c72242bb070be0f4"}
	{
	"name": "CachingAutotuner.synchronize",
	"ts": 1754336057521421.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.522000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "e02e32b9c735425ff82cb524f6118aa4"}
	{
	"name": "async_compile.precompile",
	"ts": 1754336057522678.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.523000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "94801603d69e385f61d2cdf0a7f3542f"}
	{
	"name": "async_compile.wait",
	"ts": 1754336057523139.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.523000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "9ad23fc92a8e4f2a15ffaedb2bf2a062"}
	{
	"name": "async_compile.wait",
	"ts": 1754336057523699.0,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.524000 1142858 torch/_inductor/async_compile.py:116] {"artifact": {"name": "triton_kernel_info", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "911ae427d653658a7be1def130de511a"}
	{"triton_per_fused_all_reduce_gelu_native_layer_norm_0": {"autotune_cache_state": "only 1 config", "only_config": [["XBLOCK", 1], ["num_warps", 8], ["num_stages", 1]], "compile_time_us": 200965}, "triton_poi_fused_add_mul_repeat_2": {"autotune_cache_state": "miss", "num_configs": 2, "compile_time_us": 241968}, "triton_poi_fused_all_gather_into_tensor_relu_1": {"autotune_cache_state": "miss", "num_configs": 2, "compile_time_us": 275030}}
V0804 12:34:17.524000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "bee9239babd4825a4636a5bbc00edc0a"}
	{
	"name": "PyCodeCache.load_by_key_path",
	"ts": 1754336057524497.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.526000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5d61db82333d22acbcf73f9db933c20c"}
	{
	"name": "code_gen",
	"ts": 1754336057526188.5,
	"args": {
	"fn_name": "GraphLowering.compile_to_module",
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.528000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "c96d85c4e6d3a3185d3045f553d66b16"}
	{
	"name": "GraphLowering.compile_to_fn",
	"ts": 1754336057528082.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.528000 1142858 torch/_inductor/debug.py:700] {"artifact": {"name": "inductor_collective_schedule", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "e255b7f099207a3c7478df9c470be5fb"}
	[
	"torch.ops._c10d_functional.all_reduce_.default",
	"torch.ops._c10d_functional.wait_tensor.default",
	"torch.ops._c10d_functional.all_gather_into_tensor.default",
	"torch.ops._c10d_functional.reduce_scatter_tensor.default",
	"torch.ops._c10d_functional.wait_tensor.default",
	"torch.ops._c10d_functional.wait_tensor.default"
	]
V0804 12:34:17.536000 1142858 torch/_inductor/debug.py:734] {"artifact": {"name": "inductor_runtime_and_tensor_meta", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "5bdf44b46ade21759085f713237b436d"}
	{
	"ops": [
	{
	"name": "extern_kernels.mm",
	"type": "compute",
	"estimated_runtime_ns": 7918718.150774888,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "op1_op2_op4",
	"type": "compute",
	"estimated_runtime_ns": 2494.708994708994,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.all_reduce_.default",
	"type": "collective",
	"estimated_runtime_ns": 34581.10319270239,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "extern_kernels.mm",
	"type": "compute",
	"estimated_runtime_ns": 7918718.150774888,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "op8",
	"type": "compute",
	"estimated_runtime_ns": 2492.275132275132,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.all_gather_into_tensor.default",
	"type": "collective",
	"estimated_runtime_ns": 21085.55159635119,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.reduce_scatter_tensor.default",
	"type": "collective",
	"estimated_runtime_ns": 33891.10319270239,
	"outputs": [
	{
	"shape": [],
	"stride": [],
	"dtype": null
	},
	{
	"shape": [],
	"stride": [],
	"dtype": null
	}
	]
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "torch.ops._c10d_functional.wait_tensor.default",
	"type": "compute",
	"estimated_runtime_ns": 0
	},
	{
	"name": "op13",
	"type": "compute",
	"estimated_runtime_ns": 6230.68783068783,
	"outputs": [
	{
	"shape": [
	1024,
	1024
	],
	"stride": [
	1024,
	1
	],
	"dtype": "float16"
	}
	]
	}
	]
	}
V0804 12:34:17.537000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "ca8ccf8344ba48c785e79204ca585441"}
	{
	"name": "TritonBundler.collect",
	"ts": 1754336057536993.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.538000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "ef094d43c568c6c3ba97e4ecc345ebd5"}
	{
	"name": "TritonBundler.collect",
	"ts": 1754336057538643.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.542000 1142858 torch/_dynamo/utils.py:1970] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "15cbcc011ff940cc5afe9aba4d908989"}
	{
	"name": "fx_graph_cache_miss",
	"ts": 1754336056508661.2,
	"args": {
	"cache_status_detailed": "full_miss",
	"key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia",
	"components": [
	"[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1",
	"[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_event_time": 1754336056519882928,
	"cache_state": "miss",
	"triton_bundler_meta": "TritonBundlerMetadata(cached_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2', 'triton_poi_fused_add_mul_repeat_2'], statically_launched_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2'])",
	"time_taken_ns": 1028276620,
	"compile_id": "0/1"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0804 12:34:17.543000 1142858 torch/_inductor/compile_fx.py:1046] {"artifact": {"name": "fx_graph_cache_miss", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "e6fdbc08f0c63f46936e51c6e9971b97"}
	{"cache_status_detailed": "full_miss", "key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia", "components": ["[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ", "[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1", "[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)", "[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>", "[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}", "[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}", "[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None", "[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0", "[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False", "[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10", "[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True", "[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']", "[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None", "[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op", "[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait", "[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"], "cache_event_time": 1754336056519882928, "cache_state": "miss", "triton_bundler_meta": "TritonBundlerMetadata(cached_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2', 'triton_poi_fused_add_mul_repeat_2'], statically_launched_kernel_names=['triton_per_fused_all_reduce_gelu_native_layer_norm_0', 'triton_poi_fused_all_gather_into_tensor_relu_1', 'triton_poi_fused_add_mul_repeat_2'])", "time_taken_ns": 1028276620, "compile_id": "0/1"}
V0804 12:34:17.544000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "14540daa5eed5d60e04d8d90d1acad9b"}
	{
	"name": "fx_codegen_and_compile",
	"ts": 1754336057544033.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.545000 1142858 torch/_inductor/compile_fx.py:1063] {"artifact": {"name": "inductor_provenance_tracking_node_mappings", "encoding": "json"}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "76d2422b3e3af0e2c6da07ed7be908de"}
	{"preToPost": {"h": ["permute", "mm"], "h_1": ["convert_element_type_2", "mul", "mul_1", "erf", "add", "mul_2"], "h_2": ["mul_2", "var_mean", "getitem", "getitem_1", "sub", "add_1", "rsqrt", "mul_3", "mul_4", "add_2", "convert_element_type_5"], "all_reduce_default": ["all_reduce"], "h_3": ["wait_tensor"], "h2": ["permute_1", "mm_1"], "h2_1": ["relu"], "all_gather_into_tensor_default": ["all_gather_into_tensor"], "reduce_scatter_tensor_default": ["reduce_scatter_tensor"], "gathered": ["wait_tensor_1"], "g": ["mul_5"], "rs": ["wait_tensor_2"], "rs_expanded": ["repeat"], "out": ["add_3"]}, "postToPre": {"permute": ["h"], "mm": ["h"], "convert_element_type_2": ["h_1"], "mul": ["h_1"], "mul_1": ["h_1"], "erf": ["h_1"], "add": ["h_1"], "mul_2": ["h_1", "h_2"], "var_mean": ["h_2"], "getitem": ["h_2"], "getitem_1": ["h_2"], "sub": ["h_2"], "add_1": ["h_2"], "rsqrt": ["h_2"], "mul_3": ["h_2"], "mul_4": ["h_2"], "add_2": ["h_2"], "convert_element_type_5": ["h_2"], "all_reduce": ["all_reduce_default"], "wait_tensor": ["h_3"], "permute_1": ["h2"], "mm_1": ["h2"], "relu": ["h2_1"], "all_gather_into_tensor": ["all_gather_into_tensor_default"], "reduce_scatter_tensor": ["reduce_scatter_tensor_default"], "wait_tensor_1": ["gathered"], "mul_5": ["g"], "wait_tensor_2": ["rs"], "repeat": ["rs_expanded"], "add_3": ["out"]}, "cppCodeToPost": {"triton_per_fused_all_reduce_gelu_native_layer_norm_0": ["var_mean", "mul_2", "mul", "convert_element_type_2", "add", "erf", "mul_1", "all_reduce", "convert_element_type_5", "add_2", "mul_4", "mul_3", "sub", "rsqrt", "add_1"], "triton_poi_fused_all_gather_into_tensor_relu_1": ["all_gather_into_tensor", "relu"], "triton_poi_fused_add_mul_repeat_2": ["add_3", "mul_5", "repeat"], "extern_kernels.mm": ["mm", "mm_1"]}, "postToCppCode": {"var_mean": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "convert_element_type_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "erf": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_1": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "all_reduce": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "convert_element_type_5": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add_2": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_4": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "mul_3": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "sub": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "rsqrt": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "add_1": ["triton_per_fused_all_reduce_gelu_native_layer_norm_0"], "all_gather_into_tensor": ["triton_poi_fused_all_gather_into_tensor_relu_1"], "relu": ["triton_poi_fused_all_gather_into_tensor_relu_1"], "add_3": ["triton_poi_fused_add_mul_repeat_2"], "mul_5": ["triton_poi_fused_add_mul_repeat_2"], "repeat": ["triton_poi_fused_add_mul_repeat_2"], "mm": ["extern_kernels.mm"], "mm_1": ["extern_kernels.mm"]}}
V0804 12:34:17.546000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "aa82c2077ddbafd7cce2517078b3da43"}
	{
	"name": "inductor_compile",
	"ts": 1754336057545927.5,
	"args": {
	"fn_name": "compile_fx_inner",
	"compile_id": "0/1",
	"is_backward": false,
	"cache_state": "miss",
	"cache_event_time": 1754336056508661133,
	"key": "f6bxojkv2tkyeyw3flgftq3lum4do7ftvmytln7ypkb6ieubznia",
	"components": [
	"[klslu3vy2es3tc4n5yvydgpptnche426gkgax3wi4xxqeh7rg3i] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    permute = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n    mm = torch.ops.aten.mm.default(arg1_1, permute);  arg1_1 = permute = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(mm, torch.float32);  mm = None\n    mul = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.5)\n    mul_1 = torch.ops.aten.mul.Tensor(convert_element_type_2, 0.7071067811865476);  convert_element_type_2 = None\n    erf = torch.ops.aten.erf.default(mul_1);  mul_1 = None\n    add = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_2 = torch.ops.aten.mul.Tensor(mul, add);  mul = add = None\n    convert_element_type_default = torch.ops.prims.convert_element_type.default(mul_2, torch.float32);  mul_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(convert_element_type_default, [1], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_1 = torch.ops.aten.add.Tensor(getitem, 1e-05);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n    sub = torch.ops.aten.sub.Tensor(convert_element_type_default, getitem_1);  convert_element_type_default = getitem_1 = None\n    mul_3 = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = rsqrt = None\n    mul_4 = torch.ops.aten.mul.Tensor(mul_3, arg2_1);  mul_3 = arg2_1 = None\n    add_2 = torch.ops.aten.add.Tensor(mul_4, arg3_1);  mul_4 = arg3_1 = None\n    convert_element_type_5 = torch.ops.prims.convert_element_type.default(add_2, torch.float16);  add_2 = None\n    all_reduce = torch.ops._c10d_functional.all_reduce.default(convert_element_type_5, 'sum', '0');  convert_element_type_5 = None\n    wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_reduce);  all_reduce = None\n    permute_1 = torch.ops.aten.permute.default(arg4_1, [1, 0]);  arg4_1 = None\n    mm_1 = torch.ops.aten.mm.default(wait_tensor, permute_1);  wait_tensor = permute_1 = None\n    relu = torch.ops.aten.relu.default(mm_1);  mm_1 = None\n    all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(relu, 2, '0');  relu = None\n    wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None\n    mul_5 = torch.ops.aten.mul.Tensor(wait_tensor_1, 0.7071067811865476);  wait_tensor_1 = None\n    reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(arg5_1, 'sum', 2, '0');  arg5_1 = None\n    wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None\n    repeat = torch.ops.aten.repeat.default(wait_tensor_2, [2, 1]);  wait_tensor_2 = None\n    add_3 = torch.ops.aten.add.Tensor(mul_5, repeat);  mul_5 = repeat = None\n    return (add_3,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[jn5dpznysfkshu5d7o6jstxs3eamcej7zzc3h4b6g6xra5epddl] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2048, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[dfi2upbfgvk3ozzfjnvawsrpgxhkwumw2cjlioivkmndol26fzb] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=2097152, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[t2ryydmmcqolckbtiicgzdf5xciy4mswb5c3dcbmtydcjjvufds] fx_kwargs[static_input_idxs]: [0, 2, 3, 4]",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1",
	"[qs5hilycp4ew4ivtc7m5jaxp7q4pm5slioxw3fi3ur6ei65ybz4] inputs_to_check[1]: 5",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_bypass_reason": null,
	"remote_cache_enabled": false,
	"local_cache_enabled": true
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.547000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "575fb830502bd4aef41be843d415bd81"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1754336057547051.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.551000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "c93ee0f5660e1303f99b3bb6658dba22"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1754336057551887.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.553000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "29b59e021e5c79f63433f5cc4dd58004"}
	{
	"name": "backend_compile",
	"ts": 1754336057552910.0,
	"args": {
	"fn_name": "OutputGraph.call_user_compiler",
	"compile_id": "0/1",
	"cache_state": "miss",
	"cache_event_time": 1754336056406148383,
	"key": "afubxnpftvfzvivqkfjzm5bjnp5zqzdzypxzfjm7fon6oexin4cp",
	"components": [
	"[4rhty5nckl2hipjsjkdmjgluxlm2eveaqpiafrp6qbm2mktcfxj] aot_config: (0, True, False, False, False, [DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin1')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=0, index_is_slice=False), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='weight'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='norm')), member='_parameters'), index='bias'), DictGetItemSource(base=UnspecializedParamBufferSource(base=UnspecializedBuiltinNNModuleSource(base=DictGetItemSource(base=AttrSource(base=UnspecializedNNModuleSource(base=AttrSource(base=LocalSource(local_name='fn', is_input=False, dynamism=None, is_derefed_cell_contents=True), member='__self__')), member='_modules'), index='lin2')), member='_parameters'), index='weight'), GetItemSource(base=LocalSource(local_name='args', is_input=True, dynamism=None, is_derefed_cell_contents=False), index=1, index_is_slice=False)], True, False)",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] grad_enabled: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] disable_amp: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] deterministic_algorithms: False",
	"[a3g6hu5gj6ypolpu5eiwaa24tvdrqy2d3n7y7bchqvqcla5wv4h] autograd_config: <bytes>",
	"[n6sc2fvnirfszghhl57eizswoeza3b7ymawunbnoo74dzwi675c] saved_tensors_hooks_fx_wrap_cache_hashes: ([], [])",
	"[37bbftveeozdffmrf2244yi2ocxahadxh32gqzugjlsai2z2jfg] gm: GraphModule()\n\n\n\ndef forward(self, p_0 : torch.nn.parameter.Parameter, p_1 : torch.Tensor, p_2 : torch.nn.parameter.Parameter, p_3 : torch.nn.parameter.Parameter, p_4 : torch.nn.parameter.Parameter, p_5 : torch.Tensor):\n    _set_grad_enabled = torch._C._set_grad_enabled(False);  _set_grad_enabled = None\n    h = torch._C._nn.linear(p_1, p_0, None);  p_1 = p_0 = None\n    h_1 = torch._C._nn.gelu(h);  h = None\n    h_2 = torch.nn.functional.layer_norm(h_1, (1024,), p_2, p_3, 1e-05);  h_1 = p_2 = p_3 = None\n    all_reduce_default = torch.ops._c10d_functional.all_reduce.default(h_2, 'sum', '0');  h_2 = None\n    h_3 = torch.ops._c10d_functional.wait_tensor.default(all_reduce_default);  all_reduce_default = None\n    h2 = torch._C._nn.linear(h_3, p_4, None);  h_3 = p_4 = None\n    h2_1 = torch.nn.functional.relu(h2);  h2 = None\n    all_gather_into_tensor_default = torch.ops._c10d_functional.all_gather_into_tensor.default(h2_1, 2, '0');  h2_1 = None\n    gathered = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_default);  all_gather_into_tensor_default = None\n    g = gathered * 0.7071067811865476;  gathered = None\n    reduce_scatter_tensor_default = torch.ops._c10d_functional.reduce_scatter_tensor.default(p_5, 'sum', 2, '0');  p_5 = None\n    rs = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_default);  reduce_scatter_tensor_default = None\n    rs_expanded = rs.repeat(2, 1);  rs = None\n    out = g + rs_expanded;  g = rs_expanded = None\n    _set_grad_enabled_1 = torch._C._set_grad_enabled(True);  _set_grad_enabled_1 = None\n    return (out,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[0]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[zlidl2jqksoxglnp6mo5cn62kyk56ut3k7s57j7hbiazpazgy7w] example_inputs[1]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[2]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qbrhmv4m2evjmcyqbl4e4niiykdvawenfkjbnjwcwjabarssm7h] example_inputs[3]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024]), stride=(1,), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[s7usvvnyaxl77cl7dex7yczvuhgoinfe6e2ppxa64xk746orgyd] example_inputs[4]: TensorMetadata(dtype=torch.float16, shape=torch.Size([1024, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=True, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4uhmgjyxzfhev4obncbweg4wr3iiqofhzlo5wtgqqgeqgn3o22p] example_inputs[5]: TensorMetadata(dtype=torch.float16, shape=torch.Size([2048, 1024]), stride=(1024, 1), device=device(type='cuda', index=1), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: ",
	"[lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)",
	"[o7ywtcfh5jatmugblhhm4ehexuq4zublbr5xy2sxqwv4qfyo3lo] torch_version: <bytes>",
	"[c3z7bmoxyo6gl5hi47v6dc7jwsl55b3asd75nr25uyengi5ah3p] system_info[device]: {'name': 'NVIDIA PG509-210'}",
	"[rjffsmxjhe6pczzs4jwl4grjhlz42uafteetfpfyluk2euk4mwk] system_info[version]: {'triton': '3.4.063b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-463e6d170a9f8cc475f9caf60b13abde73f7133d95e0413710d290029ebab977-63b9eee7d82feea9757d3582580583ea5c2e512baecd1c9ba2890a29dba0b9ae-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-c9a17432a7d9f35f9f2f525be5a0f1186197b368fea55395a67796413e83394b-ffa79ab5cef7184d72cfa45bb1648ed2236ce3dfe48078c7dcf7bd0ec31b2a07-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-00deb4ba92653e089ad09c2f67cbc85602c84cd3ee2347ddcfcccc2081cfa45e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-703cffec3481886c30dc5993abcc425dff6d2fdfcce2528b7ccc996099c4a11a-448c23dda5888b37a97afa2c1d688358c513e087c4dacfa41ce826827c7602f5-0d0ab0a6f849bfed40e39586bbfc4f32b94977ceb78b60a59b565e225d9fa59e-52c6eb4a6bfdd8c74d5bd25f2a4c83843380648f1daeb4b53caec0bf6ba7ec0e-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-400a9cfc4d4834a8d8956e844529dbf6e5a81010c04259f1927db288858724f4-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-89e4844782de5fdff4868ac2846514570a6e280a6b92e91af2e180904043c833-45ff80981cdc3ba3915734b14ae2d73b2d25a68653b27440b93be3485f37afe1-0e48b5e1e95136642ccfe62dc3d0a739a2c20a7b5ee13e9c23c6cecd68cdeb70-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-11141fb45eb27ae4cc98f3bbdb6196a5fc2e83bafd6435a1c5384bd64c0b7e62-130a713916833a239d4f84200a7c62157aec0bae769e8ed1a6d56817d3acccdd', 'cuda': '12.4'}",
	"[ge3s6hslcjcwqhwuwtnozc3we4c7ed5jbpxydbrwqcgd4unbeov] system_info[hash]: a27498eb8f0e137fb8151c825a36166ee7dae5040a8c1ed1edf405ddd4f7078f",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None",
	"[t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[graph_partition]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0",
	"[zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False",
	"[4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10",
	"[jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package_constants_on_disk]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.embed_kernel_binary]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.emit_multi_arch_kernel]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.compile_standalone]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_presets]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True",
	"[ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']",
	"[6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None",
	"[nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op",
	"[t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait",
	"[74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)"
	],
	"cache_bypass_reason": null,
	"remote_cache_enabled": false,
	"local_cache_enabled": true,
	"requires_subclass_dispatch": false,
	"dispatch_mode": "inference"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "993d974dfe8f1e85e9bfd2447147f6a8"}
	{
	"name": "compile_attempt_0",
	"ts": 1754336057556288.8,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.556000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "ed08aa4ec91b74e6dbd4428600f8b8fb"}
	{
	"name": "build_guards",
	"ts": 1754336057556752.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.604000 1142858 torch/_dynamo/guards.py:3264] {"dynamo_cpp_guards_str": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "e43f79e90e076e25c23fe0530956739a"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo/output_graph.py:643 in init_ambient_guards
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:631 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['fn'], accessed_by=FrameLocalsGuardAccessor(key='fn', framelocals_idx=2), type=<class 'method'>, tag_safe=(False, False)
	| | +- ID_MATCH: ___check_obj_id(L['fn'], 139646516664256)                   
	| | +- GuardManager: source=L['fn'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__), type=<class 'tuple'>, tag_safe=(False, False)
	| | | +- GuardManager: source=L['fn'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0), type=<class 'cell'>, tag_safe=(False, False)
	| | | | +- GuardManager: source=L['fn'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents), type=<class 'method'>, tag_safe=(False, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__closure__[0].cell_contents, 9738560)  # with ctx_factory():  # utils/_contextlib.py:119 in decorate_context
	| | | +- GuardManager: source=L['fn'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1), type=<class 'cell'>, tag_safe=(False, False)
	| | | | +- GuardManager: source=L['fn'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- GuardManager: source=L['fn'].__closure__[1].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__), type=<class 'code'>, tag_safe=(True, False)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['fn'].__closure__[1].cell_contents.__code__, 11214464)  # return func(*args, **kwargs)  # utils/_contextlib.py:120 in decorate_context
	| | +- GuardManager: source=L['fn'].__self__, accessed_by=GetAttrGuardAccessor(__self__), type=<class '__main__.MultiGraphRepro'>, tag_safe=(True, True)
	| | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__, 86065824)                
	| | | +- GuardManager: source=L['fn'].__self__.__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | +- GuardManager: source=L['fn'].__self__._modules, accessed_by=DictGetItemGuardAccessor('_modules'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules, 9676128)          # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1'], accessed_by=DictGetItemGuardAccessor('lin1'), type=<class 'torch.nn.modules.linear.Linear'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin1'], 87594704)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['lin1'].__dict__)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin1']._parameters, 9676128)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'NoneType'>, tag_safe=(True, False)
	| | | | | | | | | +- NONE_MATCH: L['fn'].__self__._modules['lin1']._parameters['bias'] is None  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin1']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['lin1']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2'], accessed_by=DictGetItemGuardAccessor('lin2'), type=<class 'torch.nn.modules.linear.Linear'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin2'], 87594704)  # h2 = self.lin2(h)  # test2.py:70 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['lin2'].__dict__)  # h2 = self.lin2(h)  # test2.py:70 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['lin2']._parameters, 9676128)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'NoneType'>, tag_safe=(True, False)
	| | | | | | | | | +- NONE_MATCH: L['fn'].__self__._modules['lin2']._parameters['bias'] is None  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['lin2']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['lin2']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'], accessed_by=DictGetItemGuardAccessor('norm'), type=<class 'torch.nn.modules.normalization.LayerNorm'>, tag_safe=(True, False)
	| | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm'], 88494992)  # h = self.norm(h)  # test2.py:61 in graph_one
	| | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].__dict__, accessed_by=GetGenericDictGuardAccessor, type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['fn'].__self__._modules['norm'].__dict__)  # h = self.norm(h)  # test2.py:61 in graph_one
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].eps, accessed_by=DictGetItemGuardAccessor('eps'), type=<class 'float'>, tag_safe=(True, False)
	| | | | | | | | +- EQUALS_MATCH: L['fn'].__self__._modules['norm'].eps == 1e-05                # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm']._parameters, 9676128)  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor('bias'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['norm']._parameters['bias'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024], stride=[1])  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor('weight'), type=<class 'torch.nn.parameter.Parameter'>, tag_safe=(True, False)
	| | | | | | | | | +- TENSOR_MATCH: check_tensor(L['fn'].__self__._modules['norm']._parameters['weight'], Parameter, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=True, size=[1024], stride=[1])  # input, self.normalized_shape, self.weight, self.bias, self.eps  # nn/modules/normalization.py:230 in forward
	| | | | | | | +- GuardManager: source=L['fn'].__self__._modules['norm'].normalized_shape, accessed_by=DictGetItemGuardAccessor('normalized_shape'), type=<class 'tuple'>, tag_safe=(True, False)
	| | | | | | | | +- EQUALS_MATCH: L['fn'].__self__._modules['norm'].normalized_shape == (1024,)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._modules['norm'].normalized_shape, 9650464)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | | | | | +- LENGTH_CHECK: len(L['fn'].__self__._modules['norm'].normalized_shape) == 1  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | | | +- GuardManager: source=L['fn'].__self__._parameters, accessed_by=DictGetItemGuardAccessor('_parameters'), type=<class 'dict'>, tag_safe=(True, False)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['fn'].__self__._parameters, 9676128)       # h = self.lin1(x)  # test2.py:59 in graph_one
	| +- GuardManager: source=L['args'], accessed_by=FrameLocalsGuardAccessor(key='args', framelocals_idx=0), type=<class 'tuple'>, tag_safe=(True, False)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 9650464)                        
	| | +- LENGTH_CHECK: len(L['args']) == 3                                         
	| | +- GuardManager: source=L['args'][0], accessed_by=TupleGetItemGuardAccessor(0), type=<class 'torch.Tensor'>, tag_safe=(True, False)
	| | | +- TENSOR_MATCH: check_tensor(L['args'][0], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=False, size=[1024, 1024], stride=[1024, 1])  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- NO_HASATTR: hasattr(L['args'][0], '_dynamo_dynamic_indices') == False     # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['args'][0], L['args'][1])
	| | +- GuardManager: source=L['args'][1], accessed_by=TupleGetItemGuardAccessor(1), type=<class 'torch.Tensor'>, tag_safe=(True, False)
	| | | +- TENSOR_MATCH: check_tensor(L['args'][1], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float16, device=1, requires_grad=False, size=[2048, 1024], stride=[1024, 1])  # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | +- NO_HASATTR: hasattr(L['args'][1], '_dynamo_dynamic_indices') == False     # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | +- NO_TENSOR_ALIASING
	| | +- GuardManager: source=L['args'][2], accessed_by=TupleGetItemGuardAccessor(2), type=<class 'int'>, tag_safe=(True, False)
	| | | +- EQUALS_MATCH: L['args'][2] == 2                                             # torch.ops._c10d_functional.all_gather_into_tensor.default(  # test2.py:75 in graph_one
	| +- GuardManager: source=L['kwargs'], accessed_by=FrameLocalsGuardAccessor(key='kwargs', framelocals_idx=1), type=<class 'dict'>, tag_safe=(True, False)
	| | +- TYPE_MATCH: ___check_type_id(L['kwargs'], 9676128)                      
	| | +- DICT_LENGTH: not L['kwargs']                                             
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)
	| | +- GuardManager: source=G['__import___main__'], accessed_by=DictGetItemGuardAccessor('__import___main__'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import___main__'], 139648550378592)      # h = F.gelu(h)  # test2.py:60 in graph_one
	| | | +- GuardManager: source=G['__import___main__'].math, accessed_by=GetAttrGuardAccessor(math), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].math, 139648548565248)  # g = gathered * math.sqrt(0.5)  # test2.py:82 in graph_one
	| | | | +- GuardManager: source=G['__import___main__'].math.sqrt, accessed_by=GetAttrGuardAccessor(sqrt), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].math.sqrt, 139648548568848)  # g = gathered * math.sqrt(0.5)  # test2.py:82 in graph_one
	| | | +- GuardManager: source=G['__import___main__'].torch, accessed_by=GetAttrGuardAccessor(torch), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch, 139648548799248)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | +- GuardManager: source=G['__import___main__'].torch.ops, accessed_by=GetAttrGuardAccessor(ops), type=<class 'torch._ops._Ops'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops, 139646535729696)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional, accessed_by=GetAttrGuardAccessor(_c10d_functional), type=<class 'torch._ops._OpNamespace'>, tag_safe=(False, False)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional, 139645390308672)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.all_reduce, accessed_by=GetAttrGuardAccessor(all_reduce), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.all_reduce, 139645365491216)  # torch.ops._c10d_functional.all_reduce.default(h, "sum", "0")  # test2.py:65 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.wait_tensor, accessed_by=GetAttrGuardAccessor(wait_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.wait_tensor, 139645391765136)  # h = torch.ops._c10d_functional.wait_tensor.default(  # test2.py:64 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.reduce_scatter_tensor, accessed_by=GetAttrGuardAccessor(reduce_scatter_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.reduce_scatter_tensor, 139645365494432)  # torch.ops._c10d_functional.reduce_scatter_tensor.default(  # test2.py:86 in graph_one
	| | | | | | +- GuardManager: source=G['__import___main__'].torch.ops._c10d_functional.all_gather_into_tensor, accessed_by=GetAttrGuardAccessor(all_gather_into_tensor), type=<class 'torch._ops.OpOverloadPacket'>, tag_safe=(False, False)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['__import___main__'].torch.ops._c10d_functional.all_gather_into_tensor, 139645365493040)  # torch.ops._c10d_functional.all_gather_into_tensor.default(  # test2.py:75 in graph_one
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_linear'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 139646537542256)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F), type=<class 'module'>, tag_safe=(False, False)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F, 139646537542176)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.gelu, accessed_by=GetAttrGuardAccessor(gelu), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.gelu, 139647331694640)  # h = F.gelu(h)  # test2.py:60 in graph_one
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.relu, accessed_by=GetAttrGuardAccessor(relu), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.relu, 139646534605440)  # h2 = F.relu(h2)  # test2.py:71 in graph_one
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.linear, accessed_by=GetAttrGuardAccessor(linear), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.linear, 139647331695760)  # return F.linear(input, self.weight, self.bias)  # nn/modules/linear.py:134 in forward
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F.layer_norm, accessed_by=GetAttrGuardAccessor(layer_norm), type=<class 'function'>, tag_safe=(False, False)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'].F.layer_norm, 139646534610080)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_module'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 139646542524272)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks), type=<class 'collections.OrderedDict'>, tag_safe=(True, False)
	| | | | +- TYPE_MATCH: ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 9668128)  # h = self.lin1(x)  # test2.py:59 in graph_one
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'], accessed_by=DictGetItemGuardAccessor('__import_torch_dot_nn_dot_modules_dot_normalization'), type=<class 'module'>, tag_safe=(False, False)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_normalization'], 139646533665952)  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	+- LAMBDA_GUARD: G['__import_torch_dot_nn_dot_modules_dot_linear'].F is G['__import___main__'].F  # h = F.gelu(h)  # test2.py:60 in graph_one
	+- LAMBDA_GUARD: G['__import_torch_dot_nn_dot_modules_dot_linear'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F  # return F.layer_norm(  # nn/modules/normalization.py:229 in forward
	
	Guard latency = 76.59 us
V0804 12:34:17.605000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "34c095b8287af9a8e0795bf443735bd9"}
	{
	"name": "build_guards",
	"ts": 1754336057604943.2,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.605000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "287c902d8f119efce4659e7156d907f4"}
	{
	"name": "gc",
	"ts": 1754336057605596.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.612000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "62e1991310911d573d0cd0d87742e3a8"}
	{
	"name": "gc",
	"ts": 1754336057612475.5,
	"args": {
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.613000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "c9baed5bb949943a63c9444699a3230f"}
	{
	"name": "entire_frame_compile",
	"ts": 1754336057613317.0,
	"args": {
	"fn_name": "_compile.compile_inner",
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.616000 1142858 torch/_dynamo/utils.py:1626] {"compilation_metrics": {"compile_id": "0/1", "frame_key": "2", "co_name": "inner", "co_filename": "/home/skarjala/pytorch/torch/_dynamo/external_utils.py", "co_firstlineno": 66, "cache_size": 1, "accumulated_cache_size": 1, "guard_count": 74, "shape_env_guard_count": 0, "graph_op_count": 16, "graph_node_count": 23, "graph_input_count": 6, "start_time": 1754336056.314324, "entire_frame_compile_time_s": 1.298985, "backend_compile_time_s": 1.166478, "inductor_compile_time_s": 1.03941, "code_gen_time_s": 0.915887, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": ["_c10d_functional::all_gather_into_tensor", "_c10d_functional::reduce_scatter_tensor", "_c10d_functional::all_reduce", "_c10d_functional::wait_tensor"], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "remote_cache_time_saved_s": null, "structured_logging_overhead_s": 0.055596, "config_suppress_errors": false, "config_inline_inbuilt_nn_modules": true, "specialize_float": false, "dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}", "is_forward": true, "num_triton_bundles": null, "remote_fx_graph_cache_get_time_ms": null, "remote_fx_graph_cache_put_time_ms": null, "start_time_us": 1754336056314324, "duration_us": 1298985, "dynamo_cumulative_compile_time_us": 1298985, "aot_autograd_cumulative_compile_time_us": 1166478, "inductor_cumulative_compile_time_us": 1039410, "inductor_code_gen_cumulative_compile_time_us": 915887, "triton_compile_time_us": 720120, "runtime_cudagraphify_time_us": null, "runtime_triton_autotune_time_us": null, "dynamo_compile_time_before_restart_us": 0, "distributed_ephemeral_timeout_us": null, "structured_logging_overhead_us": 55596, "remote_fx_graph_cache_get_time_us": null, "remote_fx_graph_cache_put_time_us": null, "backward_cumulative_compile_time_us": null, "end_time_us": 1754336057613729, "pre_grad_pass_time_us": 1199, "post_grad_pass_time_us": 6732, "joint_graph_pass_time_us": 10172, "log_format_version": 3, "inductor_config": "{\"TYPE_CHECKING\": false, \"_cache_config_ignore_prefix\": [\"trace\", \"cuda.cutlass_dir\", \"worker_start_method\", \"compile_threads\", \"post_grad_custom_post_pass\", \"post_grad_custom_pre_pass\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\", \"always_complex_memory_overlap_TESTING_ONLY\", \"fx_graph_cache\", \"fx_graph_remote_cache\", \"autotune_local_cache\", \"autotune_remote_cache\"], \"_collective.auto_select\": false, \"_collective.one_shot_all_reduce_threshold_bytes\": 131072, \"_fuse_ddp_bucket_size\": 25, \"_fuse_ddp_communication\": false, \"_fuse_ddp_communication_passes\": [\"fuse_ddp_with_concat_op\", \"schedule_comm_wait\"], \"_micro_pipeline_tp\": false, \"_post_fusion_custom_pass\": null, \"_pre_fusion_custom_pass\": null, \"_profile_var\": \"\", \"_raise_error_for_testing\": false, \"_save_config_ignore\": [\"trace.upload_tar\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"pre_grad_custom_pass\", \"aot_inductor.repro_level\", \"aot_inductor.dump_aoti_minifier\", \"post_grad_custom_pre_pass\", \"post_grad_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\"], \"add_pre_grad_passes\": null, \"aggressive_fusion\": false, \"alignment_asserts\": true, \"allow_buffer_reuse\": true, \"always_complex_memory_overlap_TESTING_ONLY\": false, \"always_keep_tensor_constants\": false, \"annotate_training\": false, \"aot_inductor.allow_stack_allocation\": false, \"aot_inductor.compile_standalone\": false, \"aot_inductor.compile_wrapper_opt_level\": \"O1\", \"aot_inductor.custom_op_libs\": null, \"aot_inductor.custom_ops_to_c_shims\": {}, \"aot_inductor.debug_compile\": false, \"aot_inductor.debug_intermediate_value_printer\": \"0\", \"aot_inductor.dump_aoti_minifier\": false, \"aot_inductor.embed_kernel_binary\": false, \"aot_inductor.emit_multi_arch_kernel\": false, \"aot_inductor.enable_lto\": false, \"aot_inductor.filtered_kernel_names\": null, \"aot_inductor.force_mmap_weights\": false, \"aot_inductor.metadata\": {}, \"aot_inductor.model_name_for_generated_files\": null, \"aot_inductor.output_path\": \"\", \"aot_inductor.package\": false, \"aot_inductor.package_constants_in_so\": true, \"aot_inductor.package_constants_on_disk\": false, \"aot_inductor.package_cpp_only\": null, \"aot_inductor.precompile_headers\": true, \"aot_inductor.presets\": {}, \"aot_inductor.raise_error_on_ignored_optimization\": true, \"aot_inductor.repro_level\": 2, \"aot_inductor.serialized_in_spec\": \"\", \"aot_inductor.serialized_out_spec\": \"\", \"aot_inductor.use_consts_asm_build\": true, \"aot_inductor.use_minimal_arrayref_interface\": false, \"aot_inductor.use_runtime_constant_folding\": false, \"aot_inductor.weight_use_caching_allocator\": false, \"assert_indirect_indexing\": true, \"assume_aligned_inputs\": false, \"assume_unaligned_fallback_output\": false, \"autoheuristic_collect\": \"\", \"autoheuristic_log_path\": \"DEFAULT\", \"autoheuristic_use\": \"mixed_mm\", \"autotune_fallback_to_aten\": false, \"autotune_in_subproc\": false, \"autotune_local_cache\": true, \"autotune_lookup_table\": {}, \"autotune_multi_device\": false, \"autotune_num_choices_displayed\": 10, \"autotune_remote_cache\": null, \"b2b_gemm_pass\": false, \"batch_fusion\": true, \"benchmark_combo_kernel\": false, \"benchmark_epilogue_fusion\": true, \"benchmark_fusion\": false, \"benchmark_harness\": true, \"benchmark_kernel\": false, \"bfloat16_atomic_adds_enabled\": true, \"bucket_all_gathers_fx\": \"none\", \"bucket_all_gathers_fx_bucket_size_determinator\": null, \"bucket_reduce_scatters_fx\": \"none\", \"bucket_reduce_scatters_fx_bucket_size_determinator\": null, \"bundle_triton_into_fx_graph_cache\": true, \"bundled_autotune_remote_cache\": null, \"bw_outputs_user_visible\": true, \"can_inplace_pad_graph_input\": false, \"check_stack_no_cycles_TESTING_ONLY\": false, \"combo_kernel_allow_mixed_sizes\": 1, \"combo_kernel_foreach_dynamic_shapes\": true, \"combo_kernels\": false, \"combo_kernels_autotune\": 1, \"comment_origin\": false, \"compile_threads\": 32, \"comprehensive_padding\": true, \"compute_all_bounds\": false, \"constant_and_index_propagation\": true, \"conv_1x1_as_mm\": false, \"coordinate_descent_check_all_directions\": false, \"coordinate_descent_search_radius\": 1, \"coordinate_descent_tuning\": false, \"cpp.cxx\": [null, \"g++\"], \"cpp.descriptive_names\": \"original_aten\", \"cpp.dynamic_threads\": false, \"cpp.enable_concat_linear\": false, \"cpp.enable_floating_point_contract_flag\": \"off\", \"cpp.enable_grouped_gemm_template\": false, \"cpp.enable_kernel_profile\": false, \"cpp.enable_loop_tail_vec\": true, \"cpp.enable_tiling_heuristics\": true, \"cpp.enable_unsafe_math_opt_flag\": false, \"cpp.fallback_scatter_reduce_sum\": true, \"cpp.force_inline_kernel\": false, \"cpp.gemm_cache_blocking\": null, \"cpp.gemm_max_k_slices\": 1, \"cpp.gemm_thread_factors\": null, \"cpp.inject_log1p_bug_TESTING_ONLY\": null, \"cpp.inject_relu_bug_TESTING_ONLY\": null, \"cpp.max_horizontal_fusion_size\": 16, \"cpp.min_chunk_size\": 512, \"cpp.no_redundant_loops\": true, \"cpp.simdlen\": null, \"cpp.threads\": -1, \"cpp.use_decompose_tanh\": false, \"cpp.use_small_dequant_buffer\": false, \"cpp.vec_isa_ok\": null, \"cpp.weight_prepack\": true, \"cpp_cache_precompile_headers\": true, \"cpp_wrapper\": false, \"cpp_wrapper_build_separate\": false, \"cpu_backend\": \"cpp\", \"cuda.arch\": null, \"cuda.binary_remote_cache_force_write\": false, \"cuda.compile_opt_level\": \"-O1\", \"cuda.cuda_cxx\": null, \"cuda.cutlass_backend_min_gemm_size\": 1, \"cuda.cutlass_dir\": \"/home/skarjala/pytorch/third_party/cutlass\", \"cuda.cutlass_enabled_ops\": \"all\", \"cuda.cutlass_epilogue_fusion_enabled\": false, \"cuda.cutlass_hash_with_compile_cmd\": false, \"cuda.cutlass_instantiation_level\": \"0\", \"cuda.cutlass_max_profiling_configs\": null, \"cuda.cutlass_max_profiling_swizzle_options\": [1, 2, 4, 8], \"cuda.cutlass_op_allowlist_regex\": null, \"cuda.cutlass_op_denylist_regex\": null, \"cuda.cutlass_prescreening\": true, \"cuda.cutlass_presets\": null, \"cuda.cutlass_tma_only\": false, \"cuda.enable_caching_codegen\": true, \"cuda.enable_cuda_lto\": false, \"cuda.enable_debug_info\": false, \"cuda.enable_ptxas_info\": false, \"cuda.generate_test_runner\": false, \"cuda.upload_to_binary_remote_cache\": false, \"cuda.use_binary_remote_cache\": true, \"cuda.use_fast_math\": false, \"cuda.version\": null, \"cuda_backend\": \"triton\", \"dce\": false, \"debug\": false, \"debug_fusion\": false, \"debug_index_asserts\": false, \"debug_ir_traceback\": false, \"decompose_mem_bound_mm\": false, \"developer_warnings\": true, \"disable_cpp_codegen\": false, \"disable_padding_cpu\": true, \"disable_progress\": true, \"dynamic_scale_rblock\": true, \"efficient_conv_bn_eval_fx_passes\": false, \"emulate_precision_casts\": false, \"enable_auto_functionalized_v2\": true, \"enable_caching_generated_triton_templates\": true, \"enable_linear_binary_folding\": false, \"enabled_metric_tables\": \"\", \"epilogue_fusion\": true, \"epilogue_fusion_first\": false, \"estimate_op_runtime\": \"default\", \"external_matmul\": [], \"fallback_random\": false, \"force_fuse_int_mm_with_mul\": false, \"force_layout_optimization\": false, \"force_pointwise_cat\": false, \"force_same_precision\": false, \"force_shape_pad\": false, \"freezing\": false, \"freezing_discard_parameters\": false, \"fx_graph_cache\": true, \"fx_graph_remote_cache\": null, \"fx_passes_numeric_check\": {\"num_iterations\": 1, \"pre_grad\": false, \"precision\": 0.0001, \"requires_optimizer\": true}, \"generate_intermediate_hooks\": false, \"global_cache_dir\": null, \"graph_partition\": false, \"group_fusion\": false, \"halide.asserts\": false, \"halide.cpu_target\": \"host\", \"halide.debug\": false, \"halide.gpu_target\": \"host-cuda\", \"halide.scan_kernels\": false, \"halide.scheduler_cpu\": \"Adams2019\", \"halide.scheduler_cuda\": \"Anderson2021\", \"implicit_fallbacks\": true, \"inplace_buffers\": true, \"inplace_padding\": true, \"inter_node_bw\": 25, \"intra_node_bw\": 300, \"is_nightly_or_source\": true, \"is_predispatch\": false, \"joint_custom_post_pass\": null, \"joint_custom_pre_pass\": null, \"joint_graph_constant_folding\": true, \"keep_output_stride\": true, \"kernel_name_max_ops\": 10, \"layout_opt_default\": \"1\", \"layout_optimization\": true, \"loop_ordering_after_fusion\": false, \"max_autotune\": false, \"max_autotune_conv_backends\": \"ATEN,TRITON\", \"max_autotune_flex_search_space\": \"DEFAULT\", \"max_autotune_gemm\": false, \"max_autotune_gemm_backends\": \"ATEN,TRITON,CPP\", \"max_autotune_gemm_search_space\": \"DEFAULT\", \"max_autotune_pointwise\": false, \"max_autotune_report_choices_stats\": true, \"max_autotune_subproc_graceful_timeout_seconds\": 0.0, \"max_autotune_subproc_result_timeout_seconds\": 60.0, \"max_autotune_subproc_terminate_timeout_seconds\": 0.0, \"max_epilogue_benchmarked_choices\": 1, \"max_fusion_buffer_group_pairwise_attempts\": 64, \"max_fusion_size\": 64, \"max_pointwise_cat_inputs\": 8, \"memory_planning\": false, \"memory_pool\": \"intermediates\", \"min_num_split\": 0, \"mixed_mm_choice\": \"heuristic\", \"multi_kernel_hints\": [], \"nan_asserts\": false, \"non_blocking_remote_cache_write\": true, \"online_softmax\": true, \"optimize_scatter_upon_const_tensor\": true, \"pad_channels_last\": false, \"pad_outputs\": false, \"padding_alignment_bytes\": 128, \"padding_stride_threshold\": 1024, \"pattern_matcher\": true, \"permute_fusion\": false, \"pick_loop_orders\": true, \"post_grad_custom_post_pass\": null, \"post_grad_custom_pre_pass\": null, \"post_grad_fusion_options\": {}, \"pre_grad_custom_pass\": null, \"pre_grad_fusion_options\": {}, \"precompilation_timeout_seconds\": 3600, \"profile_bandwidth\": false, \"profile_bandwidth_output\": null, \"profile_bandwidth_regex\": \"\", \"profile_bandwidth_with_do_bench_using_profiling\": false, \"profiler_mark_wrapper_call\": false, \"prologue_fusion\": true, \"quiesce_async_compile_pool\": false, \"realize_acc_reads_size_threshold\": null, \"realize_acc_reads_threshold\": 8, \"realize_opcount_threshold\": 30, \"realize_reads_threshold\": 4, \"remove_pre_grad_passes\": null, \"reorder_for_compute_comm_overlap\": false, \"reorder_for_compute_comm_overlap_passes\": [\"reorder_compute_for_overlap\", \"sink_waits\", \"raise_comms\"], \"reorder_for_locality\": true, \"reorder_for_peak_memory\": true, \"reorder_prefetch_limit\": null, \"rocm.arch\": [], \"rocm.ck_dir\": null, \"rocm.ck_max_profiling_configs\": null, \"rocm.ck_supported_arch\": [\"gfx90a\", \"gfx942\", \"gfx950\"], \"rocm.ck_tile_max_profiling_configs\": null, \"rocm.compile_opt_level\": \"-O2\", \"rocm.flush_denormals\": true, \"rocm.generate_test_runner\": false, \"rocm.is_debug\": false, \"rocm.kBatch_sweep\": null, \"rocm.n_max_profiling_configs\": null, \"rocm.print_kernel_resource_usage\": false, \"rocm.rocm_home\": null, \"rocm.save_temps\": false, \"rocm.split_k_threshold\": 16, \"rocm.use_fast_math\": true, \"rocm.use_preselected_instances\": false, \"save_args\": false, \"scalar_asserts\": true, \"score_fusion_memory_threshold\": 10, \"search_autotune_cache\": false, \"shape_padding\": true, \"size_asserts\": true, \"sleep_sec_TESTING_ONLY\": null, \"split_cat_fx_passes\": true, \"split_reductions\": true, \"static_launch_user_defined_triton_kernels\": false, \"static_weight_shapes\": true, \"strict_static_cuda_launcher\": false, \"test_configs.autotune_choice_desc_regex\": null, \"test_configs.autotune_choice_name_regex\": null, \"test_configs.force_extern_kernel_in_multi_template\": false, \"test_configs.graphsafe_rng_func_ignores_fallback_random\": false, \"test_configs.max_mm_configs\": null, \"test_configs.runtime_triton_dtype_assert\": false, \"test_configs.static_cpp_dtype_assert\": false, \"trace.compile_profile\": false, \"trace.debug_dir\": null, \"trace.debug_log\": false, \"trace.dot_graph_shape\": null, \"trace.draw_orig_fx_graph\": false, \"trace.enabled\": true, \"trace.fx_graph\": true, \"trace.fx_graph_transformed\": true, \"trace.graph_diagram\": false, \"trace.info_log\": false, \"trace.ir_post_fusion\": true, \"trace.ir_pre_fusion\": true, \"trace.log_autotuning_results\": false, \"trace.log_url_for_graph_xform\": null, \"trace.output_code\": true, \"trace.provenance_tracking\": true, \"trace.save_real_tensors\": false, \"trace.upload_tar\": null, \"triton.autotune_at_compile_time\": null, \"triton.autotune_cublasLt\": true, \"triton.autotune_pointwise\": true, \"triton.autotune_with_sample_inputs\": false, \"triton.coalesce_tiling_analysis\": true, \"triton.codegen_upcast_to_fp32\": true, \"triton.cooperative_reductions\": false, \"triton.cudagraph_capture_sizes\": null, \"triton.cudagraph_dynamic_shape_warn_limit\": 50, \"triton.cudagraph_skip_dynamic_graphs\": false, \"triton.cudagraph_support_input_mutation\": true, \"triton.cudagraph_trees\": true, \"triton.cudagraph_trees_history_recording\": false, \"triton.cudagraph_unexpected_rerecord_limit\": 128, \"triton.cudagraphs\": false, \"triton.debug_sync_graph\": false, \"triton.debug_sync_kernel\": false, \"triton.decompose_k_threshold\": 32, \"triton.dense_indexing\": false, \"triton.descriptive_names\": \"original_aten\", \"triton.disallow_failing_autotune_kernels_TESTING_ONLY\": false, \"triton.divisible_by_16\": true, \"triton.enable_persistent_tma_matmul\": false, \"triton.fast_path_cudagraph_asserts\": false, \"triton.force_cooperative_reductions\": false, \"triton.force_cudagraph_sync\": false, \"triton.force_cudagraphs_warmup\": false, \"triton.inject_relu_bug_TESTING_ONLY\": null, \"triton.max_tiles\": null, \"triton.min_split_scan_rblock\": 256, \"triton.multi_kernel\": 0, \"triton.num_decompose_k_splits\": 10, \"triton.persistent_reductions\": true, \"triton.prefer_nd_tiling\": false, \"triton.skip_cudagraph_warmup\": false, \"triton.skip_l1_cache\": false, \"triton.slow_path_cudagraph_asserts\": true, \"triton.spill_threshold\": 16, \"triton.store_cubin\": false, \"triton.tile_reductions\": false, \"triton.tiling_prevents_pointwise_fusion\": true, \"triton.tiling_prevents_reduction_fusion\": true, \"triton.unique_kernel_names\": true, \"triton.unique_user_kernel_names\": false, \"triton.use_block_ptr\": false, \"triton.use_tensor_descriptor\": false, \"triton_kernel_default_layout_constraint\": \"needs_fixed_stride_order\", \"unbacked_symint_fallback\": 8192, \"unroll_reductions_threshold\": 8, \"unsafe_ignore_unsupported_triton_autotune_args\": false, \"unsafe_marked_cacheable_functions\": {}, \"unsafe_skip_cache_dynamic_shape_guards\": false, \"use_experimental_benchmarker\": true, \"use_fast_math\": false, \"use_mixed_mm\": true, \"use_static_cuda_launcher\": true, \"verbose_progress\": false, \"warn_mix_layout\": false, \"worker_start_method\": \"subprocess\", \"worker_suppress_logging\": true}", "remote_cache_version": null, "inductor_fx_remote_cache_hit_count": null, "inductor_fx_remote_cache_miss_count": null, "inductor_fx_remote_cache_backend_type": null, "inductor_fx_remote_cache_hit_keys": null, "inductor_fx_remote_cache_miss_keys": null, "cuda_version": "12.4", "triton_version": "3.4.0", "feature_usage": {"aot_autograd_remote_cache": false, "fx_cache": true, "parallel_compile_post_warmup": false, "static_cuda_launcher": true, "triton_bundling": true}, "compile_time_autotune_time_us": 3720, "is_runtime": false, "gc_time_us": 6878, "tensorify_float_attempt": null, "tensorify_float_success": null, "tensorify_float_failure": null, "guard_latency_us": 76, "recompile_reason": "0/0: ___check_obj_id(fn, 139645370122560)                   ", "num_graph_breaks": 0, "triton_kernel_compile_times_us": "[[\"triton_poi_fused_all_gather_into_tensor_relu_1\", 275030], [\"triton_poi_fused_add_mul_repeat_2\", 241968], [\"triton_per_fused_all_reduce_gelu_native_layer_norm_0\", 200965]]", "ir_count": 123, "cudagraph_skip_reason": null, "python_version": "3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]", "pgo_put_remote_code_state_time_us": null, "pgo_get_remote_code_state_time_us": null, "param_numel": 2099200, "param_bytes": 4198400, "param_count": 4, "recompile_user_contexts": null}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0}
V0804 12:34:17.616000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "frame_id": 0, "frame_compile_id": 3, "attempt": 0, "has_payload": "e5e170a8abbb6cfeb1f911f0268e54c7"}
	{
	"name": "dynamo",
	"ts": 1754336057616827.0,
	"args": {
	"compile_id": "0/1",
	"num_graph_breaks": 0,
	"guard_latency_us": 76,
	"frame_key": "2",
	"co_name": "inner",
	"co_filename": "/home/skarjala/pytorch/torch/_dynamo/external_utils.py",
	"co_firstlineno": 66,
	"cache_size": 1,
	"accumulated_cache_size": 1,
	"guard_count": 74,
	"shape_env_guard_count": 0,
	"graph_op_count": 16,
	"graph_node_count": 23,
	"graph_input_count": 6,
	"fail_type": null,
	"fail_reason": null,
	"fail_user_frame_filename": null,
	"fail_user_frame_lineno": null,
	"non_compliant_ops": [],
	"compliant_custom_ops": [
	"_c10d_functional::all_gather_into_tensor",
	"_c10d_functional::reduce_scatter_tensor",
	"_c10d_functional::all_reduce",
	"_c10d_functional::wait_tensor"
	],
	"restart_reasons": [],
	"dynamo_time_before_restart_s": 0.0,
	"has_guarded_code": true,
	"dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.618000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "d12146f7cea70f5bcbd201d87761d0c7"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057618449.5,
	"args": {
	"kernel_name": "triton_poi_fused_all_gather_into_tensor_relu_1",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.619000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "4010c9af9457d49754c6fd46b2fdf585"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057619328.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.650000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "65f713b9210df3d5d122cf6a56ff560b"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057650626.8,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.651000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "e1389d214d9a14fb65c01353f08d6a07"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057651446.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.664000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "9af83c401cd846ee17d03bc8bc4ee499"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057664746.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.665000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "5d874912142c9bfd726b1f86e19a0e74"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057665164.5,
	"args": {
	"kernel_name": "triton_poi_fused_all_gather_into_tensor_relu_1",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.666000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "b3cea9f7482bbd3f76dfcef4848e1501"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057666301.8,
	"args": {
	"kernel_name": "triton_poi_fused_add_mul_repeat_2",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.667000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "acb4dc136e497003711efcd4ffc16634"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057667075.0,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.676000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "ab15fe0f95c885a59701a1f202e2c376"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057676590.5,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.677000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "10061e3509b8d2b1b6bea2f8c0cd17f4"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057677333.8,
	"args": {
	"compile_id": "None"
	},
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "1bbdb7e90d19a309656a9c38d86eac43"}
	{
	"name": "InductorBenchmarker.benchmark_gpu",
	"ts": 1754336057686403.5,
	"args": {
	"compile_id": "None"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.686000 1142858 torch/_dynamo/utils.py:1931] {"chromium_event": {}, "rank": 3, "has_payload": "f7e91746014d42c8f6f90be6d82ab3b7"}
	{
	"name": "CachingAutotuner.benchmark_all_configs",
	"ts": 1754336057686856.2,
	"args": {
	"kernel_name": "triton_poi_fused_add_mul_repeat_2",
	"is_backward": false,
	"compile_id": "0/1"
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0804 12:34:17.690000 1142858 torch/_dynamo/utils.py:1626] {"compilation_metrics_runtime": {"compile_id": "0/1", "frame_key": null, "co_name": null, "co_filename": null, "co_firstlineno": null, "cache_size": null, "accumulated_cache_size": null, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1754336057.665496, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": null, "compliant_custom_ops": null, "restart_reasons": null, "dynamo_time_before_restart_s": null, "has_guarded_code": null, "remote_cache_time_saved_s": null, "structured_logging_overhead_s": null, "config_suppress_errors": false, "config_inline_inbuilt_nn_modules": true, "specialize_float": null, "dynamo_config": "{\"_autograd_backward_strict_mode_conditional_banned_ops\": [\"stride\", \"storage_offset\", \"is_contiguous\"], \"_unsafe_skip_fsdp_module_guards\": false, \"accumulated_recompile_limit\": 256, \"allow_complex_guards_as_runtime_asserts\": false, \"allow_empty_graphs\": false, \"allow_ignore_mark_dynamic\": false, \"allow_rnn\": false, \"allow_unspec_int_on_nn_module\": false, \"allowed_functions_module_string_ignorelist\": [\"torch._decomp\", \"torch._prims\", \"torch._refs\", \"torch.distributions\", \"torch.testing\"], \"assume_static_by_default\": true, \"automatic_dynamic_local_pgo\": true, \"automatic_dynamic_remote_pgo\": null, \"automatic_dynamic_shapes\": true, \"automatic_dynamic_shapes_mark_as\": \"dynamic\", \"caching_precompile\": false, \"capture_autograd_function\": true, \"capture_dynamic_output_shape_ops\": false, \"capture_func_transforms\": true, \"capture_scalar_outputs\": false, \"capture_sparse_compute\": true, \"compiled_autograd\": false, \"compiled_autograd_kwargs_override\": {}, \"cprofile\": false, \"cudagraph_backend_keep_input_mutation\": false, \"cudagraph_backend_support_input_mutation\": false, \"dead_code_elimination\": true, \"disable\": false, \"do_not_emit_runtime_asserts\": false, \"dont_skip_tracing\": false, \"dynamic_shapes\": true, \"enable_compiler_collectives\": false, \"enable_cpp_framelocals_guard_eval\": true, \"enable_cpp_guard_manager\": true, \"enable_cpp_symbolic_shape_guards\": true, \"enable_faithful_generator_behavior\": true, \"enable_trace_contextlib\": true, \"enable_trace_unittest\": false, \"error_on_nested_fx_trace\": true, \"error_on_nested_jit_trace\": true, \"error_on_recompile\": false, \"fail_on_recompile_limit_hit\": false, \"fake_tensor_cache_crosscheck_enabled\": false, \"fake_tensor_cache_enabled\": true, \"fake_tensor_disable_inference_mode\": true, \"force_nn_module_property_static_shapes\": true, \"force_parameter_static_shapes\": true, \"force_unspec_int_unbacked_size_like_on_torchrec_kjt\": false, \"graph_break_on_nn_param_ctor\": true, \"graph_deduplication_lint\": false, \"guard_nn_modules\": true, \"guard_nn_modules_using_dict_tags\": true, \"inline_inbuilt_nn_modules\": true, \"install_free_tensors\": false, \"issue_3_13_0_warning\": true, \"max_saved_pointers_for_recursive_dict_tags_check\": 256, \"minimum_call_count\": 1, \"numpy_default_complex\": \"complex128\", \"numpy_default_float\": \"float64\", \"numpy_default_int\": \"int64\", \"only_allow_pt2_compliant_ops\": false, \"optimize_ddp\": true, \"optimize_ddp_lazy_compile\": false, \"prefer_deferred_runtime_asserts_over_guards\": false, \"prepare_freezing\": false, \"pt2_compile_id_prefix\": null, \"raise_on_ctx_manager_usage\": true, \"raise_on_unsafe_aot_autograd\": false, \"recompile_limit\": 8, \"record_compile_time_instruction_count\": false, \"record_runtime_overhead\": true, \"replay_record_enabled\": false, \"report_guard_failures\": true, \"rewrite_assert_with_torch_assert\": true, \"run_gc_after_compile\": true, \"skip_code_recursive_on_recompile_limit_hit\": true, \"skip_fsdp_guards\": true, \"skip_fsdp_hooks\": true, \"skip_guards_on_constant_func_defaults\": true, \"skip_nnmodule_hook_guards\": true, \"skip_no_tensor_aliasing_guards_on_parameters\": true, \"skip_tensor_guards_with_matching_dict_tags\": true, \"skip_torchrec\": true, \"skipfiles_inline_module_allowlist\": {}, \"specialize_float\": false, \"specialize_int\": false, \"suppress_errors\": false, \"trace_numpy\": true, \"track_nodes_for_deduplication\": false, \"use_graph_deduplication\": false, \"use_lamba_guard_for_object_aliasing\": true, \"use_lazy_graph_module\": true, \"use_numpy_random_stream\": false, \"use_recursive_dict_tags_for_guards\": true, \"verify_correctness\": false, \"wrap_top_frame\": false}", "is_forward": true, "num_triton_bundles": null, "remote_fx_graph_cache_get_time_ms": null, "remote_fx_graph_cache_put_time_ms": null, "start_time_us": 1754336057665496, "duration_us": 67268, "dynamo_cumulative_compile_time_us": null, "aot_autograd_cumulative_compile_time_us": null, "inductor_cumulative_compile_time_us": null, "inductor_code_gen_cumulative_compile_time_us": null, "triton_compile_time_us": null, "runtime_cudagraphify_time_us": null, "runtime_triton_autotune_time_us": 67268, "dynamo_compile_time_before_restart_us": null, "distributed_ephemeral_timeout_us": null, "structured_logging_overhead_us": null, "remote_fx_graph_cache_get_time_us": null, "remote_fx_graph_cache_put_time_us": null, "backward_cumulative_compile_time_us": null, "end_time_us": 1754336057687713, "pre_grad_pass_time_us": null, "post_grad_pass_time_us": null, "joint_graph_pass_time_us": null, "log_format_version": 3, "inductor_config": "{\"TYPE_CHECKING\": false, \"_cache_config_ignore_prefix\": [\"trace\", \"cuda.cutlass_dir\", \"worker_start_method\", \"compile_threads\", \"post_grad_custom_post_pass\", \"post_grad_custom_pre_pass\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\", \"always_complex_memory_overlap_TESTING_ONLY\", \"fx_graph_cache\", \"fx_graph_remote_cache\", \"autotune_local_cache\", \"autotune_remote_cache\"], \"_collective.auto_select\": false, \"_collective.one_shot_all_reduce_threshold_bytes\": 131072, \"_fuse_ddp_bucket_size\": 25, \"_fuse_ddp_communication\": false, \"_fuse_ddp_communication_passes\": [\"fuse_ddp_with_concat_op\", \"schedule_comm_wait\"], \"_micro_pipeline_tp\": false, \"_post_fusion_custom_pass\": null, \"_pre_fusion_custom_pass\": null, \"_profile_var\": \"\", \"_raise_error_for_testing\": false, \"_save_config_ignore\": [\"trace.upload_tar\", \"joint_custom_pre_pass\", \"joint_custom_post_pass\", \"pre_grad_custom_pass\", \"aot_inductor.repro_level\", \"aot_inductor.dump_aoti_minifier\", \"post_grad_custom_pre_pass\", \"post_grad_custom_post_pass\", \"_fuse_ddp_communication_passes\", \"_pre_fusion_custom_pass\"], \"add_pre_grad_passes\": null, \"aggressive_fusion\": false, \"alignment_asserts\": true, \"allow_buffer_reuse\": true, \"always_complex_memory_overlap_TESTING_ONLY\": false, \"always_keep_tensor_constants\": false, \"annotate_training\": false, \"aot_inductor.allow_stack_allocation\": false, \"aot_inductor.compile_standalone\": false, \"aot_inductor.compile_wrapper_opt_level\": \"O1\", \"aot_inductor.custom_op_libs\": null, \"aot_inductor.custom_ops_to_c_shims\": {}, \"aot_inductor.debug_compile\": false, \"aot_inductor.debug_intermediate_value_printer\": \"0\", \"aot_inductor.dump_aoti_minifier\": false, \"aot_inductor.embed_kernel_binary\": false, \"aot_inductor.emit_multi_arch_kernel\": false, \"aot_inductor.enable_lto\": false, \"aot_inductor.filtered_kernel_names\": null, \"aot_inductor.force_mmap_weights\": false, \"aot_inductor.metadata\": {}, \"aot_inductor.model_name_for_generated_files\": null, \"aot_inductor.output_path\": \"\", \"aot_inductor.package\": false, \"aot_inductor.package_constants_in_so\": true, \"aot_inductor.package_constants_on_disk\": false, \"aot_inductor.package_cpp_only\": null, \"aot_inductor.precompile_headers\": true, \"aot_inductor.presets\": {}, \"aot_inductor.raise_error_on_ignored_optimization\": true, \"aot_inductor.repro_level\": 2, \"aot_inductor.serialized_in_spec\": \"\", \"aot_inductor.serialized_out_spec\": \"\", \"aot_inductor.use_consts_asm_build\": true, \"aot_inductor.use_minimal_arrayref_interface\": false, \"aot_inductor.use_runtime_constant_folding\": false, \"aot_inductor.weight_use_caching_allocator\": false, \"assert_indirect_indexing\": true, \"assume_aligned_inputs\": false, \"assume_unaligned_fallback_output\": false, \"autoheuristic_collect\": \"\", \"autoheuristic_log_path\": \"DEFAULT\", \"autoheuristic_use\": \"mixed_mm\", \"autotune_fallback_to_aten\": false, \"autotune_in_subproc\": false, \"autotune_local_cache\": true, \"autotune_lookup_table\": {}, \"autotune_multi_device\": false, \"autotune_num_choices_displayed\": 10, \"autotune_remote_cache\": null, \"b2b_gemm_pass\": false, \"batch_fusion\": true, \"benchmark_combo_kernel\": false, \"benchmark_epilogue_fusion\": true, \"benchmark_fusion\": false, \"benchmark_harness\": true, \"benchmark_kernel\": false, \"bfloat16_atomic_adds_enabled\": true, \"bucket_all_gathers_fx\": \"none\", \"bucket_all_gathers_fx_bucket_size_determinator\": null, \"bucket_reduce_scatters_fx\": \"none\", \"bucket_reduce_scatters_fx_bucket_size_determinator\": null, \"bundle_triton_into_fx_graph_cache\": true, \"bundled_autotune_remote_cache\": null, \"bw_outputs_user_visible\": true, \"can_inplace_pad_graph_input\": false, \"check_stack_no_cycles_TESTING_ONLY\": false, \"combo_kernel_allow_mixed_sizes\": 1, \"combo_kernel_foreach_dynamic_shapes\": true, \"combo_kernels\": false, \"combo_kernels_autotune\": 1, \"comment_origin\": false, \"compile_threads\": 32, \"comprehensive_padding\": true, \"compute_all_bounds\": false, \"constant_and_index_propagation\": true, \"conv_1x1_as_mm\": false, \"coordinate_descent_check_all_directions\": false, \"coordinate_descent_search_radius\": 1, \"coordinate_descent_tuning\": false, \"cpp.cxx\": [null, \"g++\"], \"cpp.descriptive_names\": \"original_aten\", \"cpp.dynamic_threads\": false, \"cpp.enable_concat_linear\": false, \"cpp.enable_floating_point_contract_flag\": \"off\", \"cpp.enable_grouped_gemm_template\": false, \"cpp.enable_kernel_profile\": false, \"cpp.enable_loop_tail_vec\": true, \"cpp.enable_tiling_heuristics\": true, \"cpp.enable_unsafe_math_opt_flag\": false, \"cpp.fallback_scatter_reduce_sum\": true, \"cpp.force_inline_kernel\": false, \"cpp.gemm_cache_blocking\": null, \"cpp.gemm_max_k_slices\": 1, \"cpp.gemm_thread_factors\": null, \"cpp.inject_log1p_bug_TESTING_ONLY\": null, \"cpp.inject_relu_bug_TESTING_ONLY\": null, \"cpp.max_horizontal_fusion_size\": 16, \"cpp.min_chunk_size\": 512, \"cpp.no_redundant_loops\": true, \"cpp.simdlen\": null, \"cpp.threads\": -1, \"cpp.use_decompose_tanh\": false, \"cpp.use_small_dequant_buffer\": false, \"cpp.vec_isa_ok\": null, \"cpp.weight_prepack\": true, \"cpp_cache_precompile_headers\": true, \"cpp_wrapper\": false, \"cpp_wrapper_build_separate\": false, \"cpu_backend\": \"cpp\", \"cuda.arch\": null, \"cuda.binary_remote_cache_force_write\": false, \"cuda.compile_opt_level\": \"-O1\", \"cuda.cuda_cxx\": null, \"cuda.cutlass_backend_min_gemm_size\": 1, \"cuda.cutlass_dir\": \"/home/skarjala/pytorch/third_party/cutlass\", \"cuda.cutlass_enabled_ops\": \"all\", \"cuda.cutlass_epilogue_fusion_enabled\": false, \"cuda.cutlass_hash_with_compile_cmd\": false, \"cuda.cutlass_instantiation_level\": \"0\", \"cuda.cutlass_max_profiling_configs\": null, \"cuda.cutlass_max_profiling_swizzle_options\": [1, 2, 4, 8], \"cuda.cutlass_op_allowlist_regex\": null, \"cuda.cutlass_op_denylist_regex\": null, \"cuda.cutlass_prescreening\": true, \"cuda.cutlass_presets\": null, \"cuda.cutlass_tma_only\": false, \"cuda.enable_caching_codegen\": true, \"cuda.enable_cuda_lto\": false, \"cuda.enable_debug_info\": false, \"cuda.enable_ptxas_info\": false, \"cuda.generate_test_runner\": false, \"cuda.upload_to_binary_remote_cache\": false, \"cuda.use_binary_remote_cache\": true, \"cuda.use_fast_math\": false, \"cuda.version\": null, \"cuda_backend\": \"triton\", \"dce\": false, \"debug\": false, \"debug_fusion\": false, \"debug_index_asserts\": false, \"debug_ir_traceback\": false, \"decompose_mem_bound_mm\": false, \"developer_warnings\": true, \"disable_cpp_codegen\": false, \"disable_padding_cpu\": true, \"disable_progress\": true, \"dynamic_scale_rblock\": true, \"efficient_conv_bn_eval_fx_passes\": false, \"emulate_precision_casts\": false, \"enable_auto_functionalized_v2\": true, \"enable_caching_generated_triton_templates\": true, \"enable_linear_binary_folding\": false, \"enabled_metric_tables\": \"\", \"epilogue_fusion\": true, \"epilogue_fusion_first\": false, \"estimate_op_runtime\": \"default\", \"external_matmul\": [], \"fallback_random\": false, \"force_fuse_int_mm_with_mul\": false, \"force_layout_optimization\": false, \"force_pointwise_cat\": false, \"force_same_precision\": false, \"force_shape_pad\": false, \"freezing\": false, \"freezing_discard_parameters\": false, \"fx_graph_cache\": true, \"fx_graph_remote_cache\": null, \"fx_passes_numeric_check\": {\"num_iterations\": 1, \"pre_grad\": false, \"precision\": 0.0001, \"requires_optimizer\": true}, \"generate_intermediate_hooks\": false, \"global_cache_dir\": null, \"graph_partition\": false, \"group_fusion\": false, \"halide.asserts\": false, \"halide.cpu_target\": \"host\", \"halide.debug\": false, \"halide.gpu_target\": \"host-cuda\", \"halide.scan_kernels\": false, \"halide.scheduler_cpu\": \"Adams2019\", \"halide.scheduler_cuda\": \"Anderson2021\", \"implicit_fallbacks\": true, \"inplace_buffers\": true, \"inplace_padding\": true, \"inter_node_bw\": 25, \"intra_node_bw\": 300, \"is_nightly_or_source\": true, \"is_predispatch\": false, \"joint_custom_post_pass\": null, \"joint_custom_pre_pass\": null, \"joint_graph_constant_folding\": true, \"keep_output_stride\": true, \"kernel_name_max_ops\": 10, \"layout_opt_default\": \"1\", \"layout_optimization\": true, \"loop_ordering_after_fusion\": false, \"max_autotune\": false, \"max_autotune_conv_backends\": \"ATEN,TRITON\", \"max_autotune_flex_search_space\": \"DEFAULT\", \"max_autotune_gemm\": false, \"max_autotune_gemm_backends\": \"ATEN,TRITON,CPP\", \"max_autotune_gemm_search_space\": \"DEFAULT\", \"max_autotune_pointwise\": false, \"max_autotune_report_choices_stats\": true, \"max_autotune_subproc_graceful_timeout_seconds\": 0.0, \"max_autotune_subproc_result_timeout_seconds\": 60.0, \"max_autotune_subproc_terminate_timeout_seconds\": 0.0, \"max_epilogue_benchmarked_choices\": 1, \"max_fusion_buffer_group_pairwise_attempts\": 64, \"max_fusion_size\": 64, \"max_pointwise_cat_inputs\": 8, \"memory_planning\": false, \"memory_pool\": \"intermediates\", \"min_num_split\": 0, \"mixed_mm_choice\": \"heuristic\", \"multi_kernel_hints\": [], \"nan_asserts\": false, \"non_blocking_remote_cache_write\": true, \"online_softmax\": true, \"optimize_scatter_upon_const_tensor\": true, \"pad_channels_last\": false, \"pad_outputs\": false, \"padding_alignment_bytes\": 128, \"padding_stride_threshold\": 1024, \"pattern_matcher\": true, \"permute_fusion\": false, \"pick_loop_orders\": true, \"post_grad_custom_post_pass\": null, \"post_grad_custom_pre_pass\": null, \"post_grad_fusion_options\": {}, \"pre_grad_custom_pass\": null, \"pre_grad_fusion_options\": {}, \"precompilation_timeout_seconds\": 3600, \"profile_bandwidth\": false, \"profile_bandwidth_output\": null, \"profile_bandwidth_regex\": \"\", \"profile_bandwidth_with_do_bench_using_profiling\": false, \"profiler_mark_wrapper_call\": false, \"prologue_fusion\": true, \"quiesce_async_compile_pool\": false, \"realize_acc_reads_size_threshold\": null, \"realize_acc_reads_threshold\": 8, \"realize_opcount_threshold\": 30, \"realize_reads_threshold\": 4, \"remove_pre_grad_passes\": null, \"reorder_for_compute_comm_overlap\": false, \"reorder_for_compute_comm_overlap_passes\": [\"reorder_compute_for_overlap\", \"sink_waits\", \"raise_comms\"], \"reorder_for_locality\": true, \"reorder_for_peak_memory\": true, \"reorder_prefetch_limit\": null, \"rocm.arch\": [], \"rocm.ck_dir\": null, \"rocm.ck_max_profiling_configs\": null, \"rocm.ck_supported_arch\": [\"gfx90a\", \"gfx942\", \"gfx950\"], \"rocm.ck_tile_max_profiling_configs\": null, \"rocm.compile_opt_level\": \"-O2\", \"rocm.flush_denormals\": true, \"rocm.generate_test_runner\": false, \"rocm.is_debug\": false, \"rocm.kBatch_sweep\": null, \"rocm.n_max_profiling_configs\": null, \"rocm.print_kernel_resource_usage\": false, \"rocm.rocm_home\": null, \"rocm.save_temps\": false, \"rocm.split_k_threshold\": 16, \"rocm.use_fast_math\": true, \"rocm.use_preselected_instances\": false, \"save_args\": false, \"scalar_asserts\": true, \"score_fusion_memory_threshold\": 10, \"search_autotune_cache\": false, \"shape_padding\": true, \"size_asserts\": true, \"sleep_sec_TESTING_ONLY\": null, \"split_cat_fx_passes\": true, \"split_reductions\": true, \"static_launch_user_defined_triton_kernels\": false, \"static_weight_shapes\": true, \"strict_static_cuda_launcher\": false, \"test_configs.autotune_choice_desc_regex\": null, \"test_configs.autotune_choice_name_regex\": null, \"test_configs.force_extern_kernel_in_multi_template\": false, \"test_configs.graphsafe_rng_func_ignores_fallback_random\": false, \"test_configs.max_mm_configs\": null, \"test_configs.runtime_triton_dtype_assert\": false, \"test_configs.static_cpp_dtype_assert\": false, \"trace.compile_profile\": false, \"trace.debug_dir\": null, \"trace.debug_log\": false, \"trace.dot_graph_shape\": null, \"trace.draw_orig_fx_graph\": false, \"trace.enabled\": true, \"trace.fx_graph\": true, \"trace.fx_graph_transformed\": true, \"trace.graph_diagram\": false, \"trace.info_log\": false, \"trace.ir_post_fusion\": true, \"trace.ir_pre_fusion\": true, \"trace.log_autotuning_results\": false, \"trace.log_url_for_graph_xform\": null, \"trace.output_code\": true, \"trace.provenance_tracking\": true, \"trace.save_real_tensors\": false, \"trace.upload_tar\": null, \"triton.autotune_at_compile_time\": null, \"triton.autotune_cublasLt\": true, \"triton.autotune_pointwise\": true, \"triton.autotune_with_sample_inputs\": false, \"triton.coalesce_tiling_analysis\": true, \"triton.codegen_upcast_to_fp32\": true, \"triton.cooperative_reductions\": false, \"triton.cudagraph_capture_sizes\": null, \"triton.cudagraph_dynamic_shape_warn_limit\": 50, \"triton.cudagraph_skip_dynamic_graphs\": false, \"triton.cudagraph_support_input_mutation\": true, \"triton.cudagraph_trees\": true, \"triton.cudagraph_trees_history_recording\": false, \"triton.cudagraph_unexpected_rerecord_limit\": 128, \"triton.cudagraphs\": false, \"triton.debug_sync_graph\": false, \"triton.debug_sync_kernel\": false, \"triton.decompose_k_threshold\": 32, \"triton.dense_indexing\": false, \"triton.descriptive_names\": \"original_aten\", \"triton.disallow_failing_autotune_kernels_TESTING_ONLY\": false, \"triton.divisible_by_16\": true, \"triton.enable_persistent_tma_matmul\": false, \"triton.fast_path_cudagraph_asserts\": false, \"triton.force_cooperative_reductions\": false, \"triton.force_cudagraph_sync\": false, \"triton.force_cudagraphs_warmup\": false, \"triton.inject_relu_bug_TESTING_ONLY\": null, \"triton.max_tiles\": null, \"triton.min_split_scan_rblock\": 256, \"triton.multi_kernel\": 0, \"triton.num_decompose_k_splits\": 10, \"triton.persistent_reductions\": true, \"triton.prefer_nd_tiling\": false, \"triton.skip_cudagraph_warmup\": false, \"triton.skip_l1_cache\": false, \"triton.slow_path_cudagraph_asserts\": true, \"triton.spill_threshold\": 16, \"triton.store_cubin\": false, \"triton.tile_reductions\": false, \"triton.tiling_prevents_pointwise_fusion\": true, \"triton.tiling_prevents_reduction_fusion\": true, \"triton.unique_kernel_names\": true, \"triton.unique_user_kernel_names\": false, \"triton.use_block_ptr\": false, \"triton.use_tensor_descriptor\": false, \"triton_kernel_default_layout_constraint\": \"needs_fixed_stride_order\", \"unbacked_symint_fallback\": 8192, \"unroll_reductions_threshold\": 8, \"unsafe_ignore_unsupported_triton_autotune_args\": false, \"unsafe_marked_cacheable_functions\": {}, \"unsafe_skip_cache_dynamic_shape_guards\": false, \"use_experimental_benchmarker\": true, \"use_fast_math\": false, \"use_mixed_mm\": true, \"use_static_cuda_launcher\": true, \"verbose_progress\": false, \"warn_mix_layout\": false, \"worker_start_method\": \"subprocess\", \"worker_suppress_logging\": true}", "remote_cache_version": null, "inductor_fx_remote_cache_hit_count": null, "inductor_fx_remote_cache_miss_count": null, "inductor_fx_remote_cache_backend_type": null, "inductor_fx_remote_cache_hit_keys": null, "inductor_fx_remote_cache_miss_keys": null, "cuda_version": "12.4", "triton_version": "3.4.0", "feature_usage": null, "compile_time_autotune_time_us": null, "is_runtime": true, "gc_time_us": null, "tensorify_float_attempt": null, "tensorify_float_success": null, "tensorify_float_failure": null, "guard_latency_us": null, "recompile_reason": null, "num_graph_breaks": null, "triton_kernel_compile_times_us": null, "ir_count": null, "cudagraph_skip_reason": null, "python_version": "3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]", "pgo_put_remote_code_state_time_us": null, "pgo_get_remote_code_state_time_us": null, "param_numel": null, "param_bytes": null, "param_count": null, "recompile_user_contexts": null}, "rank": 3, "frame_id": 0, "frame_compile_id": 3}
